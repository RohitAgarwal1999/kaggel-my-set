{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from matplotlib import cm\n",
    "sns.set_style('ticks')\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>commonFileTypes</th>\n",
       "      <th>creatorName</th>\n",
       "      <th>creatorUrl</th>\n",
       "      <th>creatorUserId</th>\n",
       "      <th>currentDatasetVersionId</th>\n",
       "      <th>currentDatasetVersionNumber</th>\n",
       "      <th>datasetId</th>\n",
       "      <th>datasetSize</th>\n",
       "      <th>datasetUrl</th>\n",
       "      <th>...</th>\n",
       "      <th>ownerUrl</th>\n",
       "      <th>ownerUserId</th>\n",
       "      <th>scriptCount</th>\n",
       "      <th>scriptsUrl</th>\n",
       "      <th>thumbnailImageUrl</th>\n",
       "      <th>title</th>\n",
       "      <th>topicCount</th>\n",
       "      <th>type</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>voteButton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'categories': [{'id': 13213, 'name': 'survey ...</td>\n",
       "      <td>[{'fileType': 'csv', 'count': 3, 'totalSize': ...</td>\n",
       "      <td>Paul Mooney</td>\n",
       "      <td>/paultimothymooney</td>\n",
       "      <td>1314380</td>\n",
       "      <td>161079</td>\n",
       "      <td>5</td>\n",
       "      <td>70947</td>\n",
       "      <td>4043536</td>\n",
       "      <td>/kaggle/kaggle-survey-2018</td>\n",
       "      <td>...</td>\n",
       "      <td>/kaggle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190</td>\n",
       "      <td>/kaggle/kaggle-survey-2018/kernels</td>\n",
       "      <td>https://storage.googleapis.com/kaggle-datasets...</td>\n",
       "      <td>2018 Kaggle ML &amp; DS Survey Challenge</td>\n",
       "      <td>12</td>\n",
       "      <td>fileset</td>\n",
       "      <td>274306</td>\n",
       "      <td>{'totalVotes': 678, 'hasAlreadyVotedUp': False...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'categories': [{'id': 13205, 'name': 'text mi...</td>\n",
       "      <td>[{'fileType': 'other', 'count': 20, 'totalSize...</td>\n",
       "      <td>Jason King</td>\n",
       "      <td>/jkkphys</td>\n",
       "      <td>459483</td>\n",
       "      <td>194523</td>\n",
       "      <td>1</td>\n",
       "      <td>83790</td>\n",
       "      <td>968989653</td>\n",
       "      <td>/jkkphys/english-wikipedia-articles-20170820-m...</td>\n",
       "      <td>...</td>\n",
       "      <td>/jkkphys</td>\n",
       "      <td>459483.0</td>\n",
       "      <td>11</td>\n",
       "      <td>/jkkphys/english-wikipedia-articles-20170820-m...</td>\n",
       "      <td>https://storage.googleapis.com/kaggle-datasets...</td>\n",
       "      <td>English Wikipedia Articles 2017-08-20 Models</td>\n",
       "      <td>0</td>\n",
       "      <td>fileset</td>\n",
       "      <td>176</td>\n",
       "      <td>{'totalVotes': 2, 'hasAlreadyVotedUp': False, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'categories': [{'id': 11102, 'name': 'busines...</td>\n",
       "      <td>[{'fileType': 'csv', 'count': 1, 'totalSize': ...</td>\n",
       "      <td>Mehdi Dagdoug</td>\n",
       "      <td>/mehdidag</td>\n",
       "      <td>1227281</td>\n",
       "      <td>59109</td>\n",
       "      <td>1</td>\n",
       "      <td>38809</td>\n",
       "      <td>5621145</td>\n",
       "      <td>/mehdidag/black-friday</td>\n",
       "      <td>...</td>\n",
       "      <td>/mehdidag</td>\n",
       "      <td>1227281.0</td>\n",
       "      <td>40</td>\n",
       "      <td>/mehdidag/black-friday/kernels</td>\n",
       "      <td>https://storage.googleapis.com/kaggle-datasets...</td>\n",
       "      <td>Black Friday</td>\n",
       "      <td>4</td>\n",
       "      <td>fileset</td>\n",
       "      <td>80770</td>\n",
       "      <td>{'totalVotes': 298, 'hasAlreadyVotedUp': False...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'categories': [{'id': 1209, 'name': 'governme...</td>\n",
       "      <td>[{'fileType': 'other', 'count': 1, 'totalSize'...</td>\n",
       "      <td>Chris Crawford</td>\n",
       "      <td>/crawford</td>\n",
       "      <td>484516</td>\n",
       "      <td>150301</td>\n",
       "      <td>18</td>\n",
       "      <td>45286</td>\n",
       "      <td>45177047</td>\n",
       "      <td>/center-for-policing-equity/data-science-for-good</td>\n",
       "      <td>...</td>\n",
       "      <td>/center-for-policing-equity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>/center-for-policing-equity/data-science-for-g...</td>\n",
       "      <td>https://storage.googleapis.com/kaggle-datasets...</td>\n",
       "      <td>Data Science for Good: Center for Policing Equity</td>\n",
       "      <td>27</td>\n",
       "      <td>fileset</td>\n",
       "      <td>52192</td>\n",
       "      <td>{'totalVotes': 282, 'hasAlreadyVotedUp': False...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'categories': [{'id': 2200, 'name': 'arts and...</td>\n",
       "      <td>[{'fileType': 'other', 'count': 2, 'totalSize'...</td>\n",
       "      <td>Danil</td>\n",
       "      <td>/thedownhill</td>\n",
       "      <td>1914606</td>\n",
       "      <td>36285</td>\n",
       "      <td>2</td>\n",
       "      <td>28335</td>\n",
       "      <td>609430422</td>\n",
       "      <td>/thedownhill/art-images-drawings-painting-scul...</td>\n",
       "      <td>...</td>\n",
       "      <td>/thedownhill</td>\n",
       "      <td>1914606.0</td>\n",
       "      <td>5</td>\n",
       "      <td>/thedownhill/art-images-drawings-painting-scul...</td>\n",
       "      <td>https://storage.googleapis.com/kaggle-datasets...</td>\n",
       "      <td>Art Images: Drawing/Painting/Sculptures/Engrav...</td>\n",
       "      <td>0</td>\n",
       "      <td>fileset</td>\n",
       "      <td>4086</td>\n",
       "      <td>{'totalVotes': 42, 'hasAlreadyVotedUp': False,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          categories  \\\n",
       "0  {'categories': [{'id': 13213, 'name': 'survey ...   \n",
       "1  {'categories': [{'id': 13205, 'name': 'text mi...   \n",
       "2  {'categories': [{'id': 11102, 'name': 'busines...   \n",
       "3  {'categories': [{'id': 1209, 'name': 'governme...   \n",
       "4  {'categories': [{'id': 2200, 'name': 'arts and...   \n",
       "\n",
       "                                     commonFileTypes     creatorName  \\\n",
       "0  [{'fileType': 'csv', 'count': 3, 'totalSize': ...     Paul Mooney   \n",
       "1  [{'fileType': 'other', 'count': 20, 'totalSize...      Jason King   \n",
       "2  [{'fileType': 'csv', 'count': 1, 'totalSize': ...   Mehdi Dagdoug   \n",
       "3  [{'fileType': 'other', 'count': 1, 'totalSize'...  Chris Crawford   \n",
       "4  [{'fileType': 'other', 'count': 2, 'totalSize'...           Danil   \n",
       "\n",
       "           creatorUrl  creatorUserId  currentDatasetVersionId  \\\n",
       "0  /paultimothymooney        1314380                   161079   \n",
       "1            /jkkphys         459483                   194523   \n",
       "2           /mehdidag        1227281                    59109   \n",
       "3           /crawford         484516                   150301   \n",
       "4        /thedownhill        1914606                    36285   \n",
       "\n",
       "   currentDatasetVersionNumber  datasetId  datasetSize  \\\n",
       "0                            5      70947      4043536   \n",
       "1                            1      83790    968989653   \n",
       "2                            1      38809      5621145   \n",
       "3                           18      45286     45177047   \n",
       "4                            2      28335    609430422   \n",
       "\n",
       "                                          datasetUrl  \\\n",
       "0                         /kaggle/kaggle-survey-2018   \n",
       "1  /jkkphys/english-wikipedia-articles-20170820-m...   \n",
       "2                             /mehdidag/black-friday   \n",
       "3  /center-for-policing-equity/data-science-for-good   \n",
       "4  /thedownhill/art-images-drawings-painting-scul...   \n",
       "\n",
       "                         ...                          \\\n",
       "0                        ...                           \n",
       "1                        ...                           \n",
       "2                        ...                           \n",
       "3                        ...                           \n",
       "4                        ...                           \n",
       "\n",
       "                      ownerUrl ownerUserId  scriptCount  \\\n",
       "0                      /kaggle         NaN          190   \n",
       "1                     /jkkphys    459483.0           11   \n",
       "2                    /mehdidag   1227281.0           40   \n",
       "3  /center-for-policing-equity         NaN           54   \n",
       "4                 /thedownhill   1914606.0            5   \n",
       "\n",
       "                                          scriptsUrl  \\\n",
       "0                 /kaggle/kaggle-survey-2018/kernels   \n",
       "1  /jkkphys/english-wikipedia-articles-20170820-m...   \n",
       "2                     /mehdidag/black-friday/kernels   \n",
       "3  /center-for-policing-equity/data-science-for-g...   \n",
       "4  /thedownhill/art-images-drawings-painting-scul...   \n",
       "\n",
       "                                   thumbnailImageUrl  \\\n",
       "0  https://storage.googleapis.com/kaggle-datasets...   \n",
       "1  https://storage.googleapis.com/kaggle-datasets...   \n",
       "2  https://storage.googleapis.com/kaggle-datasets...   \n",
       "3  https://storage.googleapis.com/kaggle-datasets...   \n",
       "4  https://storage.googleapis.com/kaggle-datasets...   \n",
       "\n",
       "                                               title  topicCount     type  \\\n",
       "0               2018 Kaggle ML & DS Survey Challenge          12  fileset   \n",
       "1       English Wikipedia Articles 2017-08-20 Models           0  fileset   \n",
       "2                                       Black Friday           4  fileset   \n",
       "3  Data Science for Good: Center for Policing Equity          27  fileset   \n",
       "4  Art Images: Drawing/Painting/Sculptures/Engrav...           0  fileset   \n",
       "\n",
       "   viewCount                                         voteButton  \n",
       "0     274306  {'totalVotes': 678, 'hasAlreadyVotedUp': False...  \n",
       "1        176  {'totalVotes': 2, 'hasAlreadyVotedUp': False, ...  \n",
       "2      80770  {'totalVotes': 298, 'hasAlreadyVotedUp': False...  \n",
       "3      52192  {'totalVotes': 282, 'hasAlreadyVotedUp': False...  \n",
       "4       4086  {'totalVotes': 42, 'hasAlreadyVotedUp': False,...  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kd= pd.read_csv(\"all_kaggle_datasets.csv\")\n",
    "kd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13020, 37)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>categories</th>\n",
       "      <td>{'categories': [{'id': 13213, 'name': 'survey ...</td>\n",
       "      <td>{'categories': [{'id': 13205, 'name': 'text mi...</td>\n",
       "      <td>{'categories': [{'id': 11102, 'name': 'busines...</td>\n",
       "      <td>{'categories': [{'id': 1209, 'name': 'governme...</td>\n",
       "      <td>{'categories': [{'id': 2200, 'name': 'arts and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commonFileTypes</th>\n",
       "      <td>[{'fileType': 'csv', 'count': 3, 'totalSize': ...</td>\n",
       "      <td>[{'fileType': 'other', 'count': 20, 'totalSize...</td>\n",
       "      <td>[{'fileType': 'csv', 'count': 1, 'totalSize': ...</td>\n",
       "      <td>[{'fileType': 'other', 'count': 1, 'totalSize'...</td>\n",
       "      <td>[{'fileType': 'other', 'count': 2, 'totalSize'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creatorName</th>\n",
       "      <td>Paul Mooney</td>\n",
       "      <td>Jason King</td>\n",
       "      <td>Mehdi Dagdoug</td>\n",
       "      <td>Chris Crawford</td>\n",
       "      <td>Danil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creatorUrl</th>\n",
       "      <td>/paultimothymooney</td>\n",
       "      <td>/jkkphys</td>\n",
       "      <td>/mehdidag</td>\n",
       "      <td>/crawford</td>\n",
       "      <td>/thedownhill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creatorUserId</th>\n",
       "      <td>1314380</td>\n",
       "      <td>459483</td>\n",
       "      <td>1227281</td>\n",
       "      <td>484516</td>\n",
       "      <td>1914606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currentDatasetVersionId</th>\n",
       "      <td>161079</td>\n",
       "      <td>194523</td>\n",
       "      <td>59109</td>\n",
       "      <td>150301</td>\n",
       "      <td>36285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currentDatasetVersionNumber</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datasetId</th>\n",
       "      <td>70947</td>\n",
       "      <td>83790</td>\n",
       "      <td>38809</td>\n",
       "      <td>45286</td>\n",
       "      <td>28335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datasetSize</th>\n",
       "      <td>4043536</td>\n",
       "      <td>968989653</td>\n",
       "      <td>5621145</td>\n",
       "      <td>45177047</td>\n",
       "      <td>609430422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datasetUrl</th>\n",
       "      <td>/kaggle/kaggle-survey-2018</td>\n",
       "      <td>/jkkphys/english-wikipedia-articles-20170820-m...</td>\n",
       "      <td>/mehdidag/black-friday</td>\n",
       "      <td>/center-for-policing-equity/data-science-for-good</td>\n",
       "      <td>/thedownhill/art-images-drawings-painting-scul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dateUpdated</th>\n",
       "      <td>2018-11-03T22:35:07.12Z</td>\n",
       "      <td>2018-11-28T17:09:32.423Z</td>\n",
       "      <td>2018-07-25T20:49:48.41Z</td>\n",
       "      <td>2018-10-29T23:55:11.713Z</td>\n",
       "      <td>2018-05-25T18:00:50.393Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diffType</th>\n",
       "      <td>unversioned</td>\n",
       "      <td>versioned</td>\n",
       "      <td>versioned</td>\n",
       "      <td>unversioned</td>\n",
       "      <td>versioned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>downloadCount</th>\n",
       "      <td>5506</td>\n",
       "      <td>7</td>\n",
       "      <td>14066</td>\n",
       "      <td>2573</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forumUrl</th>\n",
       "      <td>/kaggle/kaggle-survey-2018/discussion</td>\n",
       "      <td>/jkkphys/english-wikipedia-articles-20170820-m...</td>\n",
       "      <td>/mehdidag/black-friday/discussion</td>\n",
       "      <td>/center-for-policing-equity/data-science-for-g...</td>\n",
       "      <td>/thedownhill/art-images-drawings-painting-scul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isCollaborator</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isDeleted</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isFailed</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isFeatured</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isHidden</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isPrivate</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isSuperFeatured</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>licenseName</th>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>CC0: Public Domain</td>\n",
       "      <td>CC0: Public Domain</td>\n",
       "      <td>Database: Open Database, Contents: Â© Original ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>licenseShortName</th>\n",
       "      <td>CC4</td>\n",
       "      <td>CC3</td>\n",
       "      <td>CC0</td>\n",
       "      <td>CC0</td>\n",
       "      <td>ODbL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maintainerOrganization</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overview</th>\n",
       "      <td>Explore the 2018 Kaggle ML &amp; Data Science Surv...</td>\n",
       "      <td>Gensim models trained on English Wikipedia Art...</td>\n",
       "      <td>A study of sales trough consumer behaviours</td>\n",
       "      <td>How do you measure justice?</td>\n",
       "      <td>Dataset with about 9000 images containing 5 ty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ownerAvatarUrl</th>\n",
       "      <td>https://storage.googleapis.com/kaggle-organiza...</td>\n",
       "      <td>https://storage.googleapis.com/kaggle-avatars/...</td>\n",
       "      <td>https://storage.googleapis.com/kaggle-avatars/...</td>\n",
       "      <td>https://storage.googleapis.com/kaggle-organiza...</td>\n",
       "      <td>https://storage.googleapis.com/kaggle-avatars/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ownerName</th>\n",
       "      <td>Kaggle</td>\n",
       "      <td>Jason King</td>\n",
       "      <td>Mehdi Dagdoug</td>\n",
       "      <td>Center for Policing Equity</td>\n",
       "      <td>Danil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ownerUrl</th>\n",
       "      <td>/kaggle</td>\n",
       "      <td>/jkkphys</td>\n",
       "      <td>/mehdidag</td>\n",
       "      <td>/center-for-policing-equity</td>\n",
       "      <td>/thedownhill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ownerUserId</th>\n",
       "      <td>NaN</td>\n",
       "      <td>459483</td>\n",
       "      <td>1.22728e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.91461e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scriptCount</th>\n",
       "      <td>190</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scriptsUrl</th>\n",
       "      <td>/kaggle/kaggle-survey-2018/kernels</td>\n",
       "      <td>/jkkphys/english-wikipedia-articles-20170820-m...</td>\n",
       "      <td>/mehdidag/black-friday/kernels</td>\n",
       "      <td>/center-for-policing-equity/data-science-for-g...</td>\n",
       "      <td>/thedownhill/art-images-drawings-painting-scul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thumbnailImageUrl</th>\n",
       "      <td>https://storage.googleapis.com/kaggle-datasets...</td>\n",
       "      <td>https://storage.googleapis.com/kaggle-datasets...</td>\n",
       "      <td>https://storage.googleapis.com/kaggle-datasets...</td>\n",
       "      <td>https://storage.googleapis.com/kaggle-datasets...</td>\n",
       "      <td>https://storage.googleapis.com/kaggle-datasets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>2018 Kaggle ML &amp; DS Survey Challenge</td>\n",
       "      <td>English Wikipedia Articles 2017-08-20 Models</td>\n",
       "      <td>Black Friday</td>\n",
       "      <td>Data Science for Good: Center for Policing Equity</td>\n",
       "      <td>Art Images: Drawing/Painting/Sculptures/Engrav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topicCount</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>fileset</td>\n",
       "      <td>fileset</td>\n",
       "      <td>fileset</td>\n",
       "      <td>fileset</td>\n",
       "      <td>fileset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viewCount</th>\n",
       "      <td>274306</td>\n",
       "      <td>176</td>\n",
       "      <td>80770</td>\n",
       "      <td>52192</td>\n",
       "      <td>4086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voteButton</th>\n",
       "      <td>{'totalVotes': 678, 'hasAlreadyVotedUp': False...</td>\n",
       "      <td>{'totalVotes': 2, 'hasAlreadyVotedUp': False, ...</td>\n",
       "      <td>{'totalVotes': 298, 'hasAlreadyVotedUp': False...</td>\n",
       "      <td>{'totalVotes': 282, 'hasAlreadyVotedUp': False...</td>\n",
       "      <td>{'totalVotes': 42, 'hasAlreadyVotedUp': False,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             0  \\\n",
       "categories                   {'categories': [{'id': 13213, 'name': 'survey ...   \n",
       "commonFileTypes              [{'fileType': 'csv', 'count': 3, 'totalSize': ...   \n",
       "creatorName                                                        Paul Mooney   \n",
       "creatorUrl                                                  /paultimothymooney   \n",
       "creatorUserId                                                          1314380   \n",
       "currentDatasetVersionId                                                 161079   \n",
       "currentDatasetVersionNumber                                                  5   \n",
       "datasetId                                                                70947   \n",
       "datasetSize                                                            4043536   \n",
       "datasetUrl                                          /kaggle/kaggle-survey-2018   \n",
       "dateUpdated                                            2018-11-03T22:35:07.12Z   \n",
       "diffType                                                           unversioned   \n",
       "downloadCount                                                             5506   \n",
       "forumUrl                                 /kaggle/kaggle-survey-2018/discussion   \n",
       "isCollaborator                                                           False   \n",
       "isDeleted                                                                False   \n",
       "isFailed                                                                 False   \n",
       "isFeatured                                                                True   \n",
       "isHidden                                                                 False   \n",
       "isPrivate                                                                False   \n",
       "isSuperFeatured                                                           True   \n",
       "licenseName                                                       CC BY-SA 4.0   \n",
       "licenseShortName                                                           CC4   \n",
       "maintainerOrganization                                                     NaN   \n",
       "overview                     Explore the 2018 Kaggle ML & Data Science Surv...   \n",
       "ownerAvatarUrl               https://storage.googleapis.com/kaggle-organiza...   \n",
       "ownerName                                                               Kaggle   \n",
       "ownerUrl                                                               /kaggle   \n",
       "ownerUserId                                                                NaN   \n",
       "scriptCount                                                                190   \n",
       "scriptsUrl                                  /kaggle/kaggle-survey-2018/kernels   \n",
       "thumbnailImageUrl            https://storage.googleapis.com/kaggle-datasets...   \n",
       "title                                     2018 Kaggle ML & DS Survey Challenge   \n",
       "topicCount                                                                  12   \n",
       "type                                                                   fileset   \n",
       "viewCount                                                               274306   \n",
       "voteButton                   {'totalVotes': 678, 'hasAlreadyVotedUp': False...   \n",
       "\n",
       "                                                                             1  \\\n",
       "categories                   {'categories': [{'id': 13205, 'name': 'text mi...   \n",
       "commonFileTypes              [{'fileType': 'other', 'count': 20, 'totalSize...   \n",
       "creatorName                                                         Jason King   \n",
       "creatorUrl                                                            /jkkphys   \n",
       "creatorUserId                                                           459483   \n",
       "currentDatasetVersionId                                                 194523   \n",
       "currentDatasetVersionNumber                                                  1   \n",
       "datasetId                                                                83790   \n",
       "datasetSize                                                          968989653   \n",
       "datasetUrl                   /jkkphys/english-wikipedia-articles-20170820-m...   \n",
       "dateUpdated                                           2018-11-28T17:09:32.423Z   \n",
       "diffType                                                             versioned   \n",
       "downloadCount                                                                7   \n",
       "forumUrl                     /jkkphys/english-wikipedia-articles-20170820-m...   \n",
       "isCollaborator                                                           False   \n",
       "isDeleted                                                                False   \n",
       "isFailed                                                                 False   \n",
       "isFeatured                                                                True   \n",
       "isHidden                                                                 False   \n",
       "isPrivate                                                                False   \n",
       "isSuperFeatured                                                           True   \n",
       "licenseName                                                       CC BY-SA 3.0   \n",
       "licenseShortName                                                           CC3   \n",
       "maintainerOrganization                                                     NaN   \n",
       "overview                     Gensim models trained on English Wikipedia Art...   \n",
       "ownerAvatarUrl               https://storage.googleapis.com/kaggle-avatars/...   \n",
       "ownerName                                                           Jason King   \n",
       "ownerUrl                                                              /jkkphys   \n",
       "ownerUserId                                                             459483   \n",
       "scriptCount                                                                 11   \n",
       "scriptsUrl                   /jkkphys/english-wikipedia-articles-20170820-m...   \n",
       "thumbnailImageUrl            https://storage.googleapis.com/kaggle-datasets...   \n",
       "title                             English Wikipedia Articles 2017-08-20 Models   \n",
       "topicCount                                                                   0   \n",
       "type                                                                   fileset   \n",
       "viewCount                                                                  176   \n",
       "voteButton                   {'totalVotes': 2, 'hasAlreadyVotedUp': False, ...   \n",
       "\n",
       "                                                                             2  \\\n",
       "categories                   {'categories': [{'id': 11102, 'name': 'busines...   \n",
       "commonFileTypes              [{'fileType': 'csv', 'count': 1, 'totalSize': ...   \n",
       "creatorName                                                      Mehdi Dagdoug   \n",
       "creatorUrl                                                           /mehdidag   \n",
       "creatorUserId                                                          1227281   \n",
       "currentDatasetVersionId                                                  59109   \n",
       "currentDatasetVersionNumber                                                  1   \n",
       "datasetId                                                                38809   \n",
       "datasetSize                                                            5621145   \n",
       "datasetUrl                                              /mehdidag/black-friday   \n",
       "dateUpdated                                            2018-07-25T20:49:48.41Z   \n",
       "diffType                                                             versioned   \n",
       "downloadCount                                                            14066   \n",
       "forumUrl                                     /mehdidag/black-friday/discussion   \n",
       "isCollaborator                                                           False   \n",
       "isDeleted                                                                False   \n",
       "isFailed                                                                 False   \n",
       "isFeatured                                                                True   \n",
       "isHidden                                                                 False   \n",
       "isPrivate                                                                False   \n",
       "isSuperFeatured                                                           True   \n",
       "licenseName                                                 CC0: Public Domain   \n",
       "licenseShortName                                                           CC0   \n",
       "maintainerOrganization                                                     NaN   \n",
       "overview                           A study of sales trough consumer behaviours   \n",
       "ownerAvatarUrl               https://storage.googleapis.com/kaggle-avatars/...   \n",
       "ownerName                                                        Mehdi Dagdoug   \n",
       "ownerUrl                                                             /mehdidag   \n",
       "ownerUserId                                                        1.22728e+06   \n",
       "scriptCount                                                                 40   \n",
       "scriptsUrl                                      /mehdidag/black-friday/kernels   \n",
       "thumbnailImageUrl            https://storage.googleapis.com/kaggle-datasets...   \n",
       "title                                                             Black Friday   \n",
       "topicCount                                                                   4   \n",
       "type                                                                   fileset   \n",
       "viewCount                                                                80770   \n",
       "voteButton                   {'totalVotes': 298, 'hasAlreadyVotedUp': False...   \n",
       "\n",
       "                                                                             3  \\\n",
       "categories                   {'categories': [{'id': 1209, 'name': 'governme...   \n",
       "commonFileTypes              [{'fileType': 'other', 'count': 1, 'totalSize'...   \n",
       "creatorName                                                     Chris Crawford   \n",
       "creatorUrl                                                           /crawford   \n",
       "creatorUserId                                                           484516   \n",
       "currentDatasetVersionId                                                 150301   \n",
       "currentDatasetVersionNumber                                                 18   \n",
       "datasetId                                                                45286   \n",
       "datasetSize                                                           45177047   \n",
       "datasetUrl                   /center-for-policing-equity/data-science-for-good   \n",
       "dateUpdated                                           2018-10-29T23:55:11.713Z   \n",
       "diffType                                                           unversioned   \n",
       "downloadCount                                                             2573   \n",
       "forumUrl                     /center-for-policing-equity/data-science-for-g...   \n",
       "isCollaborator                                                           False   \n",
       "isDeleted                                                                False   \n",
       "isFailed                                                                 False   \n",
       "isFeatured                                                                True   \n",
       "isHidden                                                                 False   \n",
       "isPrivate                                                                False   \n",
       "isSuperFeatured                                                           True   \n",
       "licenseName                                                 CC0: Public Domain   \n",
       "licenseShortName                                                           CC0   \n",
       "maintainerOrganization                                                     NaN   \n",
       "overview                                           How do you measure justice?   \n",
       "ownerAvatarUrl               https://storage.googleapis.com/kaggle-organiza...   \n",
       "ownerName                                           Center for Policing Equity   \n",
       "ownerUrl                                           /center-for-policing-equity   \n",
       "ownerUserId                                                                NaN   \n",
       "scriptCount                                                                 54   \n",
       "scriptsUrl                   /center-for-policing-equity/data-science-for-g...   \n",
       "thumbnailImageUrl            https://storage.googleapis.com/kaggle-datasets...   \n",
       "title                        Data Science for Good: Center for Policing Equity   \n",
       "topicCount                                                                  27   \n",
       "type                                                                   fileset   \n",
       "viewCount                                                                52192   \n",
       "voteButton                   {'totalVotes': 282, 'hasAlreadyVotedUp': False...   \n",
       "\n",
       "                                                                             4  \n",
       "categories                   {'categories': [{'id': 2200, 'name': 'arts and...  \n",
       "commonFileTypes              [{'fileType': 'other', 'count': 2, 'totalSize'...  \n",
       "creatorName                                                              Danil  \n",
       "creatorUrl                                                        /thedownhill  \n",
       "creatorUserId                                                          1914606  \n",
       "currentDatasetVersionId                                                  36285  \n",
       "currentDatasetVersionNumber                                                  2  \n",
       "datasetId                                                                28335  \n",
       "datasetSize                                                          609430422  \n",
       "datasetUrl                   /thedownhill/art-images-drawings-painting-scul...  \n",
       "dateUpdated                                           2018-05-25T18:00:50.393Z  \n",
       "diffType                                                             versioned  \n",
       "downloadCount                                                              517  \n",
       "forumUrl                     /thedownhill/art-images-drawings-painting-scul...  \n",
       "isCollaborator                                                           False  \n",
       "isDeleted                                                                False  \n",
       "isFailed                                                                 False  \n",
       "isFeatured                                                                True  \n",
       "isHidden                                                                 False  \n",
       "isPrivate                                                                False  \n",
       "isSuperFeatured                                                           True  \n",
       "licenseName                  Database: Open Database, Contents: Â© Original ...  \n",
       "licenseShortName                                                          ODbL  \n",
       "maintainerOrganization                                                     NaN  \n",
       "overview                     Dataset with about 9000 images containing 5 ty...  \n",
       "ownerAvatarUrl               https://storage.googleapis.com/kaggle-avatars/...  \n",
       "ownerName                                                                Danil  \n",
       "ownerUrl                                                          /thedownhill  \n",
       "ownerUserId                                                        1.91461e+06  \n",
       "scriptCount                                                                  5  \n",
       "scriptsUrl                   /thedownhill/art-images-drawings-painting-scul...  \n",
       "thumbnailImageUrl            https://storage.googleapis.com/kaggle-datasets...  \n",
       "title                        Art Images: Drawing/Painting/Sculptures/Engrav...  \n",
       "topicCount                                                                   0  \n",
       "type                                                                   fileset  \n",
       "viewCount                                                                 4086  \n",
       "voteButton                   {'totalVotes': 42, 'hasAlreadyVotedUp': False,...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KD.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2c4e4845e48>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_mat = KD.corr(method='pearson')\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(corr_mat,vmax=1,square=True,annot=True,cmap='cubehelix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DataFrame in module pandas.core.frame object:\n",
      "\n",
      "class DataFrame(pandas.core.generic.NDFrame)\n",
      " |  DataFrame(data=None, index=None, columns=None, dtype=None, copy=False)\n",
      " |  \n",
      " |  Two-dimensional size-mutable, potentially heterogeneous tabular data\n",
      " |  structure with labeled axes (rows and columns). Arithmetic operations\n",
      " |  align on both row and column labels. Can be thought of as a dict-like\n",
      " |  container for Series objects. The primary pandas data structure.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  data : numpy ndarray (structured or homogeneous), dict, or DataFrame\n",
      " |      Dict can contain Series, arrays, constants, or list-like objects\n",
      " |  \n",
      " |      .. versionchanged :: 0.23.0\n",
      " |         If data is a dict, argument order is maintained for Python 3.6\n",
      " |         and later.\n",
      " |  \n",
      " |  index : Index or array-like\n",
      " |      Index to use for resulting frame. Will default to RangeIndex if\n",
      " |      no indexing information part of input data and no index provided\n",
      " |  columns : Index or array-like\n",
      " |      Column labels to use for resulting frame. Will default to\n",
      " |      RangeIndex (0, 1, 2, ..., n) if no column labels are provided\n",
      " |  dtype : dtype, default None\n",
      " |      Data type to force. Only a single dtype is allowed. If None, infer\n",
      " |  copy : boolean, default False\n",
      " |      Copy data from inputs. Only affects DataFrame / 2d ndarray input\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  Constructing DataFrame from a dictionary.\n",
      " |  \n",
      " |  >>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |  >>> df = pd.DataFrame(data=d)\n",
      " |  >>> df\n",
      " |     col1  col2\n",
      " |  0     1     3\n",
      " |  1     2     4\n",
      " |  \n",
      " |  Notice that the inferred dtype is int64.\n",
      " |  \n",
      " |  >>> df.dtypes\n",
      " |  col1    int64\n",
      " |  col2    int64\n",
      " |  dtype: object\n",
      " |  \n",
      " |  To enforce a single dtype:\n",
      " |  \n",
      " |  >>> df = pd.DataFrame(data=d, dtype=np.int8)\n",
      " |  >>> df.dtypes\n",
      " |  col1    int8\n",
      " |  col2    int8\n",
      " |  dtype: object\n",
      " |  \n",
      " |  Constructing DataFrame from numpy ndarray:\n",
      " |  \n",
      " |  >>> df2 = pd.DataFrame(np.random.randint(low=0, high=10, size=(5, 5)),\n",
      " |  ...                    columns=['a', 'b', 'c', 'd', 'e'])\n",
      " |  >>> df2\n",
      " |      a   b   c   d   e\n",
      " |  0   2   8   8   3   4\n",
      " |  1   4   2   9   0   9\n",
      " |  2   1   0   7   8   0\n",
      " |  3   5   1   7   1   3\n",
      " |  4   6   0   2   4   2\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  DataFrame.from_records : constructor from tuples, also record arrays\n",
      " |  DataFrame.from_dict : from dicts of Series, arrays, or dicts\n",
      " |  DataFrame.from_items : from sequence of (key, value) pairs\n",
      " |  pandas.read_csv, pandas.read_table, pandas.read_clipboard\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DataFrame\n",
      " |      pandas.core.generic.NDFrame\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.base.StringMixin\n",
      " |      pandas.core.accessor.DirNamesMixin\n",
      " |      pandas.core.base.SelectionMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __add__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __and__(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator __and__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __div__ = __truediv__(self, other, axis=None, level=None, fill_value=None)\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Wrapper for comparison method __eq__\n",
      " |  \n",
      " |  __floordiv__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __floordiv__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __ge__(self, other)\n",
      " |      Wrapper for comparison method __ge__\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  __gt__(self, other)\n",
      " |      Wrapper for comparison method __gt__\n",
      " |  \n",
      " |  __iadd__ = f(self, other)\n",
      " |  \n",
      " |  __iand__ = f(self, other)\n",
      " |  \n",
      " |  __ifloordiv__ = f(self, other)\n",
      " |  \n",
      " |  __imod__ = f(self, other)\n",
      " |  \n",
      " |  __imul__ = f(self, other)\n",
      " |  \n",
      " |  __init__(self, data=None, index=None, columns=None, dtype=None, copy=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __ior__ = f(self, other)\n",
      " |  \n",
      " |  __ipow__ = f(self, other)\n",
      " |  \n",
      " |  __isub__ = f(self, other)\n",
      " |  \n",
      " |  __itruediv__ = f(self, other)\n",
      " |  \n",
      " |  __ixor__ = f(self, other)\n",
      " |  \n",
      " |  __le__(self, other)\n",
      " |      Wrapper for comparison method __le__\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Returns length of info axis, but here we use the index\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |      Wrapper for comparison method __lt__\n",
      " |  \n",
      " |  __matmul__(self, other)\n",
      " |      Matrix multiplication using binary `@` operator in Python>=3.5\n",
      " |  \n",
      " |  __mod__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __mod__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __mul__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __mul__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Wrapper for comparison method __ne__\n",
      " |  \n",
      " |  __or__(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator __or__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __pow__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __pow__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __radd__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __radd__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __rand__(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator __rand__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __rdiv__ = __rtruediv__(self, other, axis=None, level=None, fill_value=None)\n",
      " |  \n",
      " |  __rfloordiv__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __rfloordiv__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __rmatmul__(self, other)\n",
      " |      Matrix multiplication using binary `@` operator in Python>=3.5\n",
      " |  \n",
      " |  __rmod__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __rmod__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __rmul__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __rmul__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __ror__(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator __ror__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __rpow__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __rpow__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __rsub__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __rsub__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __rtruediv__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __rtruediv__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __rxor__(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator __rxor__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |  \n",
      " |  __sub__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __sub__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __truediv__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __truediv__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __unicode__(self)\n",
      " |      Return a string representation for a particular DataFrame\n",
      " |      \n",
      " |      Invoked by unicode(df) in py2 only. Yields a Unicode String in both\n",
      " |      py2/py3.\n",
      " |  \n",
      " |  __xor__(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator __xor__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  add(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Addition of dataframe and other, element-wise (binary operator `add`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe + other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> a = pd.DataFrame([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'],\n",
      " |      ...                  columns=['one'])\n",
      " |      >>> a\n",
      " |         one\n",
      " |      a  1.0\n",
      " |      b  1.0\n",
      " |      c  1.0\n",
      " |      d  NaN\n",
      " |      >>> b = pd.DataFrame(dict(one=[1, np.nan, 1, np.nan],\n",
      " |      ...                       two=[np.nan, 2, np.nan, 2]),\n",
      " |      ...                  index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |         one  two\n",
      " |      a  1.0  NaN\n",
      " |      b  NaN  2.0\n",
      " |      d  1.0  NaN\n",
      " |      e  NaN  2.0\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |         one  two\n",
      " |      a  2.0  NaN\n",
      " |      b  1.0  2.0\n",
      " |      c  1.0  NaN\n",
      " |      d  1.0  NaN\n",
      " |      e  NaN  2.0\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.radd\n",
      " |  \n",
      " |  agg = aggregate(self, func, axis=0, *args, **kwargs)\n",
      " |  \n",
      " |  aggregate(self, func, axis=0, *args, **kwargs)\n",
      " |      Aggregate using one or more operations over the specified axis.\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, string, dictionary, or list of string/functions\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a DataFrame or when passed to DataFrame.apply. For\n",
      " |          a DataFrame, can pass a dict, if the keys are DataFrame column names.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - string function name.\n",
      " |          - function.\n",
      " |          - list of functions.\n",
      " |          - dict of column names -> functions (or list of functions).\n",
      " |      \n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          - 0 or 'index': apply function to each column.\n",
      " |          - 1 or 'columns': apply function to each row.\n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      aggregated : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |      \n",
      " |      A passed user-defined-function will be passed a Series for evaluation.\n",
      " |      \n",
      " |      The aggregation operations are always performed over an axis, either the\n",
      " |      index (default) or the column axis. This behavior is different from\n",
      " |      `numpy` aggregation functions (`mean`, `median`, `prod`, `sum`, `std`,\n",
      " |      `var`), where the default is to compute the aggregation of the flattened\n",
      " |      array, e.g., ``numpy.mean(arr_2d)`` as opposed to ``numpy.mean(arr_2d,\n",
      " |      axis=0)``.\n",
      " |      \n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[1, 2, 3],\n",
      " |      ...                    [4, 5, 6],\n",
      " |      ...                    [7, 8, 9],\n",
      " |      ...                    [np.nan, np.nan, np.nan]],\n",
      " |      ...                   columns=['A', 'B', 'C'])\n",
      " |      \n",
      " |      Aggregate these functions over the rows.\n",
      " |      \n",
      " |      >>> df.agg(['sum', 'min'])\n",
      " |              A     B     C\n",
      " |      sum  12.0  15.0  18.0\n",
      " |      min   1.0   2.0   3.0\n",
      " |      \n",
      " |      Different aggregations per column.\n",
      " |      \n",
      " |      >>> df.agg({'A' : ['sum', 'min'], 'B' : ['min', 'max']})\n",
      " |              A    B\n",
      " |      max   NaN  8.0\n",
      " |      min   1.0  2.0\n",
      " |      sum  12.0  NaN\n",
      " |      \n",
      " |      Aggregate over the columns.\n",
      " |      \n",
      " |      >>> df.agg(\"mean\", axis=\"columns\")\n",
      " |      0    2.0\n",
      " |      1    5.0\n",
      " |      2    8.0\n",
      " |      3    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.apply : Perform any type of operations.\n",
      " |      DataFrame.transform : Perform transformation type operations.\n",
      " |      pandas.core.groupby.GroupBy : Perform operations over groups.\n",
      " |      pandas.core.resample.Resampler : Perform operations over resampled bins.\n",
      " |      pandas.core.window.Rolling : Perform operations over rolling window.\n",
      " |      pandas.core.window.Expanding : Perform operations over expanding window.\n",
      " |      pandas.core.window.EWM : Perform operation over exponential weighted\n",
      " |          window.\n",
      " |  \n",
      " |  align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0, broadcast_axis=None)\n",
      " |      Align two objects on their axes with the\n",
      " |      specified join method for each axis Index\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series\n",
      " |      join : {'outer', 'inner', 'left', 'right'}, default 'outer'\n",
      " |      axis : allowed axis of the other object, default None\n",
      " |          Align on index (0), columns (1), or both (None)\n",
      " |      level : int or level name, default None\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      copy : boolean, default True\n",
      " |          Always returns new objects. If copy=False and no reindexing is\n",
      " |          required then original objects are returned.\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value\n",
      " |      method : str, default None\n",
      " |      limit : int, default None\n",
      " |      fill_axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Filling axis, method and limit\n",
      " |      broadcast_axis : {0 or 'index', 1 or 'columns'}, default None\n",
      " |          Broadcast values along this axis, if aligning two objects of\n",
      " |          different dimensions\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      (left, right) : (DataFrame, type of other)\n",
      " |          Aligned objects\n",
      " |  \n",
      " |  all(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs)\n",
      " |      Return whether all elements are True, potentially over an axis.\n",
      " |      \n",
      " |      Returns True if all elements within a series or along a Dataframe\n",
      " |      axis are non-zero, not-empty or not-False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced.\n",
      " |      \n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |      \n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      bool_only : boolean, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      all : Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.all : Return True if all elements are True\n",
      " |      pandas.DataFrame.any : Return True if one (or more) elements are True\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Series\n",
      " |      \n",
      " |      >>> pd.Series([True, True]).all()\n",
      " |      True\n",
      " |      >>> pd.Series([True, False]).all()\n",
      " |      False\n",
      " |      \n",
      " |      DataFrames\n",
      " |      \n",
      " |      Create a dataframe from a dictionary.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [True, True], 'col2': [True, False]})\n",
      " |      >>> df\n",
      " |         col1   col2\n",
      " |      0  True   True\n",
      " |      1  True  False\n",
      " |      \n",
      " |      Default behaviour checks if column-wise values all return True.\n",
      " |      \n",
      " |      >>> df.all()\n",
      " |      col1     True\n",
      " |      col2    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Specify ``axis='columns'`` to check if row-wise values all return True.\n",
      " |      \n",
      " |      >>> df.all(axis='columns')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Or ``axis=None`` for whether every value is True.\n",
      " |      \n",
      " |      >>> df.all(axis=None)\n",
      " |      False\n",
      " |  \n",
      " |  any(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs)\n",
      " |      Return whether any element is True over requested axis.\n",
      " |      \n",
      " |      Unlike :meth:`DataFrame.all`, this performs an *or* operation. If any of the\n",
      " |      values along the specified axis is True, this will return True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced.\n",
      " |      \n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |      \n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      bool_only : boolean, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      any : Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.all : Return whether all elements are True.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      For Series input, the output is a scalar indicating whether any element\n",
      " |      is True.\n",
      " |      \n",
      " |      >>> pd.Series([True, False]).any()\n",
      " |      True\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      Whether each column contains at least one True element (the default).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [0, 2], \"C\": [0, 0]})\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      0  1  0  0\n",
      " |      1  2  2  0\n",
      " |      \n",
      " |      >>> df.any()\n",
      " |      A     True\n",
      " |      B     True\n",
      " |      C    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Aggregating over the columns.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 2]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  2\n",
      " |      \n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 0]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  0\n",
      " |      \n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Aggregating over the entire DataFrame with ``axis=None``.\n",
      " |      \n",
      " |      >>> df.any(axis=None)\n",
      " |      True\n",
      " |      \n",
      " |      `any` for an empty DataFrame is an empty Series.\n",
      " |      \n",
      " |      >>> pd.DataFrame([]).any()\n",
      " |      Series([], dtype: bool)\n",
      " |  \n",
      " |  append(self, other, ignore_index=False, verify_integrity=False, sort=None)\n",
      " |      Append rows of `other` to the end of this frame, returning a new\n",
      " |      object. Columns not in this frame are added as new columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series/dict-like object, or list of these\n",
      " |          The data to append.\n",
      " |      ignore_index : boolean, default False\n",
      " |          If True, do not use the index labels.\n",
      " |      verify_integrity : boolean, default False\n",
      " |          If True, raise ValueError on creating index with duplicates.\n",
      " |      sort : boolean, default None\n",
      " |          Sort columns if the columns of `self` and `other` are not aligned.\n",
      " |          The default sorting is deprecated and will change to not-sorting\n",
      " |          in a future version of pandas. Explicitly pass ``sort=True`` to\n",
      " |          silence the warning and sort. Explicitly pass ``sort=False`` to\n",
      " |          silence the warning and not sort.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      appended : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If a list of dict/series is passed and the keys are all contained in\n",
      " |      the DataFrame's index, the order of the columns in the resulting\n",
      " |      DataFrame will be unchanged.\n",
      " |      \n",
      " |      Iteratively appending rows to a DataFrame can be more computationally\n",
      " |      intensive than a single concatenate. A better solution is to append\n",
      " |      those rows to a list and then concatenate the list with the original\n",
      " |      DataFrame all at once.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.concat : General function to concatenate DataFrame, Series\n",
      " |          or Panel objects\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'))\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      >>> df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'))\n",
      " |      >>> df.append(df2)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      0  5  6\n",
      " |      1  7  8\n",
      " |      \n",
      " |      With `ignore_index` set to True:\n",
      " |      \n",
      " |      >>> df.append(df2, ignore_index=True)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      2  5  6\n",
      " |      3  7  8\n",
      " |      \n",
      " |      The following, while not recommended methods for generating DataFrames,\n",
      " |      show two ways to generate a DataFrame from multiple data sources.\n",
      " |      \n",
      " |      Less efficient:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(columns=['A'])\n",
      " |      >>> for i in range(5):\n",
      " |      ...     df = df.append({'A': i}, ignore_index=True)\n",
      " |      >>> df\n",
      " |         A\n",
      " |      0  0\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |      4  4\n",
      " |      \n",
      " |      More efficient:\n",
      " |      \n",
      " |      >>> pd.concat([pd.DataFrame([i], columns=['A']) for i in range(5)],\n",
      " |      ...           ignore_index=True)\n",
      " |         A\n",
      " |      0  0\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |      4  4\n",
      " |  \n",
      " |  apply(self, func, axis=0, broadcast=None, raw=False, reduce=None, result_type=None, args=(), **kwds)\n",
      " |      Apply a function along an axis of the DataFrame.\n",
      " |      \n",
      " |      Objects passed to the function are Series objects whose index is\n",
      " |      either the DataFrame's index (``axis=0``) or the DataFrame's columns\n",
      " |      (``axis=1``). By default (``result_type=None``), the final return type\n",
      " |      is inferred from the return type of the applied function. Otherwise,\n",
      " |      it depends on the `result_type` argument.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Function to apply to each column or row.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis along which the function is applied:\n",
      " |      \n",
      " |          * 0 or 'index': apply function to each column.\n",
      " |          * 1 or 'columns': apply function to each row.\n",
      " |      broadcast : bool, optional\n",
      " |          Only relevant for aggregation functions:\n",
      " |      \n",
      " |          * ``False`` or ``None`` : returns a Series whose length is the\n",
      " |            length of the index or the number of columns (based on the\n",
      " |            `axis` parameter)\n",
      " |          * ``True`` : results will be broadcast to the original shape\n",
      " |            of the frame, the original index and columns will be retained.\n",
      " |      \n",
      " |          .. deprecated:: 0.23.0\n",
      " |             This argument will be removed in a future version, replaced\n",
      " |             by result_type='broadcast'.\n",
      " |      \n",
      " |      raw : bool, default False\n",
      " |          * ``False`` : passes each row or column as a Series to the\n",
      " |            function.\n",
      " |          * ``True`` : the passed function will receive ndarray objects\n",
      " |            instead.\n",
      " |            If you are just applying a NumPy reduction function this will\n",
      " |            achieve much better performance.\n",
      " |      reduce : bool or None, default None\n",
      " |          Try to apply reduction procedures. If the DataFrame is empty,\n",
      " |          `apply` will use `reduce` to determine whether the result\n",
      " |          should be a Series or a DataFrame. If ``reduce=None`` (the\n",
      " |          default), `apply`'s return value will be guessed by calling\n",
      " |          `func` on an empty Series\n",
      " |          (note: while guessing, exceptions raised by `func` will be\n",
      " |          ignored).\n",
      " |          If ``reduce=True`` a Series will always be returned, and if\n",
      " |          ``reduce=False`` a DataFrame will always be returned.\n",
      " |      \n",
      " |          .. deprecated:: 0.23.0\n",
      " |             This argument will be removed in a future version, replaced\n",
      " |             by ``result_type='reduce'``.\n",
      " |      \n",
      " |      result_type : {'expand', 'reduce', 'broadcast', None}, default None\n",
      " |          These only act when ``axis=1`` (columns):\n",
      " |      \n",
      " |          * 'expand' : list-like results will be turned into columns.\n",
      " |          * 'reduce' : returns a Series if possible rather than expanding\n",
      " |            list-like results. This is the opposite of 'expand'.\n",
      " |          * 'broadcast' : results will be broadcast to the original shape\n",
      " |            of the DataFrame, the original index and columns will be\n",
      " |            retained.\n",
      " |      \n",
      " |          The default behaviour (None) depends on the return value of the\n",
      " |          applied function: list-like results will be returned as a Series\n",
      " |          of those. However if the apply function returns a Series these\n",
      " |          are expanded to columns.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      args : tuple\n",
      " |          Positional arguments to pass to `func` in addition to the\n",
      " |          array/series.\n",
      " |      **kwds\n",
      " |          Additional keyword arguments to pass as keywords arguments to\n",
      " |          `func`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      In the current implementation apply calls `func` twice on the\n",
      " |      first column/row to decide whether it can take a fast or slow\n",
      " |      code path. This can lead to unexpected behavior if `func` has\n",
      " |      side-effects, as they will take effect twice for the first\n",
      " |      column/row.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.applymap: For elementwise operations\n",
      " |      DataFrame.aggregate: only perform aggregating type operations\n",
      " |      DataFrame.transform: only perform transformating type operations\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[4, 9],] * 3, columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  4  9\n",
      " |      1  4  9\n",
      " |      2  4  9\n",
      " |      \n",
      " |      Using a numpy universal function (in this case the same as\n",
      " |      ``np.sqrt(df)``):\n",
      " |      \n",
      " |      >>> df.apply(np.sqrt)\n",
      " |           A    B\n",
      " |      0  2.0  3.0\n",
      " |      1  2.0  3.0\n",
      " |      2  2.0  3.0\n",
      " |      \n",
      " |      Using a reducing function on either axis\n",
      " |      \n",
      " |      >>> df.apply(np.sum, axis=0)\n",
      " |      A    12\n",
      " |      B    27\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.apply(np.sum, axis=1)\n",
      " |      0    13\n",
      " |      1    13\n",
      " |      2    13\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Retuning a list-like will result in a Series\n",
      " |      \n",
      " |      >>> df.apply(lambda x: [1, 2], axis=1)\n",
      " |      0    [1, 2]\n",
      " |      1    [1, 2]\n",
      " |      2    [1, 2]\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Passing result_type='expand' will expand list-like results\n",
      " |      to columns of a Dataframe\n",
      " |      \n",
      " |      >>> df.apply(lambda x: [1, 2], axis=1, result_type='expand')\n",
      " |         0  1\n",
      " |      0  1  2\n",
      " |      1  1  2\n",
      " |      2  1  2\n",
      " |      \n",
      " |      Returning a Series inside the function is similar to passing\n",
      " |      ``result_type='expand'``. The resulting column names\n",
      " |      will be the Series index.\n",
      " |      \n",
      " |      >>> df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)\n",
      " |         foo  bar\n",
      " |      0    1    2\n",
      " |      1    1    2\n",
      " |      2    1    2\n",
      " |      \n",
      " |      Passing ``result_type='broadcast'`` will ensure the same shape\n",
      " |      result, whether list-like or scalar is returned by the function,\n",
      " |      and broadcast it along the axis. The resulting column names will\n",
      " |      be the originals.\n",
      " |      \n",
      " |      >>> df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  1  2\n",
      " |      2  1  2\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      applied : Series or DataFrame\n",
      " |  \n",
      " |  applymap(self, func)\n",
      " |      Apply a function to a Dataframe elementwise.\n",
      " |      \n",
      " |      This method applies a function that accepts and returns a scalar\n",
      " |      to every element of a DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable\n",
      " |          Python function, returns a single value from a single value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Transformed DataFrame.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.apply : Apply a function along input axis of DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])\n",
      " |      >>> df\n",
      " |             0      1\n",
      " |      0  1.000  2.120\n",
      " |      1  3.356  4.567\n",
      " |      \n",
      " |      >>> df.applymap(lambda x: len(str(x)))\n",
      " |         0  1\n",
      " |      0  3  4\n",
      " |      1  5  5\n",
      " |      \n",
      " |      Note that a vectorized version of `func` often exists, which will\n",
      " |      be much faster. You could square each number elementwise.\n",
      " |      \n",
      " |      >>> df.applymap(lambda x: x**2)\n",
      " |                 0          1\n",
      " |      0   1.000000   4.494400\n",
      " |      1  11.262736  20.857489\n",
      " |      \n",
      " |      But it's better to avoid applymap in that case.\n",
      " |      \n",
      " |      >>> df ** 2\n",
      " |                 0          1\n",
      " |      0   1.000000   4.494400\n",
      " |      1  11.262736  20.857489\n",
      " |  \n",
      " |  assign(self, **kwargs)\n",
      " |      Assign new columns to a DataFrame, returning a new object\n",
      " |      (a copy) with the new columns added to the original ones.\n",
      " |      Existing columns that are re-assigned will be overwritten.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      kwargs : keyword, value pairs\n",
      " |          keywords are the column names. If the values are\n",
      " |          callable, they are computed on the DataFrame and\n",
      " |          assigned to the new columns. The callable must not\n",
      " |          change input DataFrame (though pandas doesn't check it).\n",
      " |          If the values are not callable, (e.g. a Series, scalar, or array),\n",
      " |          they are simply assigned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      df : DataFrame\n",
      " |          A new DataFrame with the new columns in addition to\n",
      " |          all the existing columns.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Assigning multiple columns within the same ``assign`` is possible.\n",
      " |      For Python 3.6 and above, later items in '\\*\\*kwargs' may refer to\n",
      " |      newly created or modified columns in 'df'; items are computed and\n",
      " |      assigned into 'df' in order.  For Python 3.5 and below, the order of\n",
      " |      keyword arguments is not specified, you cannot refer to newly created\n",
      " |      or modified columns. All items are computed first, and then assigned\n",
      " |      in alphabetical order.\n",
      " |      \n",
      " |      .. versionchanged :: 0.23.0\n",
      " |      \n",
      " |          Keyword argument order is maintained for Python 3.6 and later.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': range(1, 11), 'B': np.random.randn(10)})\n",
      " |      \n",
      " |      Where the value is a callable, evaluated on `df`:\n",
      " |      \n",
      " |      >>> df.assign(ln_A = lambda x: np.log(x.A))\n",
      " |          A         B      ln_A\n",
      " |      0   1  0.426905  0.000000\n",
      " |      1   2 -0.780949  0.693147\n",
      " |      2   3 -0.418711  1.098612\n",
      " |      3   4 -0.269708  1.386294\n",
      " |      4   5 -0.274002  1.609438\n",
      " |      5   6 -0.500792  1.791759\n",
      " |      6   7  1.649697  1.945910\n",
      " |      7   8 -1.495604  2.079442\n",
      " |      8   9  0.549296  2.197225\n",
      " |      9  10 -0.758542  2.302585\n",
      " |      \n",
      " |      Where the value already exists and is inserted:\n",
      " |      \n",
      " |      >>> newcol = np.log(df['A'])\n",
      " |      >>> df.assign(ln_A=newcol)\n",
      " |          A         B      ln_A\n",
      " |      0   1  0.426905  0.000000\n",
      " |      1   2 -0.780949  0.693147\n",
      " |      2   3 -0.418711  1.098612\n",
      " |      3   4 -0.269708  1.386294\n",
      " |      4   5 -0.274002  1.609438\n",
      " |      5   6 -0.500792  1.791759\n",
      " |      6   7  1.649697  1.945910\n",
      " |      7   8 -1.495604  2.079442\n",
      " |      8   9  0.549296  2.197225\n",
      " |      9  10 -0.758542  2.302585\n",
      " |      \n",
      " |      Where the keyword arguments depend on each other\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3]})\n",
      " |      \n",
      " |      >>> df.assign(B=df.A, C=lambda x:x['A']+ x['B'])\n",
      " |          A  B  C\n",
      " |       0  1  1  2\n",
      " |       1  2  2  4\n",
      " |       2  3  3  6\n",
      " |  \n",
      " |  boxplot = boxplot_frame(self, column=None, by=None, ax=None, fontsize=None, rot=0, grid=True, figsize=None, layout=None, return_type=None, **kwds)\n",
      " |      Make a box plot from DataFrame columns.\n",
      " |      \n",
      " |      Make a box-and-whisker plot from DataFrame columns, optionally grouped\n",
      " |      by some other columns. A box plot is a method for graphically depicting\n",
      " |      groups of numerical data through their quartiles.\n",
      " |      The box extends from the Q1 to Q3 quartile values of the data,\n",
      " |      with a line at the median (Q2). The whiskers extend from the edges\n",
      " |      of box to show the range of the data. The position of the whiskers\n",
      " |      is set by default to `1.5 * IQR (IQR = Q3 - Q1)` from the edges of the box.\n",
      " |      Outlier points are those past the end of the whiskers.\n",
      " |      \n",
      " |      For further details see\n",
      " |      Wikipedia's entry for `boxplot <https://en.wikipedia.org/wiki/Box_plot>`_.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      column : str or list of str, optional\n",
      " |          Column name or list of names, or vector.\n",
      " |          Can be any valid input to :meth:`pandas.DataFrame.groupby`.\n",
      " |      by : str or array-like, optional\n",
      " |          Column in the DataFrame to :meth:`pandas.DataFrame.groupby`.\n",
      " |          One box-plot will be done per value of columns in `by`.\n",
      " |      ax : object of class matplotlib.axes.Axes, optional\n",
      " |          The matplotlib axes to be used by boxplot.\n",
      " |      fontsize : float or str\n",
      " |          Tick label font size in points or as a string (e.g., `large`).\n",
      " |      rot : int or float, default 0\n",
      " |          The rotation angle of labels (in degrees)\n",
      " |          with respect to the screen coordinate sytem.\n",
      " |      grid : boolean, default True\n",
      " |          Setting this to True will show the grid.\n",
      " |      figsize : A tuple (width, height) in inches\n",
      " |          The size of the figure to create in matplotlib.\n",
      " |      layout : tuple (rows, columns), optional\n",
      " |          For example, (3, 5) will display the subplots\n",
      " |          using 3 columns and 5 rows, starting from the top-left.\n",
      " |      return_type : {'axes', 'dict', 'both'} or None, default 'axes'\n",
      " |          The kind of object to return. The default is ``axes``.\n",
      " |      \n",
      " |          * 'axes' returns the matplotlib axes the boxplot is drawn on.\n",
      " |          * 'dict' returns a dictionary whose values are the matplotlib\n",
      " |            Lines of the boxplot.\n",
      " |          * 'both' returns a namedtuple with the axes and dict.\n",
      " |          * when grouping with ``by``, a Series mapping columns to\n",
      " |            ``return_type`` is returned.\n",
      " |      \n",
      " |            If ``return_type`` is `None`, a NumPy array\n",
      " |            of axes with the same shape as ``layout`` is returned.\n",
      " |      **kwds\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          :func:`matplotlib.pyplot.boxplot`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result :\n",
      " |      \n",
      " |          The return type depends on the `return_type` parameter:\n",
      " |      \n",
      " |          * 'axes' : object of class matplotlib.axes.Axes\n",
      " |          * 'dict' : dict of matplotlib.lines.Line2D objects\n",
      " |          * 'both' : a nametuple with strucure (ax, lines)\n",
      " |      \n",
      " |          For data grouped with ``by``:\n",
      " |      \n",
      " |          * :class:`~pandas.Series`\n",
      " |          * :class:`~numpy.array` (for ``return_type = None``)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.plot.hist: Make a histogram.\n",
      " |      matplotlib.pyplot.boxplot : Matplotlib equivalent plot.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Use ``return_type='dict'`` when you want to tweak the appearance\n",
      " |      of the lines after plotting. In this case a dict containing the Lines\n",
      " |      making up the boxes, caps, fliers, medians, and whiskers is returned.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Boxplots can be created for every column in the dataframe\n",
      " |      by ``df.boxplot()`` or indicating the columns to be used:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> np.random.seed(1234)\n",
      " |          >>> df = pd.DataFrame(np.random.randn(10,4),\n",
      " |          ...                   columns=['Col1', 'Col2', 'Col3', 'Col4'])\n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2', 'Col3'])\n",
      " |      \n",
      " |      Boxplots of variables distributions grouped by the values of a third\n",
      " |      variable can be created using the option ``by``. For instance:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> df = pd.DataFrame(np.random.randn(10, 2),\n",
      " |          ...                   columns=['Col1', 'Col2'])\n",
      " |          >>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',\n",
      " |          ...                      'B', 'B', 'B', 'B', 'B'])\n",
      " |          >>> boxplot = df.boxplot(by='X')\n",
      " |      \n",
      " |      A list of strings (i.e. ``['X', 'Y']``) can be passed to boxplot\n",
      " |      in order to group the data by combination of the variables in the x-axis:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> df = pd.DataFrame(np.random.randn(10,3),\n",
      " |          ...                   columns=['Col1', 'Col2', 'Col3'])\n",
      " |          >>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',\n",
      " |          ...                      'B', 'B', 'B', 'B', 'B'])\n",
      " |          >>> df['Y'] = pd.Series(['A', 'B', 'A', 'B', 'A',\n",
      " |          ...                      'B', 'A', 'B', 'A', 'B'])\n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by=['X', 'Y'])\n",
      " |      \n",
      " |      The layout of boxplot can be adjusted giving a tuple to ``layout``:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',\n",
      " |          ...                      layout=(2, 1))\n",
      " |      \n",
      " |      Additional formatting can be done to the boxplot, like suppressing the grid\n",
      " |      (``grid=False``), rotating the labels in the x-axis (i.e. ``rot=45``)\n",
      " |      or changing the fontsize (i.e. ``fontsize=15``):\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(grid=False, rot=45, fontsize=15)\n",
      " |      \n",
      " |      The parameter ``return_type`` can be used to select the type of element\n",
      " |      returned by `boxplot`.  When ``return_type='axes'`` is selected,\n",
      " |      the matplotlib axes on which the boxplot is drawn are returned:\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1','Col2'], return_type='axes')\n",
      " |          >>> type(boxplot)\n",
      " |          <class 'matplotlib.axes._subplots.AxesSubplot'>\n",
      " |      \n",
      " |      When grouping with ``by``, a Series mapping columns to ``return_type``\n",
      " |      is returned:\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',\n",
      " |          ...                      return_type='axes')\n",
      " |          >>> type(boxplot)\n",
      " |          <class 'pandas.core.series.Series'>\n",
      " |      \n",
      " |      If ``return_type`` is `None`, a NumPy array of axes with the same shape\n",
      " |      as ``layout`` is returned:\n",
      " |      \n",
      " |          >>> boxplot =  df.boxplot(column=['Col1', 'Col2'], by='X',\n",
      " |          ...                       return_type=None)\n",
      " |          >>> type(boxplot)\n",
      " |          <class 'numpy.ndarray'>\n",
      " |  \n",
      " |  combine(self, other, func, fill_value=None, overwrite=True)\n",
      " |      Add two DataFrame objects and do not propagate NaN values, so if for a\n",
      " |      (column, time) one frame is missing a value, it will default to the\n",
      " |      other frame's value (which might be NaN as well)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |      func : function\n",
      " |          Function that takes two series as inputs and return a Series or a\n",
      " |          scalar\n",
      " |      fill_value : scalar value\n",
      " |      overwrite : boolean, default True\n",
      " |          If True then overwrite values for common keys in the calling frame\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df1 = DataFrame({'A': [0, 0], 'B': [4, 4]})\n",
      " |      >>> df2 = DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> df1.combine(df2, lambda s1, s2: s1 if s1.sum() < s2.sum() else s2)\n",
      " |         A  B\n",
      " |      0  0  3\n",
      " |      1  0  3\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.combine_first : Combine two DataFrame objects and default to\n",
      " |          non-null values in frame calling the method\n",
      " |  \n",
      " |  combine_first(self, other)\n",
      " |      Combine two DataFrame objects and default to non-null values in frame\n",
      " |      calling the method. Result index columns will be the union of the\n",
      " |      respective indexes and columns\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      combined : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      df1's values prioritized, use values from df2 to fill holes:\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame([[1, np.nan]])\n",
      " |      >>> df2 = pd.DataFrame([[3, 4]])\n",
      " |      >>> df1.combine_first(df2)\n",
      " |         0    1\n",
      " |      0  1  4.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.combine : Perform series-wise operation on two DataFrames\n",
      " |          using a given function\n",
      " |  \n",
      " |  compound(self, axis=None, skipna=None, level=None)\n",
      " |      Return the compound percentage of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      compounded : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  corr(self, method='pearson', min_periods=1)\n",
      " |      Compute pairwise correlation of columns, excluding NA/null values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'pearson', 'kendall', 'spearman'}\n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result. Currently only available for pearson\n",
      " |          and spearman correlation\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : DataFrame\n",
      " |  \n",
      " |  corrwith(self, other, axis=0, drop=False)\n",
      " |      Compute pairwise correlation between rows or columns of two DataFrame\n",
      " |      objects.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, Series\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          0 or 'index' to compute column-wise, 1 or 'columns' for row-wise\n",
      " |      drop : boolean, default False\n",
      " |          Drop missing indices from result, default returns union of all\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      correls : Series\n",
      " |  \n",
      " |  count(self, axis=0, level=None, numeric_only=False)\n",
      " |      Count non-NA cells for each column or row.\n",
      " |      \n",
      " |      The values `None`, `NaN`, `NaT`, and optionally `numpy.inf` (depending\n",
      " |      on `pandas.options.mode.use_inf_as_na`) are considered NA.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          If 0 or 'index' counts are generated for each column.\n",
      " |          If 1 or 'columns' counts are generated for each **row**.\n",
      " |      level : int or str, optional\n",
      " |          If the axis is a `MultiIndex` (hierarchical), count along a\n",
      " |          particular `level`, collapsing into a `DataFrame`.\n",
      " |          A `str` specifies the level name.\n",
      " |      numeric_only : boolean, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          For each column/row the number of non-NA/null entries.\n",
      " |          If `level` is specified returns a `DataFrame`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.count: number of non-NA elements in a Series\n",
      " |      DataFrame.shape: number of DataFrame rows and columns (including NA\n",
      " |          elements)\n",
      " |      DataFrame.isna: boolean same-sized DataFrame showing places of NA\n",
      " |          elements\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Constructing DataFrame from a dictionary:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"Person\":\n",
      " |      ...                    [\"John\", \"Myla\", None, \"John\", \"Myla\"],\n",
      " |      ...                    \"Age\": [24., np.nan, 21., 33, 26],\n",
      " |      ...                    \"Single\": [False, True, True, True, False]})\n",
      " |      >>> df\n",
      " |         Person   Age  Single\n",
      " |      0    John  24.0   False\n",
      " |      1    Myla   NaN    True\n",
      " |      2    None  21.0    True\n",
      " |      3    John  33.0    True\n",
      " |      4    Myla  26.0   False\n",
      " |      \n",
      " |      Notice the uncounted NA values:\n",
      " |      \n",
      " |      >>> df.count()\n",
      " |      Person    4\n",
      " |      Age       4\n",
      " |      Single    5\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Counts for each **row**:\n",
      " |      \n",
      " |      >>> df.count(axis='columns')\n",
      " |      0    3\n",
      " |      1    2\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Counts for one level of a `MultiIndex`:\n",
      " |      \n",
      " |      >>> df.set_index([\"Person\", \"Single\"]).count(level=\"Person\")\n",
      " |              Age\n",
      " |      Person\n",
      " |      John      2\n",
      " |      Myla      1\n",
      " |  \n",
      " |  cov(self, min_periods=None)\n",
      " |      Compute pairwise covariance of columns, excluding NA/null values.\n",
      " |      \n",
      " |      Compute the pairwise covariance among the series of a DataFrame.\n",
      " |      The returned data frame is the `covariance matrix\n",
      " |      <https://en.wikipedia.org/wiki/Covariance_matrix>`__ of the columns\n",
      " |      of the DataFrame.\n",
      " |      \n",
      " |      Both NA and null values are automatically excluded from the\n",
      " |      calculation. (See the note below about bias from missing values.)\n",
      " |      A threshold can be set for the minimum number of\n",
      " |      observations for each value created. Comparisons with observations\n",
      " |      below this threshold will be returned as ``NaN``.\n",
      " |      \n",
      " |      This method is generally used for the analysis of time series data to\n",
      " |      understand the relationship between different measures\n",
      " |      across time.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The covariance matrix of the series of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.cov : compute covariance with another Series\n",
      " |      pandas.core.window.EWM.cov: expoential weighted sample covariance\n",
      " |      pandas.core.window.Expanding.cov : expanding sample covariance\n",
      " |      pandas.core.window.Rolling.cov : rolling sample covariance\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Returns the covariance matrix of the DataFrame's time series.\n",
      " |      The covariance is normalized by N-1.\n",
      " |      \n",
      " |      For DataFrames that have Series that are missing data (assuming that\n",
      " |      data is `missing at random\n",
      " |      <https://en.wikipedia.org/wiki/Missing_data#Missing_at_random>`__)\n",
      " |      the returned covariance matrix will be an unbiased estimate\n",
      " |      of the variance and covariance between the member Series.\n",
      " |      \n",
      " |      However, for many applications this estimate may not be acceptable\n",
      " |      because the estimate covariance matrix is not guaranteed to be positive\n",
      " |      semi-definite. This could lead to estimate correlations having\n",
      " |      absolute values which are greater than one, and/or a non-invertible\n",
      " |      covariance matrix. See `Estimation of covariance matrices\n",
      " |      <http://en.wikipedia.org/w/index.php?title=Estimation_of_covariance_\n",
      " |      matrices>`__ for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.cov()\n",
      " |                dogs      cats\n",
      " |      dogs  0.666667 -1.000000\n",
      " |      cats -1.000000  1.666667\n",
      " |      \n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(1000, 5),\n",
      " |      ...                   columns=['a', 'b', 'c', 'd', 'e'])\n",
      " |      >>> df.cov()\n",
      " |                a         b         c         d         e\n",
      " |      a  0.998438 -0.020161  0.059277 -0.008943  0.014144\n",
      " |      b -0.020161  1.059352 -0.008543 -0.024738  0.009826\n",
      " |      c  0.059277 -0.008543  1.010670 -0.001486 -0.000271\n",
      " |      d -0.008943 -0.024738 -0.001486  0.921297 -0.013692\n",
      " |      e  0.014144  0.009826 -0.000271 -0.013692  0.977795\n",
      " |      \n",
      " |      **Minimum number of periods**\n",
      " |      \n",
      " |      This method also supports an optional ``min_periods`` keyword\n",
      " |      that specifies the required minimum number of non-NA observations for\n",
      " |      each column pair in order to have a valid result:\n",
      " |      \n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(20, 3),\n",
      " |      ...                   columns=['a', 'b', 'c'])\n",
      " |      >>> df.loc[df.index[:5], 'a'] = np.nan\n",
      " |      >>> df.loc[df.index[5:10], 'b'] = np.nan\n",
      " |      >>> df.cov(min_periods=12)\n",
      " |                a         b         c\n",
      " |      a  0.316741       NaN -0.150812\n",
      " |      b       NaN  1.248003  0.191417\n",
      " |      c -0.150812  0.191417  0.895202\n",
      " |  \n",
      " |  cummax(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative maximum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      maximum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs :\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cummax : Series or DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cummax()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3    5.0\n",
      " |      4    5.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cummax(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the maximum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cummax()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  3.0  1.0\n",
      " |      \n",
      " |      To iterate over columns and find the maximum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cummax(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.max : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.max : Return the maximum over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |  \n",
      " |  cummin(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative minimum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      minimum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs :\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cummin : Series or DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cummin()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    2.0\n",
      " |      3   -1.0\n",
      " |      4   -1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cummin(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the minimum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cummin()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  2.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      To iterate over columns and find the minimum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cummin(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.min : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.min : Return the minimum over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |  \n",
      " |  cumprod(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative product over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      product.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs :\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cumprod : Series or DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cumprod()\n",
      " |      0     2.0\n",
      " |      1     NaN\n",
      " |      2    10.0\n",
      " |      3   -10.0\n",
      " |      4    -0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cumprod(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the product\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cumprod()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  6.0  NaN\n",
      " |      2  6.0  0.0\n",
      " |      \n",
      " |      To iterate over columns and find the product in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cumprod(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.prod : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.prod : Return the product over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |  \n",
      " |  cumsum(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative sum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      sum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs :\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cumsum : Series or DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cumsum()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    7.0\n",
      " |      3    6.0\n",
      " |      4    6.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cumsum(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the sum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cumsum()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  5.0  NaN\n",
      " |      2  6.0  1.0\n",
      " |      \n",
      " |      To iterate over columns and find the sum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cumsum(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  3.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.sum : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.sum : Return the sum over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |  \n",
      " |  diff(self, periods=1, axis=0)\n",
      " |      First discrete difference of element.\n",
      " |      \n",
      " |      Calculates the difference of a DataFrame element compared with another\n",
      " |      element in the DataFrame (default is the element in the same column\n",
      " |      of the previous row).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for calculating difference, accepts negative\n",
      " |          values.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Take difference over rows (0) or columns (1).\n",
      " |      \n",
      " |          .. versionadded:: 0.16.1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      diffed : DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.diff: First discrete difference for a Series.\n",
      " |      DataFrame.pct_change: Percent change over given number of periods.\n",
      " |      DataFrame.shift: Shift index by desired number of periods with an\n",
      " |          optional time freq.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Difference with previous row\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'a': [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'b': [1, 1, 2, 3, 5, 8],\n",
      " |      ...                    'c': [1, 4, 9, 16, 25, 36]})\n",
      " |      >>> df\n",
      " |         a  b   c\n",
      " |      0  1  1   1\n",
      " |      1  2  1   4\n",
      " |      2  3  2   9\n",
      " |      3  4  3  16\n",
      " |      4  5  5  25\n",
      " |      5  6  8  36\n",
      " |      \n",
      " |      >>> df.diff()\n",
      " |           a    b     c\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  1.0  0.0   3.0\n",
      " |      2  1.0  1.0   5.0\n",
      " |      3  1.0  1.0   7.0\n",
      " |      4  1.0  2.0   9.0\n",
      " |      5  1.0  3.0  11.0\n",
      " |      \n",
      " |      Difference with previous column\n",
      " |      \n",
      " |      >>> df.diff(axis=1)\n",
      " |          a    b     c\n",
      " |      0 NaN  0.0   0.0\n",
      " |      1 NaN -1.0   3.0\n",
      " |      2 NaN -1.0   7.0\n",
      " |      3 NaN -1.0  13.0\n",
      " |      4 NaN  0.0  20.0\n",
      " |      5 NaN  2.0  28.0\n",
      " |      \n",
      " |      Difference with 3rd previous row\n",
      " |      \n",
      " |      >>> df.diff(periods=3)\n",
      " |           a    b     c\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  NaN  NaN   NaN\n",
      " |      2  NaN  NaN   NaN\n",
      " |      3  3.0  2.0  15.0\n",
      " |      4  3.0  4.0  21.0\n",
      " |      5  3.0  6.0  27.0\n",
      " |      \n",
      " |      Difference with following row\n",
      " |      \n",
      " |      >>> df.diff(periods=-1)\n",
      " |           a    b     c\n",
      " |      0 -1.0  0.0  -3.0\n",
      " |      1 -1.0 -1.0  -5.0\n",
      " |      2 -1.0 -1.0  -7.0\n",
      " |      3 -1.0 -2.0  -9.0\n",
      " |      4 -1.0 -3.0 -11.0\n",
      " |      5  NaN  NaN   NaN\n",
      " |  \n",
      " |  div = truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  divide = truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  dot(self, other)\n",
      " |      Matrix multiplication with DataFrame or Series objects.  Can also be\n",
      " |      called using `self @ other` in Python >= 3.5.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dot_product : DataFrame or Series\n",
      " |  \n",
      " |  drop(self, labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\n",
      " |      Drop specified labels from rows or columns.\n",
      " |      \n",
      " |      Remove rows or columns by specifying label names and corresponding\n",
      " |      axis, or by specifying directly index or column names. When using a\n",
      " |      multi-index, labels on different levels can be removed by specifying\n",
      " |      the level.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : single label or list-like\n",
      " |          Index or column labels to drop.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Whether to drop labels from the index (0 or 'index') or\n",
      " |          columns (1 or 'columns').\n",
      " |      index, columns : single label or list-like\n",
      " |          Alternative to specifying axis (``labels, axis=1``\n",
      " |          is equivalent to ``columns=labels``).\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      level : int or level name, optional\n",
      " |          For MultiIndex, level from which the labels will be removed.\n",
      " |      inplace : bool, default False\n",
      " |          If True, do operation inplace and return None.\n",
      " |      errors : {'ignore', 'raise'}, default 'raise'\n",
      " |          If 'ignore', suppress error and only existing labels are\n",
      " |          dropped.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dropped : pandas.DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Label-location based indexer for selection by label.\n",
      " |      DataFrame.dropna : Return DataFrame with labels on given axis omitted\n",
      " |          where (all or any) data are missing\n",
      " |      DataFrame.drop_duplicates : Return DataFrame with duplicate rows\n",
      " |          removed, optionally only considering certain columns\n",
      " |      Series.drop : Return Series with specified index labels removed.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If none of the labels are found in the selected axis\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.arange(12).reshape(3,4),\n",
      " |      ...                   columns=['A', 'B', 'C', 'D'])\n",
      " |      >>> df\n",
      " |         A  B   C   D\n",
      " |      0  0  1   2   3\n",
      " |      1  4  5   6   7\n",
      " |      2  8  9  10  11\n",
      " |      \n",
      " |      Drop columns\n",
      " |      \n",
      " |      >>> df.drop(['B', 'C'], axis=1)\n",
      " |         A   D\n",
      " |      0  0   3\n",
      " |      1  4   7\n",
      " |      2  8  11\n",
      " |      \n",
      " |      >>> df.drop(columns=['B', 'C'])\n",
      " |         A   D\n",
      " |      0  0   3\n",
      " |      1  4   7\n",
      " |      2  8  11\n",
      " |      \n",
      " |      Drop a row by index\n",
      " |      \n",
      " |      >>> df.drop([0, 1])\n",
      " |         A  B   C   D\n",
      " |      2  8  9  10  11\n",
      " |      \n",
      " |      Drop columns and/or rows of MultiIndex DataFrame\n",
      " |      \n",
      " |      >>> midx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'],\n",
      " |      ...                              ['speed', 'weight', 'length']],\n",
      " |      ...                      labels=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
      " |      ...                              [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
      " |      >>> df = pd.DataFrame(index=midx, columns=['big', 'small'],\n",
      " |      ...                   data=[[45, 30], [200, 100], [1.5, 1], [30, 20],\n",
      " |      ...                         [250, 150], [1.5, 0.8], [320, 250],\n",
      " |      ...                         [1, 0.8], [0.3,0.2]])\n",
      " |      >>> df\n",
      " |                      big     small\n",
      " |      lama    speed   45.0    30.0\n",
      " |              weight  200.0   100.0\n",
      " |              length  1.5     1.0\n",
      " |      cow     speed   30.0    20.0\n",
      " |              weight  250.0   150.0\n",
      " |              length  1.5     0.8\n",
      " |      falcon  speed   320.0   250.0\n",
      " |              weight  1.0     0.8\n",
      " |              length  0.3     0.2\n",
      " |      \n",
      " |      >>> df.drop(index='cow', columns='small')\n",
      " |                      big\n",
      " |      lama    speed   45.0\n",
      " |              weight  200.0\n",
      " |              length  1.5\n",
      " |      falcon  speed   320.0\n",
      " |              weight  1.0\n",
      " |              length  0.3\n",
      " |      \n",
      " |      >>> df.drop(index='length', level=1)\n",
      " |                      big     small\n",
      " |      lama    speed   45.0    30.0\n",
      " |              weight  200.0   100.0\n",
      " |      cow     speed   30.0    20.0\n",
      " |              weight  250.0   150.0\n",
      " |      falcon  speed   320.0   250.0\n",
      " |              weight  1.0     0.8\n",
      " |  \n",
      " |  drop_duplicates(self, subset=None, keep='first', inplace=False)\n",
      " |      Return DataFrame with duplicate rows removed, optionally only\n",
      " |      considering certain columns\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : column label or sequence of labels, optional\n",
      " |          Only consider certain columns for identifying duplicates, by\n",
      " |          default use all of the columns\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          - ``first`` : Drop duplicates except for the first occurrence.\n",
      " |          - ``last`` : Drop duplicates except for the last occurrence.\n",
      " |          - False : Drop all duplicates.\n",
      " |      inplace : boolean, default False\n",
      " |          Whether to drop duplicates in place or to return a copy\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      deduplicated : DataFrame\n",
      " |  \n",
      " |  dropna(self, axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
      " |      Remove missing values.\n",
      " |      \n",
      " |      See the :ref:`User Guide <missing_data>` for more on which values are\n",
      " |      considered missing, and how to work with missing data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Determine if rows or columns which contain missing values are\n",
      " |          removed.\n",
      " |      \n",
      " |          * 0, or 'index' : Drop rows which contain missing values.\n",
      " |          * 1, or 'columns' : Drop columns which contain missing value.\n",
      " |      \n",
      " |          .. deprecated:: 0.23.0: Pass tuple or list to drop on multiple\n",
      " |          axes.\n",
      " |      how : {'any', 'all'}, default 'any'\n",
      " |          Determine if row or column is removed from DataFrame, when we have\n",
      " |          at least one NA or all NA.\n",
      " |      \n",
      " |          * 'any' : If any NA values are present, drop that row or column.\n",
      " |          * 'all' : If all values are NA, drop that row or column.\n",
      " |      thresh : int, optional\n",
      " |          Require that many non-NA values.\n",
      " |      subset : array-like, optional\n",
      " |          Labels along other axis to consider, e.g. if you are dropping rows\n",
      " |          these would be a list of columns to include.\n",
      " |      inplace : bool, default False\n",
      " |          If True, do operation inplace and return None.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame with NA entries dropped from it.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isna: Indicate missing values.\n",
      " |      DataFrame.notna : Indicate existing (non-missing) values.\n",
      " |      DataFrame.fillna : Replace missing values.\n",
      " |      Series.dropna : Drop missing values.\n",
      " |      Index.dropna : Drop missing indices.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n",
      " |      ...                    \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n",
      " |      ...                    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n",
      " |      ...                             pd.NaT]})\n",
      " |      >>> df\n",
      " |             name        toy       born\n",
      " |      0    Alfred        NaN        NaT\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |      \n",
      " |      Drop the rows where at least one element is missing.\n",
      " |      \n",
      " |      >>> df.dropna()\n",
      " |           name        toy       born\n",
      " |      1  Batman  Batmobile 1940-04-25\n",
      " |      \n",
      " |      Drop the columns where at least one element is missing.\n",
      " |      \n",
      " |      >>> df.dropna(axis='columns')\n",
      " |             name\n",
      " |      0    Alfred\n",
      " |      1    Batman\n",
      " |      2  Catwoman\n",
      " |      \n",
      " |      Drop the rows where all elements are missing.\n",
      " |      \n",
      " |      >>> df.dropna(how='all')\n",
      " |             name        toy       born\n",
      " |      0    Alfred        NaN        NaT\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |      \n",
      " |      Keep only the rows with at least 2 non-NA values.\n",
      " |      \n",
      " |      >>> df.dropna(thresh=2)\n",
      " |             name        toy       born\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |      \n",
      " |      Define in which columns to look for missing values.\n",
      " |      \n",
      " |      >>> df.dropna(subset=['name', 'born'])\n",
      " |             name        toy       born\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      \n",
      " |      Keep the DataFrame with valid entries in the same variable.\n",
      " |      \n",
      " |      >>> df.dropna(inplace=True)\n",
      " |      >>> df\n",
      " |           name        toy       born\n",
      " |      1  Batman  Batmobile 1940-04-25\n",
      " |  \n",
      " |  duplicated(self, subset=None, keep='first')\n",
      " |      Return boolean Series denoting duplicate rows, optionally only\n",
      " |      considering certain columns\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : column label or sequence of labels, optional\n",
      " |          Only consider certain columns for identifying duplicates, by\n",
      " |          default use all of the columns\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          - ``first`` : Mark duplicates as ``True`` except for the\n",
      " |            first occurrence.\n",
      " |          - ``last`` : Mark duplicates as ``True`` except for the\n",
      " |            last occurrence.\n",
      " |          - False : Mark all duplicates as ``True``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      duplicated : Series\n",
      " |  \n",
      " |  eq(self, other, axis='columns', level=None)\n",
      " |      Wrapper for flexible comparison methods eq\n",
      " |  \n",
      " |  eval(self, expr, inplace=False, **kwargs)\n",
      " |      Evaluate a string describing operations on DataFrame columns.\n",
      " |      \n",
      " |      Operates on columns only, not specific rows or elements.  This allows\n",
      " |      `eval` to run arbitrary code, which can make you vulnerable to code\n",
      " |      injection if you pass user input to this function.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      expr : str\n",
      " |          The expression string to evaluate.\n",
      " |      inplace : bool, default False\n",
      " |          If the expression contains an assignment, whether to perform the\n",
      " |          operation inplace and mutate the existing DataFrame. Otherwise,\n",
      " |          a new DataFrame is returned.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0.\n",
      " |      kwargs : dict\n",
      " |          See the documentation for :func:`~pandas.eval` for complete details\n",
      " |          on the keyword arguments accepted by\n",
      " |          :meth:`~pandas.DataFrame.query`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray, scalar, or pandas object\n",
      " |          The result of the evaluation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.query : Evaluates a boolean expression to query the columns\n",
      " |          of a frame.\n",
      " |      DataFrame.assign : Can evaluate an expression or function to create new\n",
      " |          values for a column.\n",
      " |      pandas.eval : Evaluate a Python expression as a string using various\n",
      " |          backends.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For more details see the API documentation for :func:`~pandas.eval`.\n",
      " |      For detailed examples see :ref:`enhancing performance with eval\n",
      " |      <enhancingperf.eval>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': range(1, 6), 'B': range(10, 0, -2)})\n",
      " |      >>> df\n",
      " |         A   B\n",
      " |      0  1  10\n",
      " |      1  2   8\n",
      " |      2  3   6\n",
      " |      3  4   4\n",
      " |      4  5   2\n",
      " |      >>> df.eval('A + B')\n",
      " |      0    11\n",
      " |      1    10\n",
      " |      2     9\n",
      " |      3     8\n",
      " |      4     7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Assignment is allowed though by default the original DataFrame is not\n",
      " |      modified.\n",
      " |      \n",
      " |      >>> df.eval('C = A + B')\n",
      " |         A   B   C\n",
      " |      0  1  10  11\n",
      " |      1  2   8  10\n",
      " |      2  3   6   9\n",
      " |      3  4   4   8\n",
      " |      4  5   2   7\n",
      " |      >>> df\n",
      " |         A   B\n",
      " |      0  1  10\n",
      " |      1  2   8\n",
      " |      2  3   6\n",
      " |      3  4   4\n",
      " |      4  5   2\n",
      " |      \n",
      " |      Use ``inplace=True`` to modify the original DataFrame.\n",
      " |      \n",
      " |      >>> df.eval('C = A + B', inplace=True)\n",
      " |      >>> df\n",
      " |         A   B   C\n",
      " |      0  1  10  11\n",
      " |      1  2   8  10\n",
      " |      2  3   6   9\n",
      " |      3  4   4   8\n",
      " |      4  5   2   7\n",
      " |  \n",
      " |  ewm(self, com=None, span=None, halflife=None, alpha=None, min_periods=0, adjust=True, ignore_na=False, axis=0)\n",
      " |      Provides exponential weighted functions\n",
      " |      \n",
      " |      .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      com : float, optional\n",
      " |          Specify decay in terms of center of mass,\n",
      " |          :math:`\\alpha = 1 / (1 + com),\\text{ for } com \\geq 0`\n",
      " |      span : float, optional\n",
      " |          Specify decay in terms of span,\n",
      " |          :math:`\\alpha = 2 / (span + 1),\\text{ for } span \\geq 1`\n",
      " |      halflife : float, optional\n",
      " |          Specify decay in terms of half-life,\n",
      " |          :math:`\\alpha = 1 - exp(log(0.5) / halflife),\\text{ for } halflife > 0`\n",
      " |      alpha : float, optional\n",
      " |          Specify smoothing factor :math:`\\alpha` directly,\n",
      " |          :math:`0 < \\alpha \\leq 1`\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      min_periods : int, default 0\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA).\n",
      " |      adjust : boolean, default True\n",
      " |          Divide by decaying adjustment factor in beginning periods to account\n",
      " |          for imbalance in relative weightings (viewing EWMA as a moving average)\n",
      " |      ignore_na : boolean, default False\n",
      " |          Ignore missing values when calculating weights;\n",
      " |          specify True to reproduce pre-0.15.0 behavior\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window sub-classed for the particular operation\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.ewm(com=0.5).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Exactly one of center of mass, span, half-life, and alpha must be provided.\n",
      " |      Allowed values and relationship between the parameters are specified in the\n",
      " |      parameter descriptions above; see the link at the end of this section for\n",
      " |      a detailed explanation.\n",
      " |      \n",
      " |      When adjust is True (default), weighted averages are calculated using\n",
      " |      weights (1-alpha)**(n-1), (1-alpha)**(n-2), ..., 1-alpha, 1.\n",
      " |      \n",
      " |      When adjust is False, weighted averages are calculated recursively as:\n",
      " |         weighted_average[0] = arg[0];\n",
      " |         weighted_average[i] = (1-alpha)*weighted_average[i-1] + alpha*arg[i].\n",
      " |      \n",
      " |      When ignore_na is False (default), weights are based on absolute positions.\n",
      " |      For example, the weights of x and y used in calculating the final weighted\n",
      " |      average of [x, None, y] are (1-alpha)**2 and 1 (if adjust is True), and\n",
      " |      (1-alpha)**2 and alpha (if adjust is False).\n",
      " |      \n",
      " |      When ignore_na is True (reproducing pre-0.15.0 behavior), weights are based\n",
      " |      on relative positions. For example, the weights of x and y used in\n",
      " |      calculating the final weighted average of [x, None, y] are 1-alpha and 1\n",
      " |      (if adjust is True), and 1-alpha and alpha (if adjust is False).\n",
      " |      \n",
      " |      More details can be found at\n",
      " |      http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-windows\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations\n",
      " |      expanding : Provides expanding transformations.\n",
      " |  \n",
      " |  expanding(self, min_periods=1, center=False, axis=0)\n",
      " |      Provides expanding transformations.\n",
      " |      \n",
      " |      .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, default 1\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA).\n",
      " |      center : boolean, default False\n",
      " |          Set the labels at the center of the window.\n",
      " |      axis : int or string, default 0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window sub-classed for the particular operation\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.expanding(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  7.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, the result is set to the right edge of the window. This can be\n",
      " |      changed to the center of the window by setting ``center=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations\n",
      " |      ewm : Provides exponential weighted functions\n",
      " |  \n",
      " |  fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)\n",
      " |      Fill NA/NaN values using the specified method\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a\n",
      " |          dict/Series/DataFrame of values specifying which value to use for\n",
      " |          each index (for a Series) or column (for a DataFrame). (values not\n",
      " |          in the dict/Series/DataFrame will not be filled). This value cannot\n",
      " |          be a list.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series\n",
      " |          pad / ffill: propagate last valid observation forward to next valid\n",
      " |          backfill / bfill: use NEXT valid observation to fill gap\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |      inplace : boolean, default False\n",
      " |          If True, fill in place. Note: this will modify any\n",
      " |          other views on this object, (e.g. a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      downcast : dict, default is None\n",
      " |          a dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      interpolate : Fill NaN values using interpolation.\n",
      " |      reindex, asfreq\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filled : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      " |      ...                    [3, 4, np.nan, 1],\n",
      " |      ...                    [np.nan, np.nan, np.nan, 5],\n",
      " |      ...                    [np.nan, 3, np.nan, 4]],\n",
      " |      ...                    columns=list('ABCD'))\n",
      " |      >>> df\n",
      " |           A    B   C  D\n",
      " |      0  NaN  2.0 NaN  0\n",
      " |      1  3.0  4.0 NaN  1\n",
      " |      2  NaN  NaN NaN  5\n",
      " |      3  NaN  3.0 NaN  4\n",
      " |      \n",
      " |      Replace all NaN elements with 0s.\n",
      " |      \n",
      " |      >>> df.fillna(0)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 0.0 0\n",
      " |      1   3.0 4.0 0.0 1\n",
      " |      2   0.0 0.0 0.0 5\n",
      " |      3   0.0 3.0 0.0 4\n",
      " |      \n",
      " |      We can also propagate non-null values forward or backward.\n",
      " |      \n",
      " |      >>> df.fillna(method='ffill')\n",
      " |          A   B   C   D\n",
      " |      0   NaN 2.0 NaN 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   3.0 4.0 NaN 5\n",
      " |      3   3.0 3.0 NaN 4\n",
      " |      \n",
      " |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      " |      2, and 3 respectively.\n",
      " |      \n",
      " |      >>> values = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
      " |      >>> df.fillna(value=values)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 2.0 1\n",
      " |      2   0.0 1.0 2.0 5\n",
      " |      3   0.0 3.0 2.0 4\n",
      " |      \n",
      " |      Only replace the first NaN element.\n",
      " |      \n",
      " |      >>> df.fillna(value=values, limit=1)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   NaN 1.0 NaN 5\n",
      " |      3   NaN 3.0 NaN 4\n",
      " |  \n",
      " |  floordiv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Integer division of dataframe and other, element-wise (binary operator `floordiv`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe // other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      None\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.rfloordiv\n",
      " |  \n",
      " |  ge(self, other, axis='columns', level=None)\n",
      " |      Wrapper for flexible comparison methods ge\n",
      " |  \n",
      " |  get_value(self, index, col, takeable=False)\n",
      " |      Quickly retrieve single value at passed column and index\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |          Use .at[] or .iat[] accessors instead.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : row label\n",
      " |      col : column label\n",
      " |      takeable : interpret the index/col as indexers, default False\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value : scalar value\n",
      " |  \n",
      " |  gt(self, other, axis='columns', level=None)\n",
      " |      Wrapper for flexible comparison methods gt\n",
      " |  \n",
      " |  hist = hist_frame(data, column=None, by=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None, ax=None, sharex=False, sharey=False, figsize=None, layout=None, bins=10, **kwds)\n",
      " |      Make a histogram of the DataFrame's.\n",
      " |      \n",
      " |      A `histogram`_ is a representation of the distribution of data.\n",
      " |      This function calls :meth:`matplotlib.pyplot.hist`, on each series in\n",
      " |      the DataFrame, resulting in one histogram per column.\n",
      " |      \n",
      " |      .. _histogram: https://en.wikipedia.org/wiki/Histogram\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DataFrame\n",
      " |          The pandas object holding the data.\n",
      " |      column : string or sequence\n",
      " |          If passed, will be used to limit data to a subset of columns.\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups.\n",
      " |      grid : boolean, default True\n",
      " |          Whether to show axis grid lines.\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size.\n",
      " |      xrot : float, default None\n",
      " |          Rotation of x axis labels. For example, a value of 90 displays the\n",
      " |          x labels rotated 90 degrees clockwise.\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size.\n",
      " |      yrot : float, default None\n",
      " |          Rotation of y axis labels. For example, a value of 90 displays the\n",
      " |          y labels rotated 90 degrees clockwise.\n",
      " |      ax : Matplotlib axes object, default None\n",
      " |          The axes to plot the histogram on.\n",
      " |      sharex : boolean, default True if ax is None else False\n",
      " |          In case subplots=True, share x axis and set some x axis labels to\n",
      " |          invisible; defaults to True if ax is None otherwise False if an ax\n",
      " |          is passed in.\n",
      " |          Note that passing in both an ax and sharex=True will alter all x axis\n",
      " |          labels for all subplots in a figure.\n",
      " |      sharey : boolean, default False\n",
      " |          In case subplots=True, share y axis and set some y axis labels to\n",
      " |          invisible.\n",
      " |      figsize : tuple\n",
      " |          The size in inches of the figure to create. Uses the value in\n",
      " |          `matplotlib.rcParams` by default.\n",
      " |      layout : tuple, optional\n",
      " |          Tuple of (rows, columns) for the layout of the histograms.\n",
      " |      bins : integer or sequence, default 10\n",
      " |          Number of histogram bins to be used. If an integer is given, bins + 1\n",
      " |          bin edges are calculated and returned. If bins is a sequence, gives\n",
      " |          bin edges, including left edge of first bin and right edge of last\n",
      " |          bin. In this case, bins is returned unmodified.\n",
      " |      **kwds\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          :meth:`matplotlib.pyplot.hist`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      axes : matplotlib.AxesSubplot or numpy.ndarray of them\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      matplotlib.pyplot.hist : Plot a histogram using matplotlib.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          This example draws a histogram based on the length and width of\n",
      " |          some animals, displayed in three bins\n",
      " |      \n",
      " |          >>> df = pd.DataFrame({\n",
      " |          ...     'length': [1.5, 0.5, 1.2, 0.9, 3],\n",
      " |          ...     'width': [0.7, 0.2, 0.15, 0.2, 1.1]\n",
      " |          ...     }, index= ['pig', 'rabbit', 'duck', 'chicken', 'horse'])\n",
      " |          >>> hist = df.hist(bins=3)\n",
      " |  \n",
      " |  idxmax(self, axis=0, skipna=True)\n",
      " |      Return index of first occurrence of maximum over requested axis.\n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmax : Series\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmax``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmax\n",
      " |  \n",
      " |  idxmin(self, axis=0, skipna=True)\n",
      " |      Return index of first occurrence of minimum over requested axis.\n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmin : Series\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmin``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmin\n",
      " |  \n",
      " |  info(self, verbose=None, buf=None, max_cols=None, memory_usage=None, null_counts=None)\n",
      " |      Print a concise summary of a DataFrame.\n",
      " |      \n",
      " |      This method prints information about a DataFrame including\n",
      " |      the index dtype and column dtypes, non-null values and memory usage.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      verbose : bool, optional\n",
      " |          Whether to print the full summary. By default, the setting in\n",
      " |          ``pandas.options.display.max_info_columns`` is followed.\n",
      " |      buf : writable buffer, defaults to sys.stdout\n",
      " |          Where to send the output. By default, the output is printed to\n",
      " |          sys.stdout. Pass a writable buffer if you need to further process\n",
      " |          the output.\n",
      " |      max_cols : int, optional\n",
      " |          When to switch from the verbose to the truncated output. If the\n",
      " |          DataFrame has more than `max_cols` columns, the truncated output\n",
      " |          is used. By default, the setting in\n",
      " |          ``pandas.options.display.max_info_columns`` is used.\n",
      " |      memory_usage : bool, str, optional\n",
      " |          Specifies whether total memory usage of the DataFrame\n",
      " |          elements (including the index) should be displayed. By default,\n",
      " |          this follows the ``pandas.options.display.memory_usage`` setting.\n",
      " |      \n",
      " |          True always show memory usage. False never shows memory usage.\n",
      " |          A value of 'deep' is equivalent to \"True with deep introspection\".\n",
      " |          Memory usage is shown in human-readable units (base-2\n",
      " |          representation). Without deep introspection a memory estimation is\n",
      " |          made based in column dtype and number of rows assuming values\n",
      " |          consume the same memory amount for corresponding dtypes. With deep\n",
      " |          memory introspection, a real memory usage calculation is performed\n",
      " |          at the cost of computational resources.\n",
      " |      null_counts : bool, optional\n",
      " |          Whether to show the non-null counts. By default, this is shown\n",
      " |          only if the frame is smaller than\n",
      " |          ``pandas.options.display.max_info_rows`` and\n",
      " |          ``pandas.options.display.max_info_columns``. A value of True always\n",
      " |          shows the counts, and False never shows the counts.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None\n",
      " |          This method prints a summary of a DataFrame and returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.describe: Generate descriptive statistics of DataFrame\n",
      " |          columns.\n",
      " |      DataFrame.memory_usage: Memory usage of DataFrame columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> int_values = [1, 2, 3, 4, 5]\n",
      " |      >>> text_values = ['alpha', 'beta', 'gamma', 'delta', 'epsilon']\n",
      " |      >>> float_values = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
      " |      >>> df = pd.DataFrame({\"int_col\": int_values, \"text_col\": text_values,\n",
      " |      ...                   \"float_col\": float_values})\n",
      " |      >>> df\n",
      " |         int_col text_col  float_col\n",
      " |      0        1    alpha       0.00\n",
      " |      1        2     beta       0.25\n",
      " |      2        3    gamma       0.50\n",
      " |      3        4    delta       0.75\n",
      " |      4        5  epsilon       1.00\n",
      " |      \n",
      " |      Prints information of all columns:\n",
      " |      \n",
      " |      >>> df.info(verbose=True)\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 5 entries, 0 to 4\n",
      " |      Data columns (total 3 columns):\n",
      " |      int_col      5 non-null int64\n",
      " |      text_col     5 non-null object\n",
      " |      float_col    5 non-null float64\n",
      " |      dtypes: float64(1), int64(1), object(1)\n",
      " |      memory usage: 200.0+ bytes\n",
      " |      \n",
      " |      Prints a summary of columns count and its dtypes but not per column\n",
      " |      information:\n",
      " |      \n",
      " |      >>> df.info(verbose=False)\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 5 entries, 0 to 4\n",
      " |      Columns: 3 entries, int_col to float_col\n",
      " |      dtypes: float64(1), int64(1), object(1)\n",
      " |      memory usage: 200.0+ bytes\n",
      " |      \n",
      " |      Pipe output of DataFrame.info to buffer instead of sys.stdout, get\n",
      " |      buffer content and writes to a text file:\n",
      " |      \n",
      " |      >>> import io\n",
      " |      >>> buffer = io.StringIO()\n",
      " |      >>> df.info(buf=buffer)\n",
      " |      >>> s = buffer.getvalue()\n",
      " |      >>> with open(\"df_info.txt\", \"w\", encoding=\"utf-8\") as f:\n",
      " |      ...     f.write(s)\n",
      " |      260\n",
      " |      \n",
      " |      The `memory_usage` parameter allows deep introspection mode, specially\n",
      " |      useful for big DataFrames and fine-tune memory optimization:\n",
      " |      \n",
      " |      >>> random_strings_array = np.random.choice(['a', 'b', 'c'], 10 ** 6)\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'column_1': np.random.choice(['a', 'b', 'c'], 10 ** 6),\n",
      " |      ...     'column_2': np.random.choice(['a', 'b', 'c'], 10 ** 6),\n",
      " |      ...     'column_3': np.random.choice(['a', 'b', 'c'], 10 ** 6)\n",
      " |      ... })\n",
      " |      >>> df.info()\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 1000000 entries, 0 to 999999\n",
      " |      Data columns (total 3 columns):\n",
      " |      column_1    1000000 non-null object\n",
      " |      column_2    1000000 non-null object\n",
      " |      column_3    1000000 non-null object\n",
      " |      dtypes: object(3)\n",
      " |      memory usage: 22.9+ MB\n",
      " |      \n",
      " |      >>> df.info(memory_usage='deep')\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 1000000 entries, 0 to 999999\n",
      " |      Data columns (total 3 columns):\n",
      " |      column_1    1000000 non-null object\n",
      " |      column_2    1000000 non-null object\n",
      " |      column_3    1000000 non-null object\n",
      " |      dtypes: object(3)\n",
      " |      memory usage: 188.8 MB\n",
      " |  \n",
      " |  insert(self, loc, column, value, allow_duplicates=False)\n",
      " |      Insert column into DataFrame at specified location.\n",
      " |      \n",
      " |      Raises a ValueError if `column` is already contained in the DataFrame,\n",
      " |      unless `allow_duplicates` is set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      loc : int\n",
      " |          Insertion index. Must verify 0 <= loc <= len(columns)\n",
      " |      column : string, number, or hashable object\n",
      " |          label of the inserted column\n",
      " |      value : int, Series, or array-like\n",
      " |      allow_duplicates : bool, optional\n",
      " |  \n",
      " |  isin(self, values)\n",
      " |      Return boolean DataFrame showing whether each element in the\n",
      " |      DataFrame is contained in values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : iterable, Series, DataFrame or dictionary\n",
      " |          The result will only be true at a location if all the\n",
      " |          labels match. If `values` is a Series, that's the index. If\n",
      " |          `values` is a dictionary, the keys must be the column names,\n",
      " |          which must match. If `values` is a DataFrame,\n",
      " |          then both the index and column labels must match.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      \n",
      " |      DataFrame of booleans\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      When ``values`` is a list:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'f']})\n",
      " |      >>> df.isin([1, 3, 12, 'a'])\n",
      " |             A      B\n",
      " |      0   True   True\n",
      " |      1  False  False\n",
      " |      2   True  False\n",
      " |      \n",
      " |      When ``values`` is a dict:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [1, 4, 7]})\n",
      " |      >>> df.isin({'A': [1, 3], 'B': [4, 7, 12]})\n",
      " |             A      B\n",
      " |      0   True  False  # Note that B didn't match the 1 here.\n",
      " |      1  False   True\n",
      " |      2   True   True\n",
      " |      \n",
      " |      When ``values`` is a Series or DataFrame:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'f']})\n",
      " |      >>> other = DataFrame({'A': [1, 3, 3, 2], 'B': ['e', 'f', 'f', 'e']})\n",
      " |      >>> df.isin(other)\n",
      " |             A      B\n",
      " |      0   True  False\n",
      " |      1  False  False  # Column A in `other` has a 3, but not at index 1.\n",
      " |      2   True   True\n",
      " |  \n",
      " |  isna(self)\n",
      " |      Detect missing values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isnull : alias of isna\n",
      " |      DataFrame.notna : boolean inverse of isna\n",
      " |      DataFrame.dropna : omit axes labels with missing values\n",
      " |      isna : top-level isna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |      \n",
      " |      Show which entries in a Series are NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  isnull(self)\n",
      " |      Detect missing values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isnull : alias of isna\n",
      " |      DataFrame.notna : boolean inverse of isna\n",
      " |      DataFrame.dropna : omit axes labels with missing values\n",
      " |      isna : top-level isna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |      \n",
      " |      Show which entries in a Series are NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  items = iteritems(self)\n",
      " |  \n",
      " |  iteritems(self)\n",
      " |      Iterator over (column name, Series) pairs.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      iterrows : Iterate over DataFrame rows as (index, Series) pairs.\n",
      " |      itertuples : Iterate over DataFrame rows as namedtuples of the values.\n",
      " |  \n",
      " |  iterrows(self)\n",
      " |      Iterate over DataFrame rows as (index, Series) pairs.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      1. Because ``iterrows`` returns a Series for each row,\n",
      " |         it does **not** preserve dtypes across the rows (dtypes are\n",
      " |         preserved across columns for DataFrames). For example,\n",
      " |      \n",
      " |         >>> df = pd.DataFrame([[1, 1.5]], columns=['int', 'float'])\n",
      " |         >>> row = next(df.iterrows())[1]\n",
      " |         >>> row\n",
      " |         int      1.0\n",
      " |         float    1.5\n",
      " |         Name: 0, dtype: float64\n",
      " |         >>> print(row['int'].dtype)\n",
      " |         float64\n",
      " |         >>> print(df['int'].dtype)\n",
      " |         int64\n",
      " |      \n",
      " |         To preserve dtypes while iterating over the rows, it is better\n",
      " |         to use :meth:`itertuples` which returns namedtuples of the values\n",
      " |         and which is generally faster than ``iterrows``.\n",
      " |      \n",
      " |      2. You should **never modify** something you are iterating over.\n",
      " |         This is not guaranteed to work in all cases. Depending on the\n",
      " |         data types, the iterator returns a copy and not a view, and writing\n",
      " |         to it will have no effect.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      it : generator\n",
      " |          A generator that iterates over the rows of the frame.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      itertuples : Iterate over DataFrame rows as namedtuples of the values.\n",
      " |      iteritems : Iterate over (column name, Series) pairs.\n",
      " |  \n",
      " |  itertuples(self, index=True, name='Pandas')\n",
      " |      Iterate over DataFrame rows as namedtuples, with index value as first\n",
      " |      element of the tuple.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : boolean, default True\n",
      " |          If True, return the index as the first element of the tuple.\n",
      " |      name : string, default \"Pandas\"\n",
      " |          The name of the returned namedtuples or None to return regular\n",
      " |          tuples.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The column names will be renamed to positional names if they are\n",
      " |      invalid Python identifiers, repeated, or start with an underscore.\n",
      " |      With a large number of columns (>255), regular tuples are returned.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      iterrows : Iterate over DataFrame rows as (index, Series) pairs.\n",
      " |      iteritems : Iterate over (column name, Series) pairs.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [0.1, 0.2]},\n",
      " |                            index=['a', 'b'])\n",
      " |      >>> df\n",
      " |         col1  col2\n",
      " |      a     1   0.1\n",
      " |      b     2   0.2\n",
      " |      >>> for row in df.itertuples():\n",
      " |      ...     print(row)\n",
      " |      ...\n",
      " |      Pandas(Index='a', col1=1, col2=0.10000000000000001)\n",
      " |      Pandas(Index='b', col1=2, col2=0.20000000000000001)\n",
      " |  \n",
      " |  join(self, other, on=None, how='left', lsuffix='', rsuffix='', sort=False)\n",
      " |      Join columns with other DataFrame either on index or on a key\n",
      " |      column. Efficiently Join multiple DataFrame objects by index at once by\n",
      " |      passing a list.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, Series with name field set, or list of DataFrame\n",
      " |          Index should be similar to one of the columns in this one. If a\n",
      " |          Series is passed, its name attribute must be set, and that will be\n",
      " |          used as the column name in the resulting joined DataFrame\n",
      " |      on : name, tuple/list of names, or array-like\n",
      " |          Column or index level name(s) in the caller to join on the index\n",
      " |          in `other`, otherwise joins index-on-index. If multiple\n",
      " |          values given, the `other` DataFrame must have a MultiIndex. Can\n",
      " |          pass an array as the join key if it is not already contained in\n",
      " |          the calling DataFrame. Like an Excel VLOOKUP operation\n",
      " |      how : {'left', 'right', 'outer', 'inner'}, default: 'left'\n",
      " |          How to handle the operation of the two objects.\n",
      " |      \n",
      " |          * left: use calling frame's index (or column if on is specified)\n",
      " |          * right: use other frame's index\n",
      " |          * outer: form union of calling frame's index (or column if on is\n",
      " |            specified) with other frame's index, and sort it\n",
      " |            lexicographically\n",
      " |          * inner: form intersection of calling frame's index (or column if\n",
      " |            on is specified) with other frame's index, preserving the order\n",
      " |            of the calling's one\n",
      " |      lsuffix : string\n",
      " |          Suffix to use from left frame's overlapping columns\n",
      " |      rsuffix : string\n",
      " |          Suffix to use from right frame's overlapping columns\n",
      " |      sort : boolean, default False\n",
      " |          Order result DataFrame lexicographically by the join key. If False,\n",
      " |          the order of the join key depends on the join type (how keyword)\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      on, lsuffix, and rsuffix options are not supported when passing a list\n",
      " |      of DataFrame objects\n",
      " |      \n",
      " |      Support for specifying index levels as the `on` parameter was added\n",
      " |      in version 0.23.0\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> caller = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'],\n",
      " |      ...                        'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n",
      " |      \n",
      " |      >>> caller\n",
      " |          A key\n",
      " |      0  A0  K0\n",
      " |      1  A1  K1\n",
      " |      2  A2  K2\n",
      " |      3  A3  K3\n",
      " |      4  A4  K4\n",
      " |      5  A5  K5\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'key': ['K0', 'K1', 'K2'],\n",
      " |      ...                       'B': ['B0', 'B1', 'B2']})\n",
      " |      \n",
      " |      >>> other\n",
      " |          B key\n",
      " |      0  B0  K0\n",
      " |      1  B1  K1\n",
      " |      2  B2  K2\n",
      " |      \n",
      " |      Join DataFrames using their indexes.\n",
      " |      \n",
      " |      >>> caller.join(other, lsuffix='_caller', rsuffix='_other')\n",
      " |      \n",
      " |      >>>     A key_caller    B key_other\n",
      " |          0  A0         K0   B0        K0\n",
      " |          1  A1         K1   B1        K1\n",
      " |          2  A2         K2   B2        K2\n",
      " |          3  A3         K3  NaN       NaN\n",
      " |          4  A4         K4  NaN       NaN\n",
      " |          5  A5         K5  NaN       NaN\n",
      " |      \n",
      " |      \n",
      " |      If we want to join using the key columns, we need to set key to be\n",
      " |      the index in both caller and other. The joined DataFrame will have\n",
      " |      key as its index.\n",
      " |      \n",
      " |      >>> caller.set_index('key').join(other.set_index('key'))\n",
      " |      \n",
      " |      >>>      A    B\n",
      " |          key\n",
      " |          K0   A0   B0\n",
      " |          K1   A1   B1\n",
      " |          K2   A2   B2\n",
      " |          K3   A3  NaN\n",
      " |          K4   A4  NaN\n",
      " |          K5   A5  NaN\n",
      " |      \n",
      " |      Another option to join using the key columns is to use the on\n",
      " |      parameter. DataFrame.join always uses other's index but we can use any\n",
      " |      column in the caller. This method preserves the original caller's\n",
      " |      index in the result.\n",
      " |      \n",
      " |      >>> caller.join(other.set_index('key'), on='key')\n",
      " |      \n",
      " |      >>>     A key    B\n",
      " |          0  A0  K0   B0\n",
      " |          1  A1  K1   B1\n",
      " |          2  A2  K2   B2\n",
      " |          3  A3  K3  NaN\n",
      " |          4  A4  K4  NaN\n",
      " |          5  A5  K5  NaN\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.merge : For column(s)-on-columns(s) operations\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      joined : DataFrame\n",
      " |  \n",
      " |  kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased kurtosis over requested axis using Fisher's definition of\n",
      " |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      kurt : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |  \n",
      " |  le(self, other, axis='columns', level=None)\n",
      " |      Wrapper for flexible comparison methods le\n",
      " |  \n",
      " |  lookup(self, row_labels, col_labels)\n",
      " |      Label-based \"fancy indexing\" function for DataFrame.\n",
      " |      Given equal-length arrays of row and column labels, return an\n",
      " |      array of the values corresponding to each (row, col) pair.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      row_labels : sequence\n",
      " |          The row labels to use for lookup\n",
      " |      col_labels : sequence\n",
      " |          The column labels to use for lookup\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Akin to::\n",
      " |      \n",
      " |          result = []\n",
      " |          for row, col in zip(row_labels, col_labels):\n",
      " |              result.append(df.get_value(row, col))\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      values : ndarray\n",
      " |          The found values\n",
      " |  \n",
      " |  lt(self, other, axis='columns', level=None)\n",
      " |      Wrapper for flexible comparison methods lt\n",
      " |  \n",
      " |  mad(self, axis=None, skipna=None, level=None)\n",
      " |      Return the mean absolute deviation of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mad : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      This method returns the maximum of the values in the object.\n",
      " |                  If you want the *index* of the maximum, use ``idxmax``. This is\n",
      " |                  the equivalent of the ``numpy.ndarray`` method ``argmax``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      max : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the mean of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mean : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the median of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      median : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  melt(self, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None)\n",
      " |      \"Unpivots\" a DataFrame from wide format to long format, optionally\n",
      " |      leaving identifier variables set.\n",
      " |      \n",
      " |      This function is useful to massage a DataFrame into a format where one\n",
      " |      or more columns are identifier variables (`id_vars`), while all other\n",
      " |      columns, considered measured variables (`value_vars`), are \"unpivoted\" to\n",
      " |      the row axis, leaving just two non-identifier columns, 'variable' and\n",
      " |      'value'.\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      frame : DataFrame\n",
      " |      id_vars : tuple, list, or ndarray, optional\n",
      " |          Column(s) to use as identifier variables.\n",
      " |      value_vars : tuple, list, or ndarray, optional\n",
      " |          Column(s) to unpivot. If not specified, uses all columns that\n",
      " |          are not set as `id_vars`.\n",
      " |      var_name : scalar\n",
      " |          Name to use for the 'variable' column. If None it uses\n",
      " |          ``frame.columns.name`` or 'variable'.\n",
      " |      value_name : scalar, default 'value'\n",
      " |          Name to use for the 'value' column.\n",
      " |      col_level : int or string, optional\n",
      " |          If columns are a MultiIndex then use this level to melt.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      melt\n",
      " |      pivot_table\n",
      " |      DataFrame.pivot\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> df = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},\n",
      " |      ...                    'B': {0: 1, 1: 3, 2: 5},\n",
      " |      ...                    'C': {0: 2, 1: 4, 2: 6}})\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      0  a  1  2\n",
      " |      1  b  3  4\n",
      " |      2  c  5  6\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B'])\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B', 'C'])\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      3  a        C      2\n",
      " |      4  b        C      4\n",
      " |      5  c        C      6\n",
      " |      \n",
      " |      The names of 'variable' and 'value' columns can be customized:\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B'],\n",
      " |      ...         var_name='myVarname', value_name='myValname')\n",
      " |         A myVarname  myValname\n",
      " |      0  a         B          1\n",
      " |      1  b         B          3\n",
      " |      2  c         B          5\n",
      " |      \n",
      " |      If you have multi-index columns:\n",
      " |      \n",
      " |      >>> df.columns = [list('ABC'), list('DEF')]\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |         D  E  F\n",
      " |      0  a  1  2\n",
      " |      1  b  3  4\n",
      " |      2  c  5  6\n",
      " |      \n",
      " |      >>> df.melt(col_level=0, id_vars=['A'], value_vars=['B'])\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      \n",
      " |      >>> df.melt(id_vars=[('A', 'D')], value_vars=[('B', 'E')])\n",
      " |        (A, D) variable_0 variable_1  value\n",
      " |      0      a          B          E      1\n",
      " |      1      b          B          E      3\n",
      " |      2      c          B          E      5\n",
      " |  \n",
      " |  memory_usage(self, index=True, deep=False)\n",
      " |      Return the memory usage of each column in bytes.\n",
      " |      \n",
      " |      The memory usage can optionally include the contribution of\n",
      " |      the index and elements of `object` dtype.\n",
      " |      \n",
      " |      This value is displayed in `DataFrame.info` by default. This can be\n",
      " |      suppressed by setting ``pandas.options.display.memory_usage`` to False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          Specifies whether to include the memory usage of the DataFrame's\n",
      " |          index in returned Series. If ``index=True`` the memory usage of the\n",
      " |          index the first item in the output.\n",
      " |      deep : bool, default False\n",
      " |          If True, introspect the data deeply by interrogating\n",
      " |          `object` dtypes for system-level memory consumption, and include\n",
      " |          it in the returned values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sizes : Series\n",
      " |          A Series whose index is the original column names and whose values\n",
      " |          is the memory usage of each column in bytes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.nbytes : Total bytes consumed by the elements of an\n",
      " |          ndarray.\n",
      " |      Series.memory_usage : Bytes consumed by a Series.\n",
      " |      pandas.Categorical : Memory-efficient array for string values with\n",
      " |          many repeated values.\n",
      " |      DataFrame.info : Concise summary of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> dtypes = ['int64', 'float64', 'complex128', 'object', 'bool']\n",
      " |      >>> data = dict([(t, np.ones(shape=5000).astype(t))\n",
      " |      ...              for t in dtypes])\n",
      " |      >>> df = pd.DataFrame(data)\n",
      " |      >>> df.head()\n",
      " |         int64  float64  complex128 object  bool\n",
      " |      0      1      1.0      (1+0j)      1  True\n",
      " |      1      1      1.0      (1+0j)      1  True\n",
      " |      2      1      1.0      (1+0j)      1  True\n",
      " |      3      1      1.0      (1+0j)      1  True\n",
      " |      4      1      1.0      (1+0j)      1  True\n",
      " |      \n",
      " |      >>> df.memory_usage()\n",
      " |      Index            80\n",
      " |      int64         40000\n",
      " |      float64       40000\n",
      " |      complex128    80000\n",
      " |      object        40000\n",
      " |      bool           5000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.memory_usage(index=False)\n",
      " |      int64         40000\n",
      " |      float64       40000\n",
      " |      complex128    80000\n",
      " |      object        40000\n",
      " |      bool           5000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The memory footprint of `object` dtype columns is ignored by default:\n",
      " |      \n",
      " |      >>> df.memory_usage(deep=True)\n",
      " |      Index             80\n",
      " |      int64          40000\n",
      " |      float64        40000\n",
      " |      complex128     80000\n",
      " |      object        160000\n",
      " |      bool            5000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Use a Categorical for efficient storage of an object-dtype column with\n",
      " |      many repeated values.\n",
      " |      \n",
      " |      >>> df['object'].astype('category').memory_usage(deep=True)\n",
      " |      5168\n",
      " |  \n",
      " |  merge(self, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None)\n",
      " |      Merge DataFrame objects by performing a database-style join operation by\n",
      " |      columns or indexes.\n",
      " |      \n",
      " |      If joining columns on columns, the DataFrame indexes *will be\n",
      " |      ignored*. Otherwise if joining indexes on indexes or indexes on a column or\n",
      " |      columns, the index will be passed on.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      right : DataFrame\n",
      " |      how : {'left', 'right', 'outer', 'inner'}, default 'inner'\n",
      " |          * left: use only keys from left frame, similar to a SQL left outer join;\n",
      " |            preserve key order\n",
      " |          * right: use only keys from right frame, similar to a SQL right outer join;\n",
      " |            preserve key order\n",
      " |          * outer: use union of keys from both frames, similar to a SQL full outer\n",
      " |            join; sort keys lexicographically\n",
      " |          * inner: use intersection of keys from both frames, similar to a SQL inner\n",
      " |            join; preserve the order of the left keys\n",
      " |      on : label or list\n",
      " |          Column or index level names to join on. These must be found in both\n",
      " |          DataFrames. If `on` is None and not merging on indexes then this defaults\n",
      " |          to the intersection of the columns in both DataFrames.\n",
      " |      left_on : label or list, or array-like\n",
      " |          Column or index level names to join on in the left DataFrame. Can also\n",
      " |          be an array or list of arrays of the length of the left DataFrame.\n",
      " |          These arrays are treated as if they are columns.\n",
      " |      right_on : label or list, or array-like\n",
      " |          Column or index level names to join on in the right DataFrame. Can also\n",
      " |          be an array or list of arrays of the length of the right DataFrame.\n",
      " |          These arrays are treated as if they are columns.\n",
      " |      left_index : boolean, default False\n",
      " |          Use the index from the left DataFrame as the join key(s). If it is a\n",
      " |          MultiIndex, the number of keys in the other DataFrame (either the index\n",
      " |          or a number of columns) must match the number of levels\n",
      " |      right_index : boolean, default False\n",
      " |          Use the index from the right DataFrame as the join key. Same caveats as\n",
      " |          left_index\n",
      " |      sort : boolean, default False\n",
      " |          Sort the join keys lexicographically in the result DataFrame. If False,\n",
      " |          the order of the join keys depends on the join type (how keyword)\n",
      " |      suffixes : 2-length sequence (tuple, list, ...)\n",
      " |          Suffix to apply to overlapping column names in the left and right\n",
      " |          side, respectively\n",
      " |      copy : boolean, default True\n",
      " |          If False, do not copy data unnecessarily\n",
      " |      indicator : boolean or string, default False\n",
      " |          If True, adds a column to output DataFrame called \"_merge\" with\n",
      " |          information on the source of each row.\n",
      " |          If string, column with information on source of each row will be added to\n",
      " |          output DataFrame, and column will be named value of string.\n",
      " |          Information column is Categorical-type and takes on a value of \"left_only\"\n",
      " |          for observations whose merge key only appears in 'left' DataFrame,\n",
      " |          \"right_only\" for observations whose merge key only appears in 'right'\n",
      " |          DataFrame, and \"both\" if the observation's merge key is found in both.\n",
      " |      \n",
      " |      validate : string, default None\n",
      " |          If specified, checks if merge is of specified type.\n",
      " |      \n",
      " |          * \"one_to_one\" or \"1:1\": check if merge keys are unique in both\n",
      " |            left and right datasets.\n",
      " |          * \"one_to_many\" or \"1:m\": check if merge keys are unique in left\n",
      " |            dataset.\n",
      " |          * \"many_to_one\" or \"m:1\": check if merge keys are unique in right\n",
      " |            dataset.\n",
      " |          * \"many_to_many\" or \"m:m\": allowed, but does not result in checks.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Support for specifying index levels as the `on`, `left_on`, and\n",
      " |      `right_on` parameters was added in version 0.23.0\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> A              >>> B\n",
      " |          lkey value         rkey value\n",
      " |      0   foo  1         0   foo  5\n",
      " |      1   bar  2         1   bar  6\n",
      " |      2   baz  3         2   qux  7\n",
      " |      3   foo  4         3   bar  8\n",
      " |      \n",
      " |      >>> A.merge(B, left_on='lkey', right_on='rkey', how='outer')\n",
      " |         lkey  value_x  rkey  value_y\n",
      " |      0  foo   1        foo   5\n",
      " |      1  foo   4        foo   5\n",
      " |      2  bar   2        bar   6\n",
      " |      3  bar   2        bar   8\n",
      " |      4  baz   3        NaN   NaN\n",
      " |      5  NaN   NaN      qux   7\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      merged : DataFrame\n",
      " |          The output type will the be same as 'left', if it is a subclass\n",
      " |          of DataFrame.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      merge_ordered\n",
      " |      merge_asof\n",
      " |      DataFrame.join\n",
      " |  \n",
      " |  min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      This method returns the minimum of the values in the object.\n",
      " |                  If you want the *index* of the minimum, use ``idxmin``. This is\n",
      " |                  the equivalent of the ``numpy.ndarray`` method ``argmin``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      min : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  mod(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Modulo of dataframe and other, element-wise (binary operator `mod`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe % other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      None\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.rmod\n",
      " |  \n",
      " |  mode(self, axis=0, numeric_only=False)\n",
      " |      Gets the mode(s) of each element along the axis selected. Adds a row\n",
      " |      for each mode per label, fills in gaps with nan.\n",
      " |      \n",
      " |      Note that there could be multiple values returned for the selected\n",
      " |      axis (when more than one item share the maximum frequency), which is\n",
      " |      the reason why a dataframe is returned. If you want to impute missing\n",
      " |      values with the mode in a dataframe ``df``, you can just do this:\n",
      " |      ``df.fillna(df.mode().iloc[0])``\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          * 0 or 'index' : get mode of each column\n",
      " |          * 1 or 'columns' : get mode of each row\n",
      " |      numeric_only : boolean, default False\n",
      " |          if True, only apply to numeric columns\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      modes : DataFrame (sorted)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 1, 2, 1, 2, 3]})\n",
      " |      >>> df.mode()\n",
      " |         A\n",
      " |      0  1\n",
      " |      1  2\n",
      " |  \n",
      " |  mul(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Multiplication of dataframe and other, element-wise (binary operator `mul`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe * other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      None\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.rmul\n",
      " |  \n",
      " |  multiply = mul(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  ne(self, other, axis='columns', level=None)\n",
      " |      Wrapper for flexible comparison methods ne\n",
      " |  \n",
      " |  nlargest(self, n, columns, keep='first')\n",
      " |      Return the first `n` rows ordered by `columns` in descending order.\n",
      " |      \n",
      " |      Return the first `n` rows with the largest values in `columns`, in\n",
      " |      descending order. The columns that are not specified are returned as\n",
      " |      well, but not used for ordering.\n",
      " |      \n",
      " |      This method is equivalent to\n",
      " |      ``df.sort_values(columns, ascending=False).head(n)``, but more\n",
      " |      performant.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Number of rows to return.\n",
      " |      columns : label or list of labels\n",
      " |          Column label(s) to order by.\n",
      " |      keep : {'first', 'last'}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |      \n",
      " |          - `first` : prioritize the first occurrence(s)\n",
      " |          - `last` : prioritize the last occurrence(s)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The first `n` rows ordered by the given columns in descending\n",
      " |          order.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.nsmallest : Return the first `n` rows ordered by `columns` in\n",
      " |          ascending order.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the values\n",
      " |      DataFrame.head : Return the first `n` rows without re-ordering.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function cannot be used with all column types. For example, when\n",
      " |      specifying columns with `object` or `category` dtypes, ``TypeError`` is\n",
      " |      raised.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'a': [1, 10, 8, 10, -1],\n",
      " |      ...                    'b': list('abdce'),\n",
      " |      ...                    'c': [1.0, 2.0, np.nan, 3.0, 4.0]})\n",
      " |      >>> df\n",
      " |          a  b    c\n",
      " |      0   1  a  1.0\n",
      " |      1  10  b  2.0\n",
      " |      2   8  d  NaN\n",
      " |      3  10  c  3.0\n",
      " |      4  -1  e  4.0\n",
      " |      \n",
      " |      In the following example, we will use ``nlargest`` to select the three\n",
      " |      rows having the largest values in column \"a\".\n",
      " |      \n",
      " |      >>> df.nlargest(3, 'a')\n",
      " |          a  b    c\n",
      " |      1  10  b  2.0\n",
      " |      3  10  c  3.0\n",
      " |      2   8  d  NaN\n",
      " |      \n",
      " |      When using ``keep='last'``, ties are resolved in reverse order:\n",
      " |      \n",
      " |      >>> df.nlargest(3, 'a', keep='last')\n",
      " |          a  b    c\n",
      " |      3  10  c  3.0\n",
      " |      1  10  b  2.0\n",
      " |      2   8  d  NaN\n",
      " |      \n",
      " |      To order by the largest values in column \"a\" and then \"c\", we can\n",
      " |      specify multiple columns like in the next example.\n",
      " |      \n",
      " |      >>> df.nlargest(3, ['a', 'c'])\n",
      " |          a  b    c\n",
      " |      3  10  c  3.0\n",
      " |      1  10  b  2.0\n",
      " |      2   8  d  NaN\n",
      " |      \n",
      " |      Attempting to use ``nlargest`` on non-numeric dtypes will raise a\n",
      " |      ``TypeError``:\n",
      " |      \n",
      " |      >>> df.nlargest(3, 'b')\n",
      " |      Traceback (most recent call last):\n",
      " |      TypeError: Column 'b' has dtype object, cannot use method 'nlargest'\n",
      " |  \n",
      " |  notna(self)\n",
      " |      Detect existing (non-missing) values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.notnull : alias of notna\n",
      " |      DataFrame.isna : boolean inverse of notna\n",
      " |      DataFrame.dropna : omit axes labels with missing values\n",
      " |      notna : top-level notna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |      \n",
      " |      Show which entries in a Series are not NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  notnull(self)\n",
      " |      Detect existing (non-missing) values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.notnull : alias of notna\n",
      " |      DataFrame.isna : boolean inverse of notna\n",
      " |      DataFrame.dropna : omit axes labels with missing values\n",
      " |      notna : top-level notna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |      \n",
      " |      Show which entries in a Series are not NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  nsmallest(self, n, columns, keep='first')\n",
      " |      Get the rows of a DataFrame sorted by the `n` smallest\n",
      " |      values of `columns`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Number of items to retrieve\n",
      " |      columns : list or str\n",
      " |          Column name or names to order by\n",
      " |      keep : {'first', 'last'}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |          - ``first`` : take the first occurrence.\n",
      " |          - ``last`` : take the last occurrence.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'a': [1, 10, 8, 11, -1],\n",
      " |      ...                    'b': list('abdce'),\n",
      " |      ...                    'c': [1.0, 2.0, np.nan, 3.0, 4.0]})\n",
      " |      >>> df.nsmallest(3, 'a')\n",
      " |         a  b   c\n",
      " |      4 -1  e   4\n",
      " |      0  1  a   1\n",
      " |      2  8  d NaN\n",
      " |  \n",
      " |  nunique(self, axis=0, dropna=True)\n",
      " |      Return Series with number of distinct observations over requested\n",
      " |      axis.\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |      dropna : boolean, default True\n",
      " |          Don't include NaN in the counts.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      nunique : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [1, 1, 1]})\n",
      " |      >>> df.nunique()\n",
      " |      A    3\n",
      " |      B    1\n",
      " |      \n",
      " |      >>> df.nunique(axis=1)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    2\n",
      " |  \n",
      " |  pivot(self, index=None, columns=None, values=None)\n",
      " |      Return reshaped DataFrame organized by given index / column values.\n",
      " |      \n",
      " |      Reshape data (produce a \"pivot\" table) based on column values. Uses\n",
      " |      unique values from specified `index` / `columns` to form axes of the\n",
      " |      resulting DataFrame. This function does not support data\n",
      " |      aggregation, multiple values will result in a MultiIndex in the\n",
      " |      columns. See the :ref:`User Guide <reshaping>` for more on reshaping.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : string or object, optional\n",
      " |          Column to use to make new frame's index. If None, uses\n",
      " |          existing index.\n",
      " |      columns : string or object\n",
      " |          Column to use to make new frame's columns.\n",
      " |      values : string, object or a list of the previous, optional\n",
      " |          Column(s) to use for populating new frame's values. If not\n",
      " |          specified, all remaining columns will be used and the result will\n",
      " |          have hierarchically indexed columns.\n",
      " |      \n",
      " |          .. versionchanged :: 0.23.0\n",
      " |             Also accept list of column names.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Returns reshaped DataFrame.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError:\n",
      " |          When there are any `index`, `columns` combinations with multiple\n",
      " |          values. `DataFrame.pivot_table` when you need to aggregate.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.pivot_table : generalization of pivot that can handle\n",
      " |          duplicate values for one index/column pair.\n",
      " |      DataFrame.unstack : pivot based on the index values instead of a\n",
      " |          column.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For finer-tuned control, see hierarchical indexing documentation along\n",
      " |      with the related stack/unstack methods.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two',\n",
      " |      ...                            'two'],\n",
      " |      ...                    'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
      " |      ...                    'baz': [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'zoo': ['x', 'y', 'z', 'q', 'w', 't']})\n",
      " |      >>> df\n",
      " |          foo   bar  baz  zoo\n",
      " |      0   one   A    1    x\n",
      " |      1   one   B    2    y\n",
      " |      2   one   C    3    z\n",
      " |      3   two   A    4    q\n",
      " |      4   two   B    5    w\n",
      " |      5   two   C    6    t\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar', values='baz')\n",
      " |      bar  A   B   C\n",
      " |      foo\n",
      " |      one  1   2   3\n",
      " |      two  4   5   6\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar')['baz']\n",
      " |      bar  A   B   C\n",
      " |      foo\n",
      " |      one  1   2   3\n",
      " |      two  4   5   6\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar', values=['baz', 'zoo'])\n",
      " |            baz       zoo\n",
      " |      bar   A  B  C   A  B  C\n",
      " |      foo\n",
      " |      one   1  2  3   x  y  z\n",
      " |      two   4  5  6   q  w  t\n",
      " |      \n",
      " |      A ValueError is raised if there are any duplicates.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"foo\": ['one', 'one', 'two', 'two'],\n",
      " |      ...                    \"bar\": ['A', 'A', 'B', 'C'],\n",
      " |      ...                    \"baz\": [1, 2, 3, 4]})\n",
      " |      >>> df\n",
      " |         foo bar  baz\n",
      " |      0  one   A    1\n",
      " |      1  one   A    2\n",
      " |      2  two   B    3\n",
      " |      3  two   C    4\n",
      " |      \n",
      " |      Notice that the first two rows are the same for our `index`\n",
      " |      and `columns` arguments.\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar', values='baz')\n",
      " |      Traceback (most recent call last):\n",
      " |         ...\n",
      " |      ValueError: Index contains duplicate entries, cannot reshape\n",
      " |  \n",
      " |  pivot_table(self, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All')\n",
      " |      Create a spreadsheet-style pivot table as a DataFrame. The levels in\n",
      " |      the pivot table will be stored in MultiIndex objects (hierarchical\n",
      " |      indexes) on the index and columns of the result DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : column to aggregate, optional\n",
      " |      index : column, Grouper, array, or list of the previous\n",
      " |          If an array is passed, it must be the same length as the data. The\n",
      " |          list can contain any of the other types (except list).\n",
      " |          Keys to group by on the pivot table index.  If an array is passed,\n",
      " |          it is being used as the same manner as column values.\n",
      " |      columns : column, Grouper, array, or list of the previous\n",
      " |          If an array is passed, it must be the same length as the data. The\n",
      " |          list can contain any of the other types (except list).\n",
      " |          Keys to group by on the pivot table column.  If an array is passed,\n",
      " |          it is being used as the same manner as column values.\n",
      " |      aggfunc : function, list of functions, dict, default numpy.mean\n",
      " |          If list of functions passed, the resulting pivot table will have\n",
      " |          hierarchical columns whose top level are the function names\n",
      " |          (inferred from the function objects themselves)\n",
      " |          If dict is passed, the key is column to aggregate and value\n",
      " |          is function or list of functions\n",
      " |      fill_value : scalar, default None\n",
      " |          Value to replace missing values with\n",
      " |      margins : boolean, default False\n",
      " |          Add all row / columns (e.g. for subtotal / grand totals)\n",
      " |      dropna : boolean, default True\n",
      " |          Do not include columns whose entries are all NaN\n",
      " |      margins_name : string, default 'All'\n",
      " |          Name of the row / column that will contain the totals\n",
      " |          when margins is True.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
      " |      ...                          \"bar\", \"bar\", \"bar\", \"bar\"],\n",
      " |      ...                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
      " |      ...                          \"one\", \"one\", \"two\", \"two\"],\n",
      " |      ...                    \"C\": [\"small\", \"large\", \"large\", \"small\",\n",
      " |      ...                          \"small\", \"large\", \"small\", \"small\",\n",
      " |      ...                          \"large\"],\n",
      " |      ...                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7]})\n",
      " |      >>> df\n",
      " |           A    B      C  D\n",
      " |      0  foo  one  small  1\n",
      " |      1  foo  one  large  2\n",
      " |      2  foo  one  large  2\n",
      " |      3  foo  two  small  3\n",
      " |      4  foo  two  small  3\n",
      " |      5  bar  one  large  4\n",
      " |      6  bar  one  small  5\n",
      " |      7  bar  two  small  6\n",
      " |      8  bar  two  large  7\n",
      " |      \n",
      " |      >>> table = pivot_table(df, values='D', index=['A', 'B'],\n",
      " |      ...                     columns=['C'], aggfunc=np.sum)\n",
      " |      >>> table\n",
      " |      C        large  small\n",
      " |      A   B\n",
      " |      bar one    4.0    5.0\n",
      " |          two    7.0    6.0\n",
      " |      foo one    4.0    1.0\n",
      " |          two    NaN    6.0\n",
      " |      \n",
      " |      >>> table = pivot_table(df, values='D', index=['A', 'B'],\n",
      " |      ...                     columns=['C'], aggfunc=np.sum)\n",
      " |      >>> table\n",
      " |      C        large  small\n",
      " |      A   B\n",
      " |      bar one    4.0    5.0\n",
      " |          two    7.0    6.0\n",
      " |      foo one    4.0    1.0\n",
      " |          two    NaN    6.0\n",
      " |      \n",
      " |      >>> table = pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
      " |      ...                     aggfunc={'D': np.mean,\n",
      " |      ...                              'E': [min, max, np.mean]})\n",
      " |      >>> table\n",
      " |                        D   E\n",
      " |                     mean max median min\n",
      " |      A   C\n",
      " |      bar large  5.500000  16   14.5  13\n",
      " |          small  5.500000  15   14.5  14\n",
      " |      foo large  2.000000  10    9.5   9\n",
      " |          small  2.333333  12   11.0   8\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      table : DataFrame\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.pivot : pivot without aggregation that can handle\n",
      " |          non-numeric data\n",
      " |  \n",
      " |  pow(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Exponential power of dataframe and other, element-wise (binary operator `pow`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe ** other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      None\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.rpow\n",
      " |  \n",
      " |  prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |      Return the product of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |          .. versionadded :: 0.22.0\n",
      " |      \n",
      " |             Added with the default being 0. This means the sum of an all-NA\n",
      " |             or empty Series is 0, and the product of an all-NA or empty\n",
      " |             Series is 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prod : Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, the product of an empty or all-NA Series is ``1``\n",
      " |      \n",
      " |      >>> pd.Series([]).prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter\n",
      " |      \n",
      " |      >>> pd.Series([]).prod(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |  \n",
      " |  quantile(self, q=0.5, axis=0, numeric_only=True, interpolation='linear')\n",
      " |      Return values at the given quantile over requested axis, a la\n",
      " |      numpy.percentile.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          0 <= q <= 1, the quantile(s) to compute\n",
      " |      axis : {0, 1, 'index', 'columns'} (default 0)\n",
      " |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      " |      numeric_only : boolean, default True\n",
      " |          If False, the quantile of datetime and timedelta data will be\n",
      " |          computed as well\n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |          This optional parameter specifies the interpolation method to use,\n",
      " |          when the desired quantile lies between two data points `i` and `j`:\n",
      " |      \n",
      " |          * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      " |            fractional part of the index surrounded by `i` and `j`.\n",
      " |          * lower: `i`.\n",
      " |          * higher: `j`.\n",
      " |          * nearest: `i` or `j` whichever is nearest.\n",
      " |          * midpoint: (`i` + `j`) / 2.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      quantiles : Series or DataFrame\n",
      " |      \n",
      " |          - If ``q`` is an array, a DataFrame will be returned where the\n",
      " |            index is ``q``, the columns are the columns of self, and the\n",
      " |            values are the quantiles.\n",
      " |          - If ``q`` is a float, a Series will be returned where the\n",
      " |            index is the columns of self and the values are the quantiles.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),\n",
      " |                            columns=['a', 'b'])\n",
      " |      >>> df.quantile(.1)\n",
      " |      a    1.3\n",
      " |      b    3.7\n",
      " |      dtype: float64\n",
      " |      >>> df.quantile([.1, .5])\n",
      " |             a     b\n",
      " |      0.1  1.3   3.7\n",
      " |      0.5  2.5  55.0\n",
      " |      \n",
      " |      Specifying `numeric_only=False` will also compute the quantile of\n",
      " |      datetime and timedelta data.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2],\n",
      " |                             'B': [pd.Timestamp('2010'),\n",
      " |                                   pd.Timestamp('2011')],\n",
      " |                             'C': [pd.Timedelta('1 days'),\n",
      " |                                   pd.Timedelta('2 days')]})\n",
      " |      >>> df.quantile(0.5, numeric_only=False)\n",
      " |      A                    1.5\n",
      " |      B    2010-07-02 12:00:00\n",
      " |      C        1 days 12:00:00\n",
      " |      Name: 0.5, dtype: object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.core.window.Rolling.quantile\n",
      " |  \n",
      " |  query(self, expr, inplace=False, **kwargs)\n",
      " |      Query the columns of a frame with a boolean expression.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      expr : string\n",
      " |          The query string to evaluate.  You can refer to variables\n",
      " |          in the environment by prefixing them with an '@' character like\n",
      " |          ``@a + b``.\n",
      " |      inplace : bool\n",
      " |          Whether the query should modify the data in place or return\n",
      " |          a modified copy\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      kwargs : dict\n",
      " |          See the documentation for :func:`pandas.eval` for complete details\n",
      " |          on the keyword arguments accepted by :meth:`DataFrame.query`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      q : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The result of the evaluation of this expression is first passed to\n",
      " |      :attr:`DataFrame.loc` and if that fails because of a\n",
      " |      multidimensional key (e.g., a DataFrame) then the result will be passed\n",
      " |      to :meth:`DataFrame.__getitem__`.\n",
      " |      \n",
      " |      This method uses the top-level :func:`pandas.eval` function to\n",
      " |      evaluate the passed query.\n",
      " |      \n",
      " |      The :meth:`~pandas.DataFrame.query` method uses a slightly\n",
      " |      modified Python syntax by default. For example, the ``&`` and ``|``\n",
      " |      (bitwise) operators have the precedence of their boolean cousins,\n",
      " |      :keyword:`and` and :keyword:`or`. This *is* syntactically valid Python,\n",
      " |      however the semantics are different.\n",
      " |      \n",
      " |      You can change the semantics of the expression by passing the keyword\n",
      " |      argument ``parser='python'``. This enforces the same semantics as\n",
      " |      evaluation in Python space. Likewise, you can pass ``engine='python'``\n",
      " |      to evaluate an expression using Python itself as a backend. This is not\n",
      " |      recommended as it is inefficient compared to using ``numexpr`` as the\n",
      " |      engine.\n",
      " |      \n",
      " |      The :attr:`DataFrame.index` and\n",
      " |      :attr:`DataFrame.columns` attributes of the\n",
      " |      :class:`~pandas.DataFrame` instance are placed in the query namespace\n",
      " |      by default, which allows you to treat both the index and columns of the\n",
      " |      frame as a column in the frame.\n",
      " |      The identifier ``index`` is used for the frame index; you can also\n",
      " |      use the name of the index to identify it in a query. Please note that\n",
      " |      Python keywords may not be used as identifiers.\n",
      " |      \n",
      " |      For further details and examples see the ``query`` documentation in\n",
      " |      :ref:`indexing <indexing.query>`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.eval\n",
      " |      DataFrame.eval\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from numpy.random import randn\n",
      " |      >>> from pandas import DataFrame\n",
      " |      >>> df = pd.DataFrame(randn(10, 2), columns=list('ab'))\n",
      " |      >>> df.query('a > b')\n",
      " |      >>> df[df.a > df.b]  # same result as the previous expression\n",
      " |  \n",
      " |  radd(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Addition of dataframe and other, element-wise (binary operator `radd`).\n",
      " |      \n",
      " |      Equivalent to ``other + dataframe``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> a = pd.DataFrame([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'],\n",
      " |      ...                  columns=['one'])\n",
      " |      >>> a\n",
      " |         one\n",
      " |      a  1.0\n",
      " |      b  1.0\n",
      " |      c  1.0\n",
      " |      d  NaN\n",
      " |      >>> b = pd.DataFrame(dict(one=[1, np.nan, 1, np.nan],\n",
      " |      ...                       two=[np.nan, 2, np.nan, 2]),\n",
      " |      ...                  index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |         one  two\n",
      " |      a  1.0  NaN\n",
      " |      b  NaN  2.0\n",
      " |      d  1.0  NaN\n",
      " |      e  NaN  2.0\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |         one  two\n",
      " |      a  2.0  NaN\n",
      " |      b  1.0  2.0\n",
      " |      c  1.0  NaN\n",
      " |      d  1.0  NaN\n",
      " |      e  NaN  2.0\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.add\n",
      " |  \n",
      " |  rdiv = rtruediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  reindex(self, labels=None, index=None, columns=None, axis=None, method=None, copy=True, level=None, fill_value=nan, limit=None, tolerance=None)\n",
      " |      Conform DataFrame to new index with optional filling logic, placing\n",
      " |      NA/NaN in locations having no value in the previous index. A new object\n",
      " |      is produced unless the new index is equivalent to the current one and\n",
      " |      copy=False\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : array-like, optional\n",
      " |          New labels / index to conform the axis specified by 'axis' to.\n",
      " |      index, columns : array-like, optional (should be specified using keywords)\n",
      " |          New labels / index to conform to. Preferably an Index object to\n",
      " |          avoid duplicating data\n",
      " |      axis : int or str, optional\n",
      " |          Axis to target. Can be either the axis name ('index', 'columns')\n",
      " |          or number (0, 1).\n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}, optional\n",
      " |          method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |      \n",
      " |          * default: don't fill gaps\n",
      " |          * pad / ffill: propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * backfill / bfill: use next valid observation to fill gap\n",
      " |          * nearest: use nearest valid observations to fill gap\n",
      " |      \n",
      " |      copy : boolean, default True\n",
      " |          Return a new object, even if the passed indexes are the same\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive elements to forward or backward fill\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |      \n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0 (list-like tolerance)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      ``DataFrame.reindex`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_labels, columns=column_labels, ...)``\n",
      " |      * ``(labels, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      Create a dataframe with some fictional data.\n",
      " |      \n",
      " |      >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...      'http_status': [200,200,404,404,301],\n",
      " |      ...      'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      " |      ...       index=index)\n",
      " |      >>> df\n",
      " |                 http_status  response_time\n",
      " |      Firefox            200           0.04\n",
      " |      Chrome             200           0.02\n",
      " |      Safari             404           0.07\n",
      " |      IE10               404           0.08\n",
      " |      Konqueror          301           1.00\n",
      " |      \n",
      " |      Create a new index and reindex the dataframe. By default\n",
      " |      values in the new index that do not have corresponding\n",
      " |      records in the dataframe are assigned ``NaN``.\n",
      " |      \n",
      " |      >>> new_index= ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      " |      ...             'Chrome']\n",
      " |      >>> df.reindex(new_index)\n",
      " |                     http_status  response_time\n",
      " |      Safari               404.0           0.07\n",
      " |      Iceweasel              NaN            NaN\n",
      " |      Comodo Dragon          NaN            NaN\n",
      " |      IE10                 404.0           0.08\n",
      " |      Chrome               200.0           0.02\n",
      " |      \n",
      " |      We can fill in the missing values by passing a value to\n",
      " |      the keyword ``fill_value``. Because the index is not monotonically\n",
      " |      increasing or decreasing, we cannot use arguments to the keyword\n",
      " |      ``method`` to fill the ``NaN`` values.\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value=0)\n",
      " |                     http_status  response_time\n",
      " |      Safari                 404           0.07\n",
      " |      Iceweasel                0           0.00\n",
      " |      Comodo Dragon            0           0.00\n",
      " |      IE10                   404           0.08\n",
      " |      Chrome                 200           0.02\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value='missing')\n",
      " |                    http_status response_time\n",
      " |      Safari                404          0.07\n",
      " |      Iceweasel         missing       missing\n",
      " |      Comodo Dragon     missing       missing\n",
      " |      IE10                  404          0.08\n",
      " |      Chrome                200          0.02\n",
      " |      \n",
      " |      We can also reindex the columns.\n",
      " |      \n",
      " |      >>> df.reindex(columns=['http_status', 'user_agent'])\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |      \n",
      " |      Or we can use \"axis-style\" keyword arguments\n",
      " |      \n",
      " |      >>> df.reindex(['http_status', 'user_agent'], axis=\"columns\")\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |      \n",
      " |      To further illustrate the filling functionality in\n",
      " |      ``reindex``, we will create a dataframe with a\n",
      " |      monotonically increasing index (for example, a sequence\n",
      " |      of dates).\n",
      " |      \n",
      " |      >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      " |      >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      " |      ...                    index=date_index)\n",
      " |      >>> df2\n",
      " |                  prices\n",
      " |      2010-01-01     100\n",
      " |      2010-01-02     101\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04     100\n",
      " |      2010-01-05      89\n",
      " |      2010-01-06      88\n",
      " |      \n",
      " |      Suppose we decide to expand the dataframe to cover a wider\n",
      " |      date range.\n",
      " |      \n",
      " |      >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      " |      >>> df2.reindex(date_index2)\n",
      " |                  prices\n",
      " |      2009-12-29     NaN\n",
      " |      2009-12-30     NaN\n",
      " |      2009-12-31     NaN\n",
      " |      2010-01-01     100\n",
      " |      2010-01-02     101\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04     100\n",
      " |      2010-01-05      89\n",
      " |      2010-01-06      88\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      The index entries that did not have a value in the original data frame\n",
      " |      (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      " |      If desired, we can fill in the missing values using one of several\n",
      " |      options.\n",
      " |      \n",
      " |      For example, to backpropagate the last valid value to fill the ``NaN``\n",
      " |      values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      " |      \n",
      " |      >>> df2.reindex(date_index2, method='bfill')\n",
      " |                  prices\n",
      " |      2009-12-29     100\n",
      " |      2009-12-30     100\n",
      " |      2009-12-31     100\n",
      " |      2010-01-01     100\n",
      " |      2010-01-02     101\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04     100\n",
      " |      2010-01-05      89\n",
      " |      2010-01-06      88\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      Please note that the ``NaN`` value present in the original dataframe\n",
      " |      (at index value 2010-01-03) will not be filled by any of the\n",
      " |      value propagation schemes. This is because filling while reindexing\n",
      " |      does not look at dataframe values, but only compares the original and\n",
      " |      desired indexes. If you do want to fill in the ``NaN`` values present\n",
      " |      in the original dataframe, use the ``fillna()`` method.\n",
      " |      \n",
      " |      See the :ref:`user guide <basics.reindexing>` for more.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reindexed : DataFrame\n",
      " |  \n",
      " |  reindex_axis(self, labels, axis=0, method=None, level=None, copy=True, limit=None, fill_value=nan)\n",
      " |      Conform input object to new index with optional\n",
      " |      filling logic, placing NA/NaN in locations having no value in the\n",
      " |      previous index. A new object is produced unless the new index is\n",
      " |      equivalent to the current one and copy=False\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : array-like\n",
      " |          New labels / index to conform to. Preferably an Index object to\n",
      " |          avoid duplicating data\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}, optional\n",
      " |          Method to use for filling holes in reindexed DataFrame:\n",
      " |      \n",
      " |          * default: don't fill gaps\n",
      " |          * pad / ffill: propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * backfill / bfill: use next valid observation to fill gap\n",
      " |          * nearest: use nearest valid observations to fill gap\n",
      " |      \n",
      " |      copy : boolean, default True\n",
      " |          Return a new object, even if the passed indexes are the same\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive elements to forward or backward fill\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |      \n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0 (list-like tolerance)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df.reindex_axis(['A', 'B', 'C'], axis=1)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex, reindex_like\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reindexed : DataFrame\n",
      " |  \n",
      " |  rename(self, mapper=None, index=None, columns=None, axis=None, copy=True, inplace=False, level=None)\n",
      " |      Alter axes labels.\n",
      " |      \n",
      " |      Function / dict values must be unique (1-to-1). Labels not contained in\n",
      " |      a dict / Series will be left as-is. Extra labels listed don't throw an\n",
      " |      error.\n",
      " |      \n",
      " |      See the :ref:`user guide <basics.rename>` for more.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper, index, columns : dict-like or function, optional\n",
      " |          dict-like or functions transformations to apply to\n",
      " |          that axis' values. Use either ``mapper`` and ``axis`` to\n",
      " |          specify the axis to target with ``mapper``, or ``index`` and\n",
      " |          ``columns``.\n",
      " |      axis : int or str, optional\n",
      " |          Axis to target with ``mapper``. Can be either the axis name\n",
      " |          ('index', 'columns') or number (0, 1). The default is 'index'.\n",
      " |      copy : boolean, default True\n",
      " |          Also copy underlying data\n",
      " |      inplace : boolean, default False\n",
      " |          Whether to return a new DataFrame. If True then value of copy is\n",
      " |          ignored.\n",
      " |      level : int or level name, default None\n",
      " |          In case of a MultiIndex, only rename labels in the specified\n",
      " |          level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.rename_axis\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      ``DataFrame.rename`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_mapper, columns=columns_mapper, ...)``\n",
      " |      * ``(mapper, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      >>> df.rename(index=str, columns={\"A\": \"a\", \"B\": \"c\"})\n",
      " |         a  c\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |      \n",
      " |      >>> df.rename(index=str, columns={\"A\": \"a\", \"C\": \"c\"})\n",
      " |         a  B\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |      \n",
      " |      Using axis-style parameters\n",
      " |      \n",
      " |      >>> df.rename(str.lower, axis='columns')\n",
      " |         a  b\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |      \n",
      " |      >>> df.rename({1: 2, 2: 4}, axis='index')\n",
      " |         A  B\n",
      " |      0  1  4\n",
      " |      2  2  5\n",
      " |      4  3  6\n",
      " |  \n",
      " |  reorder_levels(self, order, axis=0)\n",
      " |      Rearrange index levels using input order.\n",
      " |      May not drop or duplicate levels\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order : list of int or list of str\n",
      " |          List representing new level order. Reference level by number\n",
      " |          (position) or by key (label).\n",
      " |      axis : int\n",
      " |          Where to reorder levels.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller (new object)\n",
      " |  \n",
      " |  replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad')\n",
      " |      Replace values given in `to_replace` with `value`.\n",
      " |      \n",
      " |      Values of the DataFrame are replaced with other values dynamically.\n",
      " |      This differs from updating with ``.loc`` or ``.iloc``, which require\n",
      " |      you to specify a location to update with some value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_replace : str, regex, list, dict, Series, int, float, or None\n",
      " |          How to find the values that will be replaced.\n",
      " |      \n",
      " |          * numeric, str or regex:\n",
      " |      \n",
      " |              - numeric: numeric values equal to `to_replace` will be\n",
      " |                replaced with `value`\n",
      " |              - str: string exactly matching `to_replace` will be replaced\n",
      " |                with `value`\n",
      " |              - regex: regexs matching `to_replace` will be replaced with\n",
      " |                `value`\n",
      " |      \n",
      " |          * list of str, regex, or numeric:\n",
      " |      \n",
      " |              - First, if `to_replace` and `value` are both lists, they\n",
      " |                **must** be the same length.\n",
      " |              - Second, if ``regex=True`` then all of the strings in **both**\n",
      " |                lists will be interpreted as regexs otherwise they will match\n",
      " |                directly. This doesn't matter much for `value` since there\n",
      " |                are only a few possible substitution regexes you can use.\n",
      " |              - str, regex and numeric rules apply as above.\n",
      " |      \n",
      " |          * dict:\n",
      " |      \n",
      " |              - Dicts can be used to specify different replacement values\n",
      " |                for different existing values. For example,\n",
      " |                ``{'a': 'b', 'y': 'z'}`` replaces the value 'a' with 'b' and\n",
      " |                'y' with 'z'. To use a dict in this way the `value`\n",
      " |                parameter should be `None`.\n",
      " |              - For a DataFrame a dict can specify that different values\n",
      " |                should be replaced in different columns. For example,\n",
      " |                ``{'a': 1, 'b': 'z'}`` looks for the value 1 in column 'a'\n",
      " |                and the value 'z' in column 'b' and replaces these values\n",
      " |                with whatever is specified in `value`. The `value` parameter\n",
      " |                should not be ``None`` in this case. You can treat this as a\n",
      " |                special case of passing two lists except that you are\n",
      " |                specifying the column to search in.\n",
      " |              - For a DataFrame nested dictionaries, e.g.,\n",
      " |                ``{'a': {'b': np.nan}}``, are read as follows: look in column\n",
      " |                'a' for the value 'b' and replace it with NaN. The `value`\n",
      " |                parameter should be ``None`` to use a nested dict in this\n",
      " |                way. You can nest regular expressions as well. Note that\n",
      " |                column names (the top-level dictionary keys in a nested\n",
      " |                dictionary) **cannot** be regular expressions.\n",
      " |      \n",
      " |          * None:\n",
      " |      \n",
      " |              - This means that the `regex` argument must be a string,\n",
      " |                compiled regular expression, or list, dict, ndarray or\n",
      " |                Series of such elements. If `value` is also ``None`` then\n",
      " |                this **must** be a nested dictionary or Series.\n",
      " |      \n",
      " |          See the examples section for examples of each of these.\n",
      " |      value : scalar, dict, list, str, regex, default None\n",
      " |          Value to replace any values matching `to_replace` with.\n",
      " |          For a DataFrame a dict of values can be used to specify which\n",
      " |          value to use for each column (columns not in the dict will not be\n",
      " |          filled). Regular expressions, strings and lists or dicts of such\n",
      " |          objects are also allowed.\n",
      " |      inplace : boolean, default False\n",
      " |          If True, in place. Note: this will modify any\n",
      " |          other views on this object (e.g. a column from a DataFrame).\n",
      " |          Returns the caller if this is True.\n",
      " |      limit : int, default None\n",
      " |          Maximum size gap to forward or backward fill.\n",
      " |      regex : bool or same types as `to_replace`, default False\n",
      " |          Whether to interpret `to_replace` and/or `value` as regular\n",
      " |          expressions. If this is ``True`` then `to_replace` *must* be a\n",
      " |          string. Alternatively, this could be a regular expression or a\n",
      " |          list, dict, or array of regular expressions in which case\n",
      " |          `to_replace` must be ``None``.\n",
      " |      method : {'pad', 'ffill', 'bfill', `None`}\n",
      " |          The method to use when for replacement, when `to_replace` is a\n",
      " |          scalar, list or tuple and `value` is ``None``.\n",
      " |      \n",
      " |          .. versionchanged:: 0.23.0\n",
      " |              Added to DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.fillna : Fill NA values\n",
      " |      DataFrame.where : Replace values based on boolean condition\n",
      " |      Series.str.replace : Simple string replacement.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Object after replacement.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AssertionError\n",
      " |          * If `regex` is not a ``bool`` and `to_replace` is not\n",
      " |            ``None``.\n",
      " |      TypeError\n",
      " |          * If `to_replace` is a ``dict`` and `value` is not a ``list``,\n",
      " |            ``dict``, ``ndarray``, or ``Series``\n",
      " |          * If `to_replace` is ``None`` and `regex` is not compilable\n",
      " |            into a regular expression or is a list, dict, ndarray, or\n",
      " |            Series.\n",
      " |          * When replacing multiple ``bool`` or ``datetime64`` objects and\n",
      " |            the arguments to `to_replace` does not match the type of the\n",
      " |            value being replaced\n",
      " |      ValueError\n",
      " |          * If a ``list`` or an ``ndarray`` is passed to `to_replace` and\n",
      " |            `value` but they are not the same length.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * Regex substitution is performed under the hood with ``re.sub``. The\n",
      " |        rules for substitution for ``re.sub`` are the same.\n",
      " |      * Regular expressions will only substitute on strings, meaning you\n",
      " |        cannot provide, for example, a regular expression matching floating\n",
      " |        point numbers and expect the columns in your frame that have a\n",
      " |        numeric dtype to be matched. However, if those floating point\n",
      " |        numbers *are* strings, then you can do this.\n",
      " |      * This method has *a lot* of options. You are encouraged to experiment\n",
      " |        and play with this method to gain intuition about how it works.\n",
      " |      * When dict is used as the `to_replace` value, it is like\n",
      " |        key(s) in the dict are the to_replace part and\n",
      " |        value(s) in the dict are the value parameter.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      **Scalar `to_replace` and `value`**\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 1, 2, 3, 4])\n",
      " |      >>> s.replace(0, 5)\n",
      " |      0    5\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [0, 1, 2, 3, 4],\n",
      " |      ...                    'B': [5, 6, 7, 8, 9],\n",
      " |      ...                    'C': ['a', 'b', 'c', 'd', 'e']})\n",
      " |      >>> df.replace(0, 5)\n",
      " |         A  B  C\n",
      " |      0  5  5  a\n",
      " |      1  1  6  b\n",
      " |      2  2  7  c\n",
      " |      3  3  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      **List-like `to_replace`**\n",
      " |      \n",
      " |      >>> df.replace([0, 1, 2, 3], 4)\n",
      " |         A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  4  6  b\n",
      " |      2  4  7  c\n",
      " |      3  4  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      >>> df.replace([0, 1, 2, 3], [4, 3, 2, 1])\n",
      " |         A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  3  6  b\n",
      " |      2  2  7  c\n",
      " |      3  1  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      >>> s.replace([1, 2], method='bfill')\n",
      " |      0    0\n",
      " |      1    3\n",
      " |      2    3\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **dict-like `to_replace`**\n",
      " |      \n",
      " |      >>> df.replace({0: 10, 1: 100})\n",
      " |           A  B  C\n",
      " |      0   10  5  a\n",
      " |      1  100  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4    4  9  e\n",
      " |      \n",
      " |      >>> df.replace({'A': 0, 'B': 5}, 100)\n",
      " |           A    B  C\n",
      " |      0  100  100  a\n",
      " |      1    1    6  b\n",
      " |      2    2    7  c\n",
      " |      3    3    8  d\n",
      " |      4    4    9  e\n",
      " |      \n",
      " |      >>> df.replace({'A': {0: 100, 4: 400}})\n",
      " |           A  B  C\n",
      " |      0  100  5  a\n",
      " |      1    1  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4  400  9  e\n",
      " |      \n",
      " |      **Regular expression `to_replace`**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['bat', 'foo', 'bait'],\n",
      " |      ...                    'B': ['abc', 'bar', 'xyz']})\n",
      " |      >>> df.replace(to_replace=r'^ba.$', value='new', regex=True)\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace({'A': r'^ba.$'}, {'A': 'new'}, regex=True)\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  bar\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex=r'^ba.$', value='new')\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex={r'^ba.$':'new', 'foo':'xyz'})\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   xyz  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex=[r'^ba.$', 'foo'], value='new')\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   new  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      Note that when replacing multiple ``bool`` or ``datetime64`` objects,\n",
      " |      the data types in the `to_replace` parameter must match the data\n",
      " |      type of the value being replaced:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [True, False, True],\n",
      " |      ...                    'B': [False, True, False]})\n",
      " |      >>> df.replace({'a string': 'new value', True: False})  # raises\n",
      " |      Traceback (most recent call last):\n",
      " |          ...\n",
      " |      TypeError: Cannot compare types 'ndarray(dtype=bool)' and 'str'\n",
      " |      \n",
      " |      This raises a ``TypeError`` because one of the ``dict`` keys is not of\n",
      " |      the correct type for replacement.\n",
      " |      \n",
      " |      Compare the behavior of ``s.replace({'a': None})`` and\n",
      " |      ``s.replace('a', None)`` to understand the pecularities\n",
      " |      of the `to_replace` parameter:\n",
      " |      \n",
      " |      >>> s = pd.Series([10, 'a', 'a', 'b', 'a'])\n",
      " |      \n",
      " |      When one uses a dict as the `to_replace` value, it is like the\n",
      " |      value(s) in the dict are equal to the `value` parameter.\n",
      " |      ``s.replace({'a': None})`` is equivalent to\n",
      " |      ``s.replace(to_replace={'a': None}, value=None, method=None)``:\n",
      " |      \n",
      " |      >>> s.replace({'a': None})\n",
      " |      0      10\n",
      " |      1    None\n",
      " |      2    None\n",
      " |      3       b\n",
      " |      4    None\n",
      " |      dtype: object\n",
      " |      \n",
      " |      When ``value=None`` and `to_replace` is a scalar, list or\n",
      " |      tuple, `replace` uses the method parameter (default 'pad') to do the\n",
      " |      replacement. So this is why the 'a' values are being replaced by 10\n",
      " |      in rows 1 and 2 and 'b' in row 4 in this case.\n",
      " |      The command ``s.replace('a', None)`` is actually equivalent to\n",
      " |      ``s.replace(to_replace='a', value=None, method='pad')``:\n",
      " |      \n",
      " |      >>> s.replace('a', None)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    10\n",
      " |      3     b\n",
      " |      4     b\n",
      " |      dtype: object\n",
      " |  \n",
      " |  reset_index(self, level=None, drop=False, inplace=False, col_level=0, col_fill='')\n",
      " |      For DataFrame with multi-level index, return new DataFrame with\n",
      " |      labeling information in the columns under the index names, defaulting\n",
      " |      to 'level_0', 'level_1', etc. if any are None. For a standard index,\n",
      " |      the index name will be used (if set), otherwise a default 'index' or\n",
      " |      'level_0' (if 'index' is already taken) will be used.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, tuple, or list, default None\n",
      " |          Only remove the given levels from the index. Removes all levels by\n",
      " |          default\n",
      " |      drop : boolean, default False\n",
      " |          Do not try to insert index into dataframe columns. This resets\n",
      " |          the index to the default integer index.\n",
      " |      inplace : boolean, default False\n",
      " |          Modify the DataFrame in place (do not create a new object)\n",
      " |      col_level : int or str, default 0\n",
      " |          If the columns have multiple levels, determines which level the\n",
      " |          labels are inserted into. By default it is inserted into the first\n",
      " |          level.\n",
      " |      col_fill : object, default ''\n",
      " |          If the columns have multiple levels, determines how the other\n",
      " |          levels are named. If None then the index name is repeated.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      resetted : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('bird',    389.0),\n",
      " |      ...                    ('bird',     24.0),\n",
      " |      ...                    ('mammal',   80.5),\n",
      " |      ...                    ('mammal', np.nan)],\n",
      " |      ...                   index=['falcon', 'parrot', 'lion', 'monkey'],\n",
      " |      ...                   columns=('class', 'max_speed'))\n",
      " |      >>> df\n",
      " |               class  max_speed\n",
      " |      falcon    bird      389.0\n",
      " |      parrot    bird       24.0\n",
      " |      lion    mammal       80.5\n",
      " |      monkey  mammal        NaN\n",
      " |      \n",
      " |      When we reset the index, the old index is added as a column, and a\n",
      " |      new sequential index is used:\n",
      " |      \n",
      " |      >>> df.reset_index()\n",
      " |          index   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  parrot    bird       24.0\n",
      " |      2    lion  mammal       80.5\n",
      " |      3  monkey  mammal        NaN\n",
      " |      \n",
      " |      We can use the `drop` parameter to avoid the old index being added as\n",
      " |      a column:\n",
      " |      \n",
      " |      >>> df.reset_index(drop=True)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      1    bird       24.0\n",
      " |      2  mammal       80.5\n",
      " |      3  mammal        NaN\n",
      " |      \n",
      " |      You can also use `reset_index` with `MultiIndex`.\n",
      " |      \n",
      " |      >>> index = pd.MultiIndex.from_tuples([('bird', 'falcon'),\n",
      " |      ...                                    ('bird', 'parrot'),\n",
      " |      ...                                    ('mammal', 'lion'),\n",
      " |      ...                                    ('mammal', 'monkey')],\n",
      " |      ...                                   names=['class', 'name'])\n",
      " |      >>> columns = pd.MultiIndex.from_tuples([('speed', 'max'),\n",
      " |      ...                                      ('species', 'type')])\n",
      " |      >>> df = pd.DataFrame([(389.0, 'fly'),\n",
      " |      ...                    ( 24.0, 'fly'),\n",
      " |      ...                    ( 80.5, 'run'),\n",
      " |      ...                    (np.nan, 'jump')],\n",
      " |      ...                   index=index,\n",
      " |      ...                   columns=columns)\n",
      " |      >>> df\n",
      " |                     speed species\n",
      " |                       max    type\n",
      " |      class  name\n",
      " |      bird   falcon  389.0     fly\n",
      " |             parrot   24.0     fly\n",
      " |      mammal lion     80.5     run\n",
      " |             monkey    NaN    jump\n",
      " |      \n",
      " |      If the index has multiple levels, we can reset a subset of them:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class')\n",
      " |               class  speed species\n",
      " |                        max    type\n",
      " |      name\n",
      " |      falcon    bird  389.0     fly\n",
      " |      parrot    bird   24.0     fly\n",
      " |      lion    mammal   80.5     run\n",
      " |      monkey  mammal    NaN    jump\n",
      " |      \n",
      " |      If we are not dropping the index, by default, it is placed in the top\n",
      " |      level. We can place it in another level:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class', col_level=1)\n",
      " |                      speed species\n",
      " |               class    max    type\n",
      " |      name\n",
      " |      falcon    bird  389.0     fly\n",
      " |      parrot    bird   24.0     fly\n",
      " |      lion    mammal   80.5     run\n",
      " |      monkey  mammal    NaN    jump\n",
      " |      \n",
      " |      When the index is inserted under another level, we can specify under\n",
      " |      which one with the parameter `col_fill`:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class', col_level=1, col_fill='species')\n",
      " |                    species  speed species\n",
      " |                      class    max    type\n",
      " |      name\n",
      " |      falcon           bird  389.0     fly\n",
      " |      parrot           bird   24.0     fly\n",
      " |      lion           mammal   80.5     run\n",
      " |      monkey         mammal    NaN    jump\n",
      " |      \n",
      " |      If we specify a nonexistent level for `col_fill`, it is created:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class', col_level=1, col_fill='genus')\n",
      " |                      genus  speed species\n",
      " |                      class    max    type\n",
      " |      name\n",
      " |      falcon           bird  389.0     fly\n",
      " |      parrot           bird   24.0     fly\n",
      " |      lion           mammal   80.5     run\n",
      " |      monkey         mammal    NaN    jump\n",
      " |  \n",
      " |  rfloordiv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Integer division of dataframe and other, element-wise (binary operator `rfloordiv`).\n",
      " |      \n",
      " |      Equivalent to ``other // dataframe``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      None\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.floordiv\n",
      " |  \n",
      " |  rmod(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Modulo of dataframe and other, element-wise (binary operator `rmod`).\n",
      " |      \n",
      " |      Equivalent to ``other % dataframe``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      None\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.mod\n",
      " |  \n",
      " |  rmul(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Multiplication of dataframe and other, element-wise (binary operator `rmul`).\n",
      " |      \n",
      " |      Equivalent to ``other * dataframe``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      None\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.mul\n",
      " |  \n",
      " |  rolling(self, window, min_periods=None, center=False, win_type=None, on=None, axis=0, closed=None)\n",
      " |      Provides rolling window calculations.\n",
      " |      \n",
      " |      .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      window : int, or offset\n",
      " |          Size of the moving window. This is the number of observations used for\n",
      " |          calculating the statistic. Each window will be a fixed size.\n",
      " |      \n",
      " |          If its an offset then this will be the time period of each window. Each\n",
      " |          window will be a variable sized based on the observations included in\n",
      " |          the time-period. This is only valid for datetimelike indexes. This is\n",
      " |          new in 0.19.0\n",
      " |      min_periods : int, default None\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA). For a window that is specified by an offset,\n",
      " |          this will default to 1.\n",
      " |      center : boolean, default False\n",
      " |          Set the labels at the center of the window.\n",
      " |      win_type : string, default None\n",
      " |          Provide a window type. If ``None``, all points are evenly weighted.\n",
      " |          See the notes below for further information.\n",
      " |      on : string, optional\n",
      " |          For a DataFrame, column on which to calculate\n",
      " |          the rolling window, rather than the index\n",
      " |      closed : string, default None\n",
      " |          Make the interval closed on the 'right', 'left', 'both' or\n",
      " |          'neither' endpoints.\n",
      " |          For offset-based windows, it defaults to 'right'.\n",
      " |          For fixed windows, defaults to 'both'. Remaining cases not implemented\n",
      " |          for fixed windows.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      axis : int or string, default 0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window or Rolling sub-classed for the particular operation\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, using the 'triang'\n",
      " |      window type.\n",
      " |      \n",
      " |      >>> df.rolling(2, win_type='triang').sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  2.5\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, min_periods defaults\n",
      " |      to the window length.\n",
      " |      \n",
      " |      >>> df.rolling(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |      \n",
      " |      Same as above, but explicitly set the min_periods\n",
      " |      \n",
      " |      >>> df.rolling(2, min_periods=1).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  2.0\n",
      " |      4  4.0\n",
      " |      \n",
      " |      A ragged (meaning not-a-regular frequency), time-indexed DataFrame\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},\n",
      " |      ...                   index = [pd.Timestamp('20130101 09:00:00'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:02'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:03'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:05'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:06')])\n",
      " |      \n",
      " |      >>> df\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  2.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |      \n",
      " |      \n",
      " |      Contrasting to an integer rolling window, this will roll a variable\n",
      " |      length window corresponding to the time period.\n",
      " |      The default for min_periods is 1.\n",
      " |      \n",
      " |      >>> df.rolling('2s').sum()\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  3.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, the result is set to the right edge of the window. This can be\n",
      " |      changed to the center of the window by setting ``center=True``.\n",
      " |      \n",
      " |      To learn more about the offsets & frequency strings, please see `this link\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |      The recognized win_types are:\n",
      " |      \n",
      " |      * ``boxcar``\n",
      " |      * ``triang``\n",
      " |      * ``blackman``\n",
      " |      * ``hamming``\n",
      " |      * ``bartlett``\n",
      " |      * ``parzen``\n",
      " |      * ``bohman``\n",
      " |      * ``blackmanharris``\n",
      " |      * ``nuttall``\n",
      " |      * ``barthann``\n",
      " |      * ``kaiser`` (needs beta)\n",
      " |      * ``gaussian`` (needs std)\n",
      " |      * ``general_gaussian`` (needs power, width)\n",
      " |      * ``slepian`` (needs width).\n",
      " |      \n",
      " |      If ``win_type=None`` all points are evenly weighted. To learn more about\n",
      " |      different window types see `scipy.signal window functions\n",
      " |      <https://docs.scipy.org/doc/scipy/reference/signal.html#window-functions>`__.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      expanding : Provides expanding transformations.\n",
      " |      ewm : Provides exponential weighted functions\n",
      " |  \n",
      " |  round(self, decimals=0, *args, **kwargs)\n",
      " |      Round a DataFrame to a variable number of decimal places.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      decimals : int, dict, Series\n",
      " |          Number of decimal places to round each column to. If an int is\n",
      " |          given, round each column to the same number of places.\n",
      " |          Otherwise dict and Series round to variable numbers of places.\n",
      " |          Column names should be in the keys if `decimals` is a\n",
      " |          dict-like, or in the index if `decimals` is a Series. Any\n",
      " |          columns not included in `decimals` will be left as is. Elements\n",
      " |          of `decimals` which are not columns of the input will be\n",
      " |          ignored.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.random.random([3, 3]),\n",
      " |      ...     columns=['A', 'B', 'C'], index=['first', 'second', 'third'])\n",
      " |      >>> df\n",
      " |                     A         B         C\n",
      " |      first   0.028208  0.992815  0.173891\n",
      " |      second  0.038683  0.645646  0.577595\n",
      " |      third   0.877076  0.149370  0.491027\n",
      " |      >>> df.round(2)\n",
      " |                 A     B     C\n",
      " |      first   0.03  0.99  0.17\n",
      " |      second  0.04  0.65  0.58\n",
      " |      third   0.88  0.15  0.49\n",
      " |      >>> df.round({'A': 1, 'C': 2})\n",
      " |                A         B     C\n",
      " |      first   0.0  0.992815  0.17\n",
      " |      second  0.0  0.645646  0.58\n",
      " |      third   0.9  0.149370  0.49\n",
      " |      >>> decimals = pd.Series([1, 0, 2], index=['A', 'B', 'C'])\n",
      " |      >>> df.round(decimals)\n",
      " |                A  B     C\n",
      " |      first   0.0  1  0.17\n",
      " |      second  0.0  1  0.58\n",
      " |      third   0.9  0  0.49\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.around\n",
      " |      Series.round\n",
      " |  \n",
      " |  rpow(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Exponential power of dataframe and other, element-wise (binary operator `rpow`).\n",
      " |      \n",
      " |      Equivalent to ``other ** dataframe``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      None\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.pow\n",
      " |  \n",
      " |  rsub(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Subtraction of dataframe and other, element-wise (binary operator `rsub`).\n",
      " |      \n",
      " |      Equivalent to ``other - dataframe``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> a = pd.DataFrame([2, 1, 1, np.nan], index=['a', 'b', 'c', 'd'],\n",
      " |      ...                  columns=['one'])\n",
      " |      >>> a\n",
      " |         one\n",
      " |      a  2.0\n",
      " |      b  1.0\n",
      " |      c  1.0\n",
      " |      d  NaN\n",
      " |      >>> b = pd.DataFrame(dict(one=[1, np.nan, 1, np.nan],\n",
      " |      ...                       two=[3, 2, np.nan, 2]),\n",
      " |      ...                  index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |         one  two\n",
      " |      a  1.0  3.0\n",
      " |      b  NaN  2.0\n",
      " |      d  1.0  NaN\n",
      " |      e  NaN  2.0\n",
      " |      >>> a.sub(b, fill_value=0)\n",
      " |         one  two\n",
      " |      a  1.0  -3.0\n",
      " |      b  1.0  -2.0\n",
      " |      c  1.0  NaN\n",
      " |      d  -1.0  NaN\n",
      " |      e  NaN  -2.0\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.sub\n",
      " |  \n",
      " |  rtruediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Floating division of dataframe and other, element-wise (binary operator `rtruediv`).\n",
      " |      \n",
      " |      Equivalent to ``other / dataframe``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      None\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.truediv\n",
      " |  \n",
      " |  select_dtypes(self, include=None, exclude=None)\n",
      " |      Return a subset of the DataFrame's columns based on the column dtypes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      include, exclude : scalar or list-like\n",
      " |          A selection of dtypes or strings to be included/excluded. At least\n",
      " |          one of these parameters must be supplied.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If both of ``include`` and ``exclude`` are empty\n",
      " |          * If ``include`` and ``exclude`` have overlapping elements\n",
      " |          * If any kind of string dtype is passed in.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      subset : DataFrame\n",
      " |          The subset of the frame including the dtypes in ``include`` and\n",
      " |          excluding the dtypes in ``exclude``.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * To select all *numeric* types, use ``np.number`` or ``'number'``\n",
      " |      * To select strings you must use the ``object`` dtype, but note that\n",
      " |        this will return *all* object dtype columns\n",
      " |      * See the `numpy dtype hierarchy\n",
      " |        <http://docs.scipy.org/doc/numpy/reference/arrays.scalars.html>`__\n",
      " |      * To select datetimes, use ``np.datetime64``, ``'datetime'`` or\n",
      " |        ``'datetime64'``\n",
      " |      * To select timedeltas, use ``np.timedelta64``, ``'timedelta'`` or\n",
      " |        ``'timedelta64'``\n",
      " |      * To select Pandas categorical dtypes, use ``'category'``\n",
      " |      * To select Pandas datetimetz dtypes, use ``'datetimetz'`` (new in\n",
      " |        0.20.0) or ``'datetime64[ns, tz]'``\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'a': [1, 2] * 3,\n",
      " |      ...                    'b': [True, False] * 3,\n",
      " |      ...                    'c': [1.0, 2.0] * 3})\n",
      " |      >>> df\n",
      " |              a      b  c\n",
      " |      0       1   True  1.0\n",
      " |      1       2  False  2.0\n",
      " |      2       1   True  1.0\n",
      " |      3       2  False  2.0\n",
      " |      4       1   True  1.0\n",
      " |      5       2  False  2.0\n",
      " |      \n",
      " |      >>> df.select_dtypes(include='bool')\n",
      " |         b\n",
      " |      0  True\n",
      " |      1  False\n",
      " |      2  True\n",
      " |      3  False\n",
      " |      4  True\n",
      " |      5  False\n",
      " |      \n",
      " |      >>> df.select_dtypes(include=['float64'])\n",
      " |         c\n",
      " |      0  1.0\n",
      " |      1  2.0\n",
      " |      2  1.0\n",
      " |      3  2.0\n",
      " |      4  1.0\n",
      " |      5  2.0\n",
      " |      \n",
      " |      >>> df.select_dtypes(exclude=['int'])\n",
      " |             b    c\n",
      " |      0   True  1.0\n",
      " |      1  False  2.0\n",
      " |      2   True  1.0\n",
      " |      3  False  2.0\n",
      " |      4   True  1.0\n",
      " |      5  False  2.0\n",
      " |  \n",
      " |  sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased standard error of the mean over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sem : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  set_index(self, keys, drop=True, append=False, inplace=False, verify_integrity=False)\n",
      " |      Set the DataFrame index (row labels) using one or more existing\n",
      " |      columns. By default yields a new object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keys : column label or list of column labels / arrays\n",
      " |      drop : boolean, default True\n",
      " |          Delete columns to be used as the new index\n",
      " |      append : boolean, default False\n",
      " |          Whether to append columns to existing index\n",
      " |      inplace : boolean, default False\n",
      " |          Modify the DataFrame in place (do not create a new object)\n",
      " |      verify_integrity : boolean, default False\n",
      " |          Check the new index for duplicates. Otherwise defer the check until\n",
      " |          necessary. Setting to False will improve the performance of this\n",
      " |          method\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'month': [1, 4, 7, 10],\n",
      " |      ...                    'year': [2012, 2014, 2013, 2014],\n",
      " |      ...                    'sale':[55, 40, 84, 31]})\n",
      " |         month  sale  year\n",
      " |      0  1      55    2012\n",
      " |      1  4      40    2014\n",
      " |      2  7      84    2013\n",
      " |      3  10     31    2014\n",
      " |      \n",
      " |      Set the index to become the 'month' column:\n",
      " |      \n",
      " |      >>> df.set_index('month')\n",
      " |             sale  year\n",
      " |      month\n",
      " |      1      55    2012\n",
      " |      4      40    2014\n",
      " |      7      84    2013\n",
      " |      10     31    2014\n",
      " |      \n",
      " |      Create a multi-index using columns 'year' and 'month':\n",
      " |      \n",
      " |      >>> df.set_index(['year', 'month'])\n",
      " |                  sale\n",
      " |      year  month\n",
      " |      2012  1     55\n",
      " |      2014  4     40\n",
      " |      2013  7     84\n",
      " |      2014  10    31\n",
      " |      \n",
      " |      Create a multi-index using a set of values and a column:\n",
      " |      \n",
      " |      >>> df.set_index([[1, 2, 3, 4], 'year'])\n",
      " |               month  sale\n",
      " |         year\n",
      " |      1  2012  1      55\n",
      " |      2  2014  4      40\n",
      " |      3  2013  7      84\n",
      " |      4  2014  10     31\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dataframe : DataFrame\n",
      " |  \n",
      " |  set_value(self, index, col, value, takeable=False)\n",
      " |      Put single value at passed column and index\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |          Use .at[] or .iat[] accessors instead.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : row label\n",
      " |      col : column label\n",
      " |      value : scalar value\n",
      " |      takeable : interpret the index/col as indexers, default False\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      frame : DataFrame\n",
      " |          If label pair is contained, will be reference to calling DataFrame,\n",
      " |          otherwise a new object\n",
      " |  \n",
      " |  shift(self, periods=1, freq=None, axis=0)\n",
      " |      Shift index by desired number of periods with an optional time freq\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      freq : DateOffset, timedelta, or time rule string, optional\n",
      " |          Increment to use from the tseries module or time rule (e.g. 'EOM').\n",
      " |          See Notes.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is specified then the index values are shifted but the data\n",
      " |      is not realigned. That is, use freq if you would like to extend the\n",
      " |      index when shifting and preserve the original data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : DataFrame\n",
      " |  \n",
      " |  skew(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased skew over requested axis\n",
      " |      Normalized by N-1\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      skew : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  sort_index(self, axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True, by=None)\n",
      " |      Sort object by labels (along an axis)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : index, columns to direct sorting\n",
      " |      level : int or level name or list of ints or list of level names\n",
      " |          if not None, sort on values in specified index level(s)\n",
      " |      ascending : boolean, default True\n",
      " |          Sort ascending vs. descending\n",
      " |      inplace : bool, default False\n",
      " |          if True, perform operation in-place\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n",
      " |           Choice of sorting algorithm. See also ndarray.np.sort for more\n",
      " |           information.  `mergesort` is the only stable algorithm. For\n",
      " |           DataFrames, this option is only applied when sorting on a single\n",
      " |           column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |           `first` puts NaNs at the beginning, `last` puts NaNs at the end.\n",
      " |           Not implemented for MultiIndex.\n",
      " |      sort_remaining : bool, default True\n",
      " |          if true and sorting by level and index is multilevel, sort by other\n",
      " |          levels too (in order) after sorting by specified level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sorted_obj : DataFrame\n",
      " |  \n",
      " |  sort_values(self, by, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
      " |      Sort by the values along either axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : str or list of str\n",
      " |          Name or list of names to sort by.\n",
      " |      \n",
      " |          - if `axis` is 0 or `'index'` then `by` may contain index\n",
      " |            levels and/or column labels\n",
      " |          - if `axis` is 1 or `'columns'` then `by` may contain column\n",
      " |            levels and/or index labels\n",
      " |      \n",
      " |          .. versionchanged:: 0.23.0\n",
      " |             Allow specifying index or column level names.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |           Axis to be sorted\n",
      " |      ascending : bool or list of bool, default True\n",
      " |           Sort ascending vs. descending. Specify list for multiple sort\n",
      " |           orders.  If this is a list of bools, must match the length of\n",
      " |           the by.\n",
      " |      inplace : bool, default False\n",
      " |           if True, perform operation in-place\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n",
      " |           Choice of sorting algorithm. See also ndarray.np.sort for more\n",
      " |           information.  `mergesort` is the only stable algorithm. For\n",
      " |           DataFrames, this option is only applied when sorting on a single\n",
      " |           column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |           `first` puts NaNs at the beginning, `last` puts NaNs at the end\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sorted_obj : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'col1' : ['A', 'A', 'B', np.nan, 'D', 'C'],\n",
      " |      ...     'col2' : [2, 1, 9, 8, 7, 4],\n",
      " |      ...     'col3': [0, 1, 9, 4, 2, 3],\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |          col1 col2 col3\n",
      " |      0   A    2    0\n",
      " |      1   A    1    1\n",
      " |      2   B    9    9\n",
      " |      3   NaN  8    4\n",
      " |      4   D    7    2\n",
      " |      5   C    4    3\n",
      " |      \n",
      " |      Sort by col1\n",
      " |      \n",
      " |      >>> df.sort_values(by=['col1'])\n",
      " |          col1 col2 col3\n",
      " |      0   A    2    0\n",
      " |      1   A    1    1\n",
      " |      2   B    9    9\n",
      " |      5   C    4    3\n",
      " |      4   D    7    2\n",
      " |      3   NaN  8    4\n",
      " |      \n",
      " |      Sort by multiple columns\n",
      " |      \n",
      " |      >>> df.sort_values(by=['col1', 'col2'])\n",
      " |          col1 col2 col3\n",
      " |      1   A    1    1\n",
      " |      0   A    2    0\n",
      " |      2   B    9    9\n",
      " |      5   C    4    3\n",
      " |      4   D    7    2\n",
      " |      3   NaN  8    4\n",
      " |      \n",
      " |      Sort Descending\n",
      " |      \n",
      " |      >>> df.sort_values(by='col1', ascending=False)\n",
      " |          col1 col2 col3\n",
      " |      4   D    7    2\n",
      " |      5   C    4    3\n",
      " |      2   B    9    9\n",
      " |      0   A    2    0\n",
      " |      1   A    1    1\n",
      " |      3   NaN  8    4\n",
      " |      \n",
      " |      Putting NAs first\n",
      " |      \n",
      " |      >>> df.sort_values(by='col1', ascending=False, na_position='first')\n",
      " |          col1 col2 col3\n",
      " |      3   NaN  8    4\n",
      " |      4   D    7    2\n",
      " |      5   C    4    3\n",
      " |      2   B    9    9\n",
      " |      0   A    2    0\n",
      " |      1   A    1    1\n",
      " |  \n",
      " |  sortlevel(self, level=0, axis=0, ascending=True, inplace=False, sort_remaining=True)\n",
      " |      Sort multilevel index by chosen axis and primary level. Data will be\n",
      " |      lexicographically sorted by the chosen level followed by the other\n",
      " |      levels (in order).\n",
      " |      \n",
      " |      .. deprecated:: 0.20.0\n",
      " |          Use :meth:`DataFrame.sort_index`\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |      ascending : boolean, default True\n",
      " |      inplace : boolean, default False\n",
      " |          Sort the DataFrame without creating a new instance\n",
      " |      sort_remaining : boolean, default True\n",
      " |          Sort by the other levels too.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sorted : DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.sort_index(level=...)\n",
      " |  \n",
      " |  stack(self, level=-1, dropna=True)\n",
      " |      Stack the prescribed level(s) from columns to index.\n",
      " |      \n",
      " |      Return a reshaped DataFrame or Series having a multi-level\n",
      " |      index with one or more new inner-most levels compared to the current\n",
      " |      DataFrame. The new inner-most levels are created by pivoting the\n",
      " |      columns of the current dataframe:\n",
      " |      \n",
      " |        - if the columns have a single level, the output is a Series;\n",
      " |        - if the columns have multiple levels, the new index\n",
      " |          level(s) is (are) taken from the prescribed level(s) and\n",
      " |          the output is a DataFrame.\n",
      " |      \n",
      " |      The new index levels are sorted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, list, default -1\n",
      " |          Level(s) to stack from the column axis onto the index\n",
      " |          axis, defined as one index or label, or a list of indices\n",
      " |          or labels.\n",
      " |      dropna : bool, default True\n",
      " |          Whether to drop rows in the resulting Frame/Series with\n",
      " |          missing values. Stacking a column level onto the index\n",
      " |          axis can create combinations of index and column values\n",
      " |          that are missing from the original dataframe. See Examples\n",
      " |          section.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or Series\n",
      " |          Stacked dataframe or series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.unstack : Unstack prescribed level(s) from index axis\n",
      " |           onto column axis.\n",
      " |      DataFrame.pivot : Reshape dataframe from long format to wide\n",
      " |           format.\n",
      " |      DataFrame.pivot_table : Create a spreadsheet-style pivot table\n",
      " |           as a DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The function is named by analogy with a collection of books\n",
      " |      being re-organised from being side by side on a horizontal\n",
      " |      position (the columns of the dataframe) to being stacked\n",
      " |      vertically on top of of each other (in the index of the\n",
      " |      dataframe).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Single level columns**\n",
      " |      \n",
      " |      >>> df_single_level_cols = pd.DataFrame([[0, 1], [2, 3]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=['weight', 'height'])\n",
      " |      \n",
      " |      Stacking a dataframe with a single level column axis returns a Series:\n",
      " |      \n",
      " |      >>> df_single_level_cols\n",
      " |           weight height\n",
      " |      cat       0      1\n",
      " |      dog       2      3\n",
      " |      >>> df_single_level_cols.stack()\n",
      " |      cat  weight    0\n",
      " |           height    1\n",
      " |      dog  weight    2\n",
      " |           height    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **Multi level columns: simple case**\n",
      " |      \n",
      " |      >>> multicol1 = pd.MultiIndex.from_tuples([('weight', 'kg'),\n",
      " |      ...                                        ('weight', 'pounds')])\n",
      " |      >>> df_multi_level_cols1 = pd.DataFrame([[1, 2], [2, 4]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=multicol1)\n",
      " |      \n",
      " |      Stacking a dataframe with a multi-level column axis:\n",
      " |      \n",
      " |      >>> df_multi_level_cols1\n",
      " |           weight\n",
      " |               kg    pounds\n",
      " |      cat       1        2\n",
      " |      dog       2        4\n",
      " |      >>> df_multi_level_cols1.stack()\n",
      " |                  weight\n",
      " |      cat kg           1\n",
      " |          pounds       2\n",
      " |      dog kg           2\n",
      " |          pounds       4\n",
      " |      \n",
      " |      **Missing values**\n",
      " |      \n",
      " |      >>> multicol2 = pd.MultiIndex.from_tuples([('weight', 'kg'),\n",
      " |      ...                                        ('height', 'm')])\n",
      " |      >>> df_multi_level_cols2 = pd.DataFrame([[1.0, 2.0], [3.0, 4.0]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=multicol2)\n",
      " |      \n",
      " |      It is common to have missing values when stacking a dataframe\n",
      " |      with multi-level columns, as the stacked dataframe typically\n",
      " |      has more values than the original dataframe. Missing values\n",
      " |      are filled with NaNs:\n",
      " |      \n",
      " |      >>> df_multi_level_cols2\n",
      " |          weight height\n",
      " |              kg      m\n",
      " |      cat    1.0    2.0\n",
      " |      dog    3.0    4.0\n",
      " |      >>> df_multi_level_cols2.stack()\n",
      " |              height  weight\n",
      " |      cat kg     NaN     1.0\n",
      " |          m      2.0     NaN\n",
      " |      dog kg     NaN     3.0\n",
      " |          m      4.0     NaN\n",
      " |      \n",
      " |      **Prescribing the level(s) to be stacked**\n",
      " |      \n",
      " |      The first parameter controls which level or levels are stacked:\n",
      " |      \n",
      " |      >>> df_multi_level_cols2.stack(0)\n",
      " |                   kg    m\n",
      " |      cat height  NaN  2.0\n",
      " |          weight  1.0  NaN\n",
      " |      dog height  NaN  4.0\n",
      " |          weight  3.0  NaN\n",
      " |      >>> df_multi_level_cols2.stack([0, 1])\n",
      " |      cat  height  m     2.0\n",
      " |           weight  kg    1.0\n",
      " |      dog  height  m     4.0\n",
      " |           weight  kg    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **Dropping missing values**\n",
      " |      \n",
      " |      >>> df_multi_level_cols3 = pd.DataFrame([[None, 1.0], [2.0, 3.0]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=multicol2)\n",
      " |      \n",
      " |      Note that rows where all values are missing are dropped by\n",
      " |      default but this behaviour can be controlled via the dropna\n",
      " |      keyword parameter:\n",
      " |      \n",
      " |      >>> df_multi_level_cols3\n",
      " |          weight height\n",
      " |              kg      m\n",
      " |      cat    NaN    1.0\n",
      " |      dog    2.0    3.0\n",
      " |      >>> df_multi_level_cols3.stack(dropna=False)\n",
      " |              height  weight\n",
      " |      cat kg     NaN     NaN\n",
      " |          m      1.0     NaN\n",
      " |      dog kg     NaN     2.0\n",
      " |          m      3.0     NaN\n",
      " |      >>> df_multi_level_cols3.stack(dropna=True)\n",
      " |              height  weight\n",
      " |      cat m      1.0     NaN\n",
      " |      dog kg     NaN     2.0\n",
      " |          m      3.0     NaN\n",
      " |  \n",
      " |  std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return sample standard deviation over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      std : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  sub(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Subtraction of dataframe and other, element-wise (binary operator `sub`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe - other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> a = pd.DataFrame([2, 1, 1, np.nan], index=['a', 'b', 'c', 'd'],\n",
      " |      ...                  columns=['one'])\n",
      " |      >>> a\n",
      " |         one\n",
      " |      a  2.0\n",
      " |      b  1.0\n",
      " |      c  1.0\n",
      " |      d  NaN\n",
      " |      >>> b = pd.DataFrame(dict(one=[1, np.nan, 1, np.nan],\n",
      " |      ...                       two=[3, 2, np.nan, 2]),\n",
      " |      ...                  index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |         one  two\n",
      " |      a  1.0  3.0\n",
      " |      b  NaN  2.0\n",
      " |      d  1.0  NaN\n",
      " |      e  NaN  2.0\n",
      " |      >>> a.sub(b, fill_value=0)\n",
      " |         one  two\n",
      " |      a  1.0  -3.0\n",
      " |      b  1.0  -2.0\n",
      " |      c  1.0  NaN\n",
      " |      d  -1.0  NaN\n",
      " |      e  NaN  -2.0\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.rsub\n",
      " |  \n",
      " |  subtract = sub(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  sum(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |      Return the sum of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |          .. versionadded :: 0.22.0\n",
      " |      \n",
      " |             Added with the default being 0. This means the sum of an all-NA\n",
      " |             or empty Series is 0, and the product of an all-NA or empty\n",
      " |             Series is 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sum : Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, the sum of an empty or all-NA Series is ``0``.\n",
      " |      \n",
      " |      >>> pd.Series([]).sum()  # min_count=0 is the default\n",
      " |      0.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter. For example, if\n",
      " |      you'd like the sum of an empty series to be NaN, pass ``min_count=1``.\n",
      " |      \n",
      " |      >>> pd.Series([]).sum(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).sum()\n",
      " |      0.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  swaplevel(self, i=-2, j=-1, axis=0)\n",
      " |      Swap levels i and j in a MultiIndex on a particular axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      i, j : int, string (can be mixed)\n",
      " |          Level of index to be swapped. Can pass level name as string.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      swapped : type of caller (new object)\n",
      " |      \n",
      " |      .. versionchanged:: 0.18.1\n",
      " |      \n",
      " |         The indexes ``i`` and ``j`` are now optional, and default to\n",
      " |         the two innermost levels of the index.\n",
      " |  \n",
      " |  to_csv(self, path_or_buf=None, sep=',', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, mode='w', encoding=None, compression=None, quoting=None, quotechar='\"', line_terminator='\\n', chunksize=None, tupleize_cols=None, date_format=None, doublequote=True, escapechar=None, decimal='.')\n",
      " |      Write DataFrame to a comma-separated values (csv) file\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : string or file handle, default None\n",
      " |          File path or object, if None is provided the result is returned as\n",
      " |          a string.\n",
      " |      sep : character, default ','\n",
      " |          Field delimiter for the output file.\n",
      " |      na_rep : string, default ''\n",
      " |          Missing data representation\n",
      " |      float_format : string, default None\n",
      " |          Format string for floating point numbers\n",
      " |      columns : sequence, optional\n",
      " |          Columns to write\n",
      " |      header : boolean or list of string, default True\n",
      " |          Write out the column names. If a list of strings is given it is\n",
      " |          assumed to be aliases for the column names\n",
      " |      index : boolean, default True\n",
      " |          Write row names (index)\n",
      " |      index_label : string or sequence, or False, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.  If\n",
      " |          False do not print fields for index names. Use index_label=False\n",
      " |          for easier importing in R\n",
      " |      mode : str\n",
      " |          Python write mode, default 'w'\n",
      " |      encoding : string, optional\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'ascii' on Python 2 and 'utf-8' on Python 3.\n",
      " |      compression : string, optional\n",
      " |          A string representing the compression to use in the output file.\n",
      " |          Allowed values are 'gzip', 'bz2', 'zip', 'xz'. This input is only\n",
      " |          used when the first argument is a filename.\n",
      " |      line_terminator : string, default ``'\\n'``\n",
      " |          The newline character or character sequence to use in the output\n",
      " |          file\n",
      " |      quoting : optional constant from csv module\n",
      " |          defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
      " |          then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
      " |          will treat them as non-numeric\n",
      " |      quotechar : string (length 1), default '\\\"'\n",
      " |          character used to quote fields\n",
      " |      doublequote : boolean, default True\n",
      " |          Control quoting of `quotechar` inside a field\n",
      " |      escapechar : string (length 1), default None\n",
      " |          character used to escape `sep` and `quotechar` when appropriate\n",
      " |      chunksize : int or None\n",
      " |          rows to write at a time\n",
      " |      tupleize_cols : boolean, default False\n",
      " |          .. deprecated:: 0.21.0\n",
      " |             This argument will be removed and will always write each row\n",
      " |             of the multi-index as a separate row in the CSV file.\n",
      " |      \n",
      " |          Write MultiIndex columns as a list of tuples (if True) or in\n",
      " |          the new, expanded format, where each MultiIndex column is a row\n",
      " |          in the CSV (if False).\n",
      " |      date_format : string, default None\n",
      " |          Format string for datetime objects\n",
      " |      decimal: string, default '.'\n",
      " |          Character recognized as decimal separator. E.g. use ',' for\n",
      " |          European data\n",
      " |  \n",
      " |  to_dict(self, orient='dict', into=<class 'dict'>)\n",
      " |      Convert the DataFrame to a dictionary.\n",
      " |      \n",
      " |      The type of the key-value pairs can be customized with the parameters\n",
      " |      (see below).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      orient : str {'dict', 'list', 'series', 'split', 'records', 'index'}\n",
      " |          Determines the type of the values of the dictionary.\n",
      " |      \n",
      " |          - 'dict' (default) : dict like {column -> {index -> value}}\n",
      " |          - 'list' : dict like {column -> [values]}\n",
      " |          - 'series' : dict like {column -> Series(values)}\n",
      " |          - 'split' : dict like\n",
      " |            {'index' -> [index], 'columns' -> [columns], 'data' -> [values]}\n",
      " |          - 'records' : list like\n",
      " |            [{column -> value}, ... , {column -> value}]\n",
      " |          - 'index' : dict like {index -> {column -> value}}\n",
      " |      \n",
      " |          Abbreviations are allowed. `s` indicates `series` and `sp`\n",
      " |          indicates `split`.\n",
      " |      \n",
      " |      into : class, default dict\n",
      " |          The collections.Mapping subclass used for all Mappings\n",
      " |          in the return value.  Can be the actual class or an empty\n",
      " |          instance of the mapping type you want.  If you want a\n",
      " |          collections.defaultdict, you must pass it initialized.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : collections.Mapping like {column -> {index -> value}}\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_dict: create a DataFrame from a dictionary\n",
      " |      DataFrame.to_json: convert a DataFrame to JSON format\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2],\n",
      " |      ...                    'col2': [0.5, 0.75]},\n",
      " |      ...                   index=['a', 'b'])\n",
      " |      >>> df\n",
      " |         col1  col2\n",
      " |      a     1   0.50\n",
      " |      b     2   0.75\n",
      " |      >>> df.to_dict()\n",
      " |      {'col1': {'a': 1, 'b': 2}, 'col2': {'a': 0.5, 'b': 0.75}}\n",
      " |      \n",
      " |      You can specify the return orientation.\n",
      " |      \n",
      " |      >>> df.to_dict('series')\n",
      " |      {'col1': a    1\n",
      " |               b    2\n",
      " |               Name: col1, dtype: int64,\n",
      " |       'col2': a    0.50\n",
      " |               b    0.75\n",
      " |               Name: col2, dtype: float64}\n",
      " |      \n",
      " |      >>> df.to_dict('split')\n",
      " |      {'index': ['a', 'b'], 'columns': ['col1', 'col2'],\n",
      " |       'data': [[1.0, 0.5], [2.0, 0.75]]}\n",
      " |      \n",
      " |      >>> df.to_dict('records')\n",
      " |      [{'col1': 1.0, 'col2': 0.5}, {'col1': 2.0, 'col2': 0.75}]\n",
      " |      \n",
      " |      >>> df.to_dict('index')\n",
      " |      {'a': {'col1': 1.0, 'col2': 0.5}, 'b': {'col1': 2.0, 'col2': 0.75}}\n",
      " |      \n",
      " |      You can also specify the mapping type.\n",
      " |      \n",
      " |      >>> from collections import OrderedDict, defaultdict\n",
      " |      >>> df.to_dict(into=OrderedDict)\n",
      " |      OrderedDict([('col1', OrderedDict([('a', 1), ('b', 2)])),\n",
      " |                   ('col2', OrderedDict([('a', 0.5), ('b', 0.75)]))])\n",
      " |      \n",
      " |      If you want a `defaultdict`, you need to initialize it:\n",
      " |      \n",
      " |      >>> dd = defaultdict(list)\n",
      " |      >>> df.to_dict('records', into=dd)\n",
      " |      [defaultdict(<class 'list'>, {'col1': 1.0, 'col2': 0.5}),\n",
      " |       defaultdict(<class 'list'>, {'col1': 2.0, 'col2': 0.75})]\n",
      " |  \n",
      " |  to_excel(self, excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True, freeze_panes=None)\n",
      " |      Write DataFrame to an excel sheet\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel_writer : string or ExcelWriter object\n",
      " |          File path or existing ExcelWriter\n",
      " |      sheet_name : string, default 'Sheet1'\n",
      " |          Name of sheet which will contain DataFrame\n",
      " |      na_rep : string, default ''\n",
      " |          Missing data representation\n",
      " |      float_format : string, default None\n",
      " |          Format string for floating point numbers\n",
      " |      columns : sequence, optional\n",
      " |          Columns to write\n",
      " |      header : boolean or list of string, default True\n",
      " |          Write out the column names. If a list of strings is given it is\n",
      " |          assumed to be aliases for the column names\n",
      " |      index : boolean, default True\n",
      " |          Write row names (index)\n",
      " |      index_label : string or sequence, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      startrow :\n",
      " |          upper left cell row to dump data frame\n",
      " |      startcol :\n",
      " |          upper left cell column to dump data frame\n",
      " |      engine : string, default None\n",
      " |          write engine to use - you can also set this via the options\n",
      " |          ``io.excel.xlsx.writer``, ``io.excel.xls.writer``, and\n",
      " |          ``io.excel.xlsm.writer``.\n",
      " |      merge_cells : boolean, default True\n",
      " |          Write MultiIndex and Hierarchical Rows as merged cells.\n",
      " |      encoding: string, default None\n",
      " |          encoding of the resulting excel file. Only necessary for xlwt,\n",
      " |          other writers support unicode natively.\n",
      " |      inf_rep : string, default 'inf'\n",
      " |          Representation for infinity (there is no native representation for\n",
      " |          infinity in Excel)\n",
      " |      freeze_panes : tuple of integer (length 2), default None\n",
      " |          Specifies the one-based bottommost row and rightmost column that\n",
      " |          is to be frozen\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If passing an existing ExcelWriter object, then the sheet will be added\n",
      " |      to the existing workbook.  This can be used to save different\n",
      " |      DataFrames to one workbook:\n",
      " |      \n",
      " |      >>> writer = pd.ExcelWriter('output.xlsx')\n",
      " |      >>> df1.to_excel(writer,'Sheet1')\n",
      " |      >>> df2.to_excel(writer,'Sheet2')\n",
      " |      >>> writer.save()\n",
      " |      \n",
      " |      For compatibility with to_csv, to_excel serializes lists and dicts to\n",
      " |      strings before writing.\n",
      " |  \n",
      " |  to_feather(self, fname)\n",
      " |      write out the binary feather-format for DataFrames\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : str\n",
      " |          string file path\n",
      " |  \n",
      " |  to_gbq(self, destination_table, project_id, chunksize=None, verbose=None, reauth=False, if_exists='fail', private_key=None, auth_local_webserver=False, table_schema=None)\n",
      " |      Write a DataFrame to a Google BigQuery table.\n",
      " |      \n",
      " |      This function requires the `pandas-gbq package\n",
      " |      <https://pandas-gbq.readthedocs.io>`__.\n",
      " |      \n",
      " |      Authentication to the Google BigQuery service is via OAuth 2.0.\n",
      " |      \n",
      " |      - If ``private_key`` is provided, the library loads the JSON service\n",
      " |        account credentials and uses those to authenticate.\n",
      " |      \n",
      " |      - If no ``private_key`` is provided, the library tries `application\n",
      " |        default credentials`_.\n",
      " |      \n",
      " |        .. _application default credentials:\n",
      " |            https://cloud.google.com/docs/authentication/production#providing_credentials_to_your_application\n",
      " |      \n",
      " |      - If application default credentials are not found or cannot be used\n",
      " |        with BigQuery, the library authenticates with user account\n",
      " |        credentials. In this case, you will be asked to grant permissions\n",
      " |        for product name 'pandas GBQ'.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      destination_table : str\n",
      " |          Name of table to be written, in the form 'dataset.tablename'.\n",
      " |      project_id : str\n",
      " |          Google BigQuery Account project ID.\n",
      " |      chunksize : int, optional\n",
      " |          Number of rows to be inserted in each chunk from the dataframe.\n",
      " |          Set to ``None`` to load the whole dataframe at once.\n",
      " |      reauth : bool, default False\n",
      " |          Force Google BigQuery to reauthenticate the user. This is useful\n",
      " |          if multiple accounts are used.\n",
      " |      if_exists : str, default 'fail'\n",
      " |          Behavior when the destination table exists. Value can be one of:\n",
      " |      \n",
      " |          ``'fail'``\n",
      " |              If table exists, do nothing.\n",
      " |          ``'replace'``\n",
      " |              If table exists, drop it, recreate it, and insert data.\n",
      " |          ``'append'``\n",
      " |              If table exists, insert data. Create if does not exist.\n",
      " |      private_key : str, optional\n",
      " |          Service account private key in JSON format. Can be file path\n",
      " |          or string contents. This is useful for remote server\n",
      " |          authentication (eg. Jupyter/IPython notebook on remote host).\n",
      " |      auth_local_webserver : bool, default False\n",
      " |          Use the `local webserver flow`_ instead of the `console flow`_\n",
      " |          when getting user credentials.\n",
      " |      \n",
      " |          .. _local webserver flow:\n",
      " |              http://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_local_server\n",
      " |          .. _console flow:\n",
      " |              http://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_console\n",
      " |      \n",
      " |          *New in version 0.2.0 of pandas-gbq*.\n",
      " |      table_schema : list of dicts, optional\n",
      " |          List of BigQuery table fields to which according DataFrame\n",
      " |          columns conform to, e.g. ``[{'name': 'col1', 'type':\n",
      " |          'STRING'},...]``. If schema is not provided, it will be\n",
      " |          generated according to dtypes of DataFrame columns. See\n",
      " |          BigQuery API documentation on available names of a field.\n",
      " |      \n",
      " |          *New in version 0.3.1 of pandas-gbq*.\n",
      " |      verbose : boolean, deprecated\n",
      " |          *Deprecated in Pandas-GBQ 0.4.0.* Use the `logging module\n",
      " |          to adjust verbosity instead\n",
      " |          <https://pandas-gbq.readthedocs.io/en/latest/intro.html#logging>`__.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas_gbq.to_gbq : This function in the pandas-gbq library.\n",
      " |      pandas.read_gbq : Read a DataFrame from Google BigQuery.\n",
      " |  \n",
      " |  to_html(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, justify=None, bold_rows=True, classes=None, escape=True, max_rows=None, max_cols=None, show_dimensions=False, notebook=False, decimal='.', border=None, table_id=None)\n",
      " |      Render a DataFrame as an HTML table.\n",
      " |      \n",
      " |      `to_html`-specific options:\n",
      " |      \n",
      " |      bold_rows : boolean, default True\n",
      " |          Make the row labels bold in the output\n",
      " |      classes : str or list or tuple, default None\n",
      " |          CSS class(es) to apply to the resulting html table\n",
      " |      escape : boolean, default True\n",
      " |          Convert the characters <, >, and & to HTML-safe sequences.\n",
      " |      max_rows : int, optional\n",
      " |          Maximum number of rows to show before truncating. If None, show\n",
      " |          all.\n",
      " |      max_cols : int, optional\n",
      " |          Maximum number of columns to show before truncating. If None, show\n",
      " |          all.\n",
      " |      decimal : string, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      border : int\n",
      " |          A ``border=border`` attribute is included in the opening\n",
      " |          `<table>` tag. Default ``pd.options.html.border``.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      table_id : str, optional\n",
      " |          A css id is included in the opening `<table>` tag if specified.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : StringIO-like, optional\n",
      " |          buffer to write to\n",
      " |      columns : sequence, optional\n",
      " |          the subset of columns to write; default None writes all columns\n",
      " |      col_space : int, optional\n",
      " |          the minimum width of each column\n",
      " |      header : bool, optional\n",
      " |          whether to print column labels, default True\n",
      " |      index : bool, optional\n",
      " |          whether to print index (row) labels, default True\n",
      " |      na_rep : string, optional\n",
      " |          string representation of NAN to use, default 'NaN'\n",
      " |      formatters : list or dict of one-parameter functions, optional\n",
      " |          formatter functions to apply to columns' elements by position or name,\n",
      " |          default None. The result of each function must be a unicode string.\n",
      " |          List must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function, optional\n",
      " |          formatter function to apply to columns' elements if they are floats,\n",
      " |          default None. The result of this function must be a unicode string.\n",
      " |      sparsify : bool, optional\n",
      " |          Set to False for a DataFrame with a hierarchical index to print every\n",
      " |          multiindex key at each row, default True\n",
      " |      index_names : bool, optional\n",
      " |          Prints the names of the indexes, default True\n",
      " |      line_width : int, optional\n",
      " |          Width to wrap a line in characters, default no wrap\n",
      " |      table_id : str, optional\n",
      " |          id for the <table> element create by to_html\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      justify : str, default None\n",
      " |          How to justify the column labels. If None uses the option from\n",
      " |          the print configuration (controlled by set_option), 'right' out\n",
      " |          of the box. Valid values are\n",
      " |      \n",
      " |          * left\n",
      " |          * right\n",
      " |          * center\n",
      " |          * justify\n",
      " |          * justify-all\n",
      " |          * start\n",
      " |          * end\n",
      " |          * inherit\n",
      " |          * match-parent\n",
      " |          * initial\n",
      " |          * unset\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      formatted : string (or unicode, depending on data and options)\n",
      " |  \n",
      " |  to_panel(self)\n",
      " |      Transform long (stacked) format (DataFrame) into wide (3D, Panel)\n",
      " |      format.\n",
      " |      \n",
      " |      .. deprecated:: 0.20.0\n",
      " |      \n",
      " |      Currently the index of the DataFrame must be a 2-level MultiIndex. This\n",
      " |      may be generalized later\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      panel : Panel\n",
      " |  \n",
      " |  to_parquet(self, fname, engine='auto', compression='snappy', **kwargs)\n",
      " |      Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      This function writes the dataframe as a `parquet file\n",
      " |      <https://parquet.apache.org/>`_. You can choose different parquet\n",
      " |      backends, and have the option of compression. See\n",
      " |      :ref:`the user guide <io.parquet>` for more details.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : str\n",
      " |          String file path.\n",
      " |      engine : {'auto', 'pyarrow', 'fastparquet'}, default 'auto'\n",
      " |          Parquet library to use. If 'auto', then the option\n",
      " |          ``io.parquet.engine`` is used. The default ``io.parquet.engine``\n",
      " |          behavior is to try 'pyarrow', falling back to 'fastparquet' if\n",
      " |          'pyarrow' is unavailable.\n",
      " |      compression : {'snappy', 'gzip', 'brotli', None}, default 'snappy'\n",
      " |          Name of the compression to use. Use ``None`` for no compression.\n",
      " |      **kwargs\n",
      " |          Additional arguments passed to the parquet library. See\n",
      " |          :ref:`pandas io <io.parquet>` for more details.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_parquet : Read a parquet file.\n",
      " |      DataFrame.to_csv : Write a csv file.\n",
      " |      DataFrame.to_sql : Write to a sql table.\n",
      " |      DataFrame.to_hdf : Write to hdf.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function requires either the `fastparquet\n",
      " |      <https://pypi.org/project/fastparquet>`_ or `pyarrow\n",
      " |      <https://arrow.apache.org/docs/python/>`_ library.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(data={'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.to_parquet('df.parquet.gzip', compression='gzip')\n",
      " |      >>> pd.read_parquet('df.parquet.gzip')\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |  \n",
      " |  to_period(self, freq=None, axis=0, copy=True)\n",
      " |      Convert DataFrame from DatetimeIndex to PeriodIndex with desired\n",
      " |      frequency (inferred from index if not passed)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : string, default\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to convert (the index by default)\n",
      " |      copy : boolean, default True\n",
      " |          If False then underlying input data is not copied\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ts : TimeSeries with PeriodIndex\n",
      " |  \n",
      " |  to_records(self, index=True, convert_datetime64=None)\n",
      " |      Convert DataFrame to a NumPy record array.\n",
      " |      \n",
      " |      Index will be put in the 'index' field of the record array if\n",
      " |      requested.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : boolean, default True\n",
      " |          Include index in resulting record array, stored in 'index' field.\n",
      " |      convert_datetime64 : boolean, default None\n",
      " |          .. deprecated:: 0.23.0\n",
      " |      \n",
      " |          Whether to convert the index to datetime.datetime if it is a\n",
      " |          DatetimeIndex.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : numpy.recarray\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_records: convert structured or record ndarray\n",
      " |          to DataFrame.\n",
      " |      numpy.recarray: ndarray that allows field access using\n",
      " |          attributes, analogous to typed columns in a\n",
      " |          spreadsheet.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2], 'B': [0.5, 0.75]},\n",
      " |      ...                   index=['a', 'b'])\n",
      " |      >>> df\n",
      " |         A     B\n",
      " |      a  1  0.50\n",
      " |      b  2  0.75\n",
      " |      >>> df.to_records()\n",
      " |      rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n",
      " |                dtype=[('index', 'O'), ('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      The index can be excluded from the record array:\n",
      " |      \n",
      " |      >>> df.to_records(index=False)\n",
      " |      rec.array([(1, 0.5 ), (2, 0.75)],\n",
      " |                dtype=[('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      By default, timestamps are converted to `datetime.datetime`:\n",
      " |      \n",
      " |      >>> df.index = pd.date_range('2018-01-01 09:00', periods=2, freq='min')\n",
      " |      >>> df\n",
      " |                           A     B\n",
      " |      2018-01-01 09:00:00  1  0.50\n",
      " |      2018-01-01 09:01:00  2  0.75\n",
      " |      >>> df.to_records()\n",
      " |      rec.array([(datetime.datetime(2018, 1, 1, 9, 0), 1, 0.5 ),\n",
      " |                 (datetime.datetime(2018, 1, 1, 9, 1), 2, 0.75)],\n",
      " |                dtype=[('index', 'O'), ('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      The timestamp conversion can be disabled so NumPy's datetime64\n",
      " |      data type is used instead:\n",
      " |      \n",
      " |      >>> df.to_records(convert_datetime64=False)\n",
      " |      rec.array([('2018-01-01T09:00:00.000000000', 1, 0.5 ),\n",
      " |                 ('2018-01-01T09:01:00.000000000', 2, 0.75)],\n",
      " |                dtype=[('index', '<M8[ns]'), ('A', '<i8'), ('B', '<f8')])\n",
      " |  \n",
      " |  to_sparse(self, fill_value=None, kind='block')\n",
      " |      Convert to SparseDataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fill_value : float, default NaN\n",
      " |      kind : {'block', 'integer'}\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : SparseDataFrame\n",
      " |  \n",
      " |  to_stata(self, fname, convert_dates=None, write_index=True, encoding='latin-1', byteorder=None, time_stamp=None, data_label=None, variable_labels=None, version=114, convert_strl=None)\n",
      " |      Export Stata binary dta files.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : path (string), buffer or path object\n",
      " |          string, path object (pathlib.Path or py._path.local.LocalPath) or\n",
      " |          object implementing a binary write() functions. If using a buffer\n",
      " |          then the buffer will not be automatically closed after the file\n",
      " |          data has been written.\n",
      " |      convert_dates : dict\n",
      " |          Dictionary mapping columns containing datetime types to stata\n",
      " |          internal format to use when writing the dates. Options are 'tc',\n",
      " |          'td', 'tm', 'tw', 'th', 'tq', 'ty'. Column can be either an integer\n",
      " |          or a name. Datetime columns that do not have a conversion type\n",
      " |          specified will be converted to 'tc'. Raises NotImplementedError if\n",
      " |          a datetime column has timezone information.\n",
      " |      write_index : bool\n",
      " |          Write the index to Stata dataset.\n",
      " |      encoding : str\n",
      " |          Default is latin-1. Unicode is not supported.\n",
      " |      byteorder : str\n",
      " |          Can be \">\", \"<\", \"little\", or \"big\". default is `sys.byteorder`.\n",
      " |      time_stamp : datetime\n",
      " |          A datetime to use as file creation date.  Default is the current\n",
      " |          time.\n",
      " |      data_label : str\n",
      " |          A label for the data set.  Must be 80 characters or smaller.\n",
      " |      variable_labels : dict\n",
      " |          Dictionary containing columns as keys and variable labels as\n",
      " |          values. Each label must be 80 characters or smaller.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      version : {114, 117}\n",
      " |          Version to use in the output dta file.  Version 114 can be used\n",
      " |          read by Stata 10 and later.  Version 117 can be read by Stata 13\n",
      " |          or later. Version 114 limits string variables to 244 characters or\n",
      " |          fewer while 117 allows strings with lengths up to 2,000,000\n",
      " |          characters.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      convert_strl : list, optional\n",
      " |          List of column names to convert to string columns to Stata StrL\n",
      " |          format. Only available if version is 117.  Storing strings in the\n",
      " |          StrL format can produce smaller dta files if strings have more than\n",
      " |          8 characters and values are repeated.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      NotImplementedError\n",
      " |          * If datetimes contain timezone information\n",
      " |          * Column dtype is not representable in Stata\n",
      " |      ValueError\n",
      " |          * Columns listed in convert_dates are neither datetime64[ns]\n",
      " |            or datetime.datetime\n",
      " |          * Column listed in convert_dates is not in DataFrame\n",
      " |          * Categorical label contains more than 32,000 characters\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.read_stata : Import Stata data files\n",
      " |      pandas.io.stata.StataWriter : low-level writer for Stata data files\n",
      " |      pandas.io.stata.StataWriter117 : low-level writer for version 117 files\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data.to_stata('./data_file.dta')\n",
      " |      \n",
      " |      Or with dates\n",
      " |      \n",
      " |      >>> data.to_stata('./date_data_file.dta', {2 : 'tw'})\n",
      " |      \n",
      " |      Alternatively you can create an instance of the StataWriter class\n",
      " |      \n",
      " |      >>> writer = StataWriter('./data_file.dta', data)\n",
      " |      >>> writer.write_file()\n",
      " |      \n",
      " |      With dates:\n",
      " |      \n",
      " |      >>> writer = StataWriter('./date_data_file.dta', data, {2 : 'tw'})\n",
      " |      >>> writer.write_file()\n",
      " |  \n",
      " |  to_string(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, justify=None, line_width=None, max_rows=None, max_cols=None, show_dimensions=False)\n",
      " |      Render a DataFrame to a console-friendly tabular output.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : StringIO-like, optional\n",
      " |          buffer to write to\n",
      " |      columns : sequence, optional\n",
      " |          the subset of columns to write; default None writes all columns\n",
      " |      col_space : int, optional\n",
      " |          the minimum width of each column\n",
      " |      header : bool, optional\n",
      " |          Write out the column names. If a list of strings is given, it is assumed to be aliases for the column names\n",
      " |      index : bool, optional\n",
      " |          whether to print index (row) labels, default True\n",
      " |      na_rep : string, optional\n",
      " |          string representation of NAN to use, default 'NaN'\n",
      " |      formatters : list or dict of one-parameter functions, optional\n",
      " |          formatter functions to apply to columns' elements by position or name,\n",
      " |          default None. The result of each function must be a unicode string.\n",
      " |          List must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function, optional\n",
      " |          formatter function to apply to columns' elements if they are floats,\n",
      " |          default None. The result of this function must be a unicode string.\n",
      " |      sparsify : bool, optional\n",
      " |          Set to False for a DataFrame with a hierarchical index to print every\n",
      " |          multiindex key at each row, default True\n",
      " |      index_names : bool, optional\n",
      " |          Prints the names of the indexes, default True\n",
      " |      line_width : int, optional\n",
      " |          Width to wrap a line in characters, default no wrap\n",
      " |      table_id : str, optional\n",
      " |          id for the <table> element create by to_html\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      justify : str, default None\n",
      " |          How to justify the column labels. If None uses the option from\n",
      " |          the print configuration (controlled by set_option), 'right' out\n",
      " |          of the box. Valid values are\n",
      " |      \n",
      " |          * left\n",
      " |          * right\n",
      " |          * center\n",
      " |          * justify\n",
      " |          * justify-all\n",
      " |          * start\n",
      " |          * end\n",
      " |          * inherit\n",
      " |          * match-parent\n",
      " |          * initial\n",
      " |          * unset\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      formatted : string (or unicode, depending on data and options)\n",
      " |  \n",
      " |  to_timestamp(self, freq=None, how='start', axis=0, copy=True)\n",
      " |      Cast to DatetimeIndex of timestamps, at *beginning* of period\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : string, default frequency of PeriodIndex\n",
      " |          Desired frequency\n",
      " |      how : {'s', 'e', 'start', 'end'}\n",
      " |          Convention for converting period to timestamp; start of period\n",
      " |          vs. end\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to convert (the index by default)\n",
      " |      copy : boolean, default True\n",
      " |          If false then underlying input data is not copied\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      df : DataFrame with DatetimeIndex\n",
      " |  \n",
      " |  transform(self, func, *args, **kwargs)\n",
      " |      Call function producing a like-indexed NDFrame\n",
      " |      and return a NDFrame with the transformed values\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable, string, dictionary, or list of string/callables\n",
      " |          To apply to column\n",
      " |      \n",
      " |          Accepted Combinations are:\n",
      " |      \n",
      " |          - string function name\n",
      " |          - function\n",
      " |          - list of functions\n",
      " |          - dict of column names -> functions (or list of functions)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      transformed : NDFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],\n",
      " |      ...                   index=pd.date_range('1/1/2000', periods=10))\n",
      " |      df.iloc[3:7] = np.nan\n",
      " |      \n",
      " |      >>> df.transform(lambda x: (x - x.mean()) / x.std())\n",
      " |                         A         B         C\n",
      " |      2000-01-01  0.579457  1.236184  0.123424\n",
      " |      2000-01-02  0.370357 -0.605875 -1.231325\n",
      " |      2000-01-03  1.455756 -0.277446  0.288967\n",
      " |      2000-01-04       NaN       NaN       NaN\n",
      " |      2000-01-05       NaN       NaN       NaN\n",
      " |      2000-01-06       NaN       NaN       NaN\n",
      " |      2000-01-07       NaN       NaN       NaN\n",
      " |      2000-01-08 -0.498658  1.274522  1.642524\n",
      " |      2000-01-09 -0.540524 -1.012676 -0.828968\n",
      " |      2000-01-10 -1.366388 -0.614710  0.005378\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.NDFrame.aggregate\n",
      " |      pandas.NDFrame.apply\n",
      " |  \n",
      " |  transpose(self, *args, **kwargs)\n",
      " |      Transpose index and columns.\n",
      " |      \n",
      " |      Reflect the DataFrame over its main diagonal by writing rows as columns\n",
      " |      and vice-versa. The property :attr:`.T` is an accessor to the method\n",
      " |      :meth:`transpose`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : bool, default False\n",
      " |          If True, the underlying data is copied. Otherwise (default), no\n",
      " |          copy is made if possible.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with numpy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The transposed DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.transpose : Permute the dimensions of a given array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Transposing a DataFrame with mixed dtypes will result in a homogeneous\n",
      " |      DataFrame with the `object` dtype. In such a case, a copy of the data\n",
      " |      is always made.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Square DataFrame with homogeneous dtype**\n",
      " |      \n",
      " |      >>> d1 = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |      >>> df1 = pd.DataFrame(data=d1)\n",
      " |      >>> df1\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |      \n",
      " |      >>> df1_transposed = df1.T # or df1.transpose()\n",
      " |      >>> df1_transposed\n",
      " |            0  1\n",
      " |      col1  1  2\n",
      " |      col2  3  4\n",
      " |      \n",
      " |      When the dtype is homogeneous in the original DataFrame, we get a\n",
      " |      transposed DataFrame with the same dtype:\n",
      " |      \n",
      " |      >>> df1.dtypes\n",
      " |      col1    int64\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |      >>> df1_transposed.dtypes\n",
      " |      0    int64\n",
      " |      1    int64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      **Non-square DataFrame with mixed dtypes**\n",
      " |      \n",
      " |      >>> d2 = {'name': ['Alice', 'Bob'],\n",
      " |      ...       'score': [9.5, 8],\n",
      " |      ...       'employed': [False, True],\n",
      " |      ...       'kids': [0, 0]}\n",
      " |      >>> df2 = pd.DataFrame(data=d2)\n",
      " |      >>> df2\n",
      " |          name  score  employed  kids\n",
      " |      0  Alice    9.5     False     0\n",
      " |      1    Bob    8.0      True     0\n",
      " |      \n",
      " |      >>> df2_transposed = df2.T # or df2.transpose()\n",
      " |      >>> df2_transposed\n",
      " |                    0     1\n",
      " |      name      Alice   Bob\n",
      " |      score       9.5     8\n",
      " |      employed  False  True\n",
      " |      kids          0     0\n",
      " |      \n",
      " |      When the DataFrame has mixed dtypes, we get a transposed DataFrame with\n",
      " |      the `object` dtype:\n",
      " |      \n",
      " |      >>> df2.dtypes\n",
      " |      name         object\n",
      " |      score       float64\n",
      " |      employed       bool\n",
      " |      kids          int64\n",
      " |      dtype: object\n",
      " |      >>> df2_transposed.dtypes\n",
      " |      0    object\n",
      " |      1    object\n",
      " |      dtype: object\n",
      " |  \n",
      " |  truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Floating division of dataframe and other, element-wise (binary operator `truediv`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe / other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      None\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.rtruediv\n",
      " |  \n",
      " |  unstack(self, level=-1, fill_value=None)\n",
      " |      Pivot a level of the (necessarily hierarchical) index labels, returning\n",
      " |      a DataFrame having a new level of column labels whose inner-most level\n",
      " |      consists of the pivoted index labels. If the index is not a MultiIndex,\n",
      " |      the output will be a Series (the analogue of stack when the columns are\n",
      " |      not a MultiIndex).\n",
      " |      The level involved will automatically get sorted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, string, or list of these, default -1 (last level)\n",
      " |          Level(s) of index to unstack, can pass level name\n",
      " |      fill_value : replace NaN with this value if the unstack produces\n",
      " |          missing values\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.pivot : Pivot a table based on column values.\n",
      " |      DataFrame.stack : Pivot a level of the column labels (inverse operation\n",
      " |          from `unstack`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> index = pd.MultiIndex.from_tuples([('one', 'a'), ('one', 'b'),\n",
      " |      ...                                    ('two', 'a'), ('two', 'b')])\n",
      " |      >>> s = pd.Series(np.arange(1.0, 5.0), index=index)\n",
      " |      >>> s\n",
      " |      one  a   1.0\n",
      " |           b   2.0\n",
      " |      two  a   3.0\n",
      " |           b   4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.unstack(level=-1)\n",
      " |           a   b\n",
      " |      one  1.0  2.0\n",
      " |      two  3.0  4.0\n",
      " |      \n",
      " |      >>> s.unstack(level=0)\n",
      " |         one  two\n",
      " |      a  1.0   3.0\n",
      " |      b  2.0   4.0\n",
      " |      \n",
      " |      >>> df = s.unstack(level=0)\n",
      " |      >>> df.unstack()\n",
      " |      one  a  1.0\n",
      " |           b  2.0\n",
      " |      two  a  3.0\n",
      " |           b  4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      unstacked : DataFrame or Series\n",
      " |  \n",
      " |  update(self, other, join='left', overwrite=True, filter_func=None, raise_conflict=False)\n",
      " |      Modify in place using non-NA values from another DataFrame.\n",
      " |      \n",
      " |      Aligns on indices. There is no return value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, or object coercible into a DataFrame\n",
      " |          Should have at least one matching index/column label\n",
      " |          with the original DataFrame. If a Series is passed,\n",
      " |          its name attribute must be set, and that will be\n",
      " |          used as the column name to align with the original DataFrame.\n",
      " |      join : {'left'}, default 'left'\n",
      " |          Only left join is implemented, keeping the index and columns of the\n",
      " |          original object.\n",
      " |      overwrite : bool, default True\n",
      " |          How to handle non-NA values for overlapping keys:\n",
      " |      \n",
      " |          * True: overwrite original DataFrame's values\n",
      " |            with values from `other`.\n",
      " |          * False: only update values that are NA in\n",
      " |            the original DataFrame.\n",
      " |      \n",
      " |      filter_func : callable(1d-array) -> boolean 1d-array, optional\n",
      " |          Can choose to replace values other than NA. Return True for values\n",
      " |          that should be updated.\n",
      " |      raise_conflict : bool, default False\n",
      " |          If True, will raise a ValueError if the DataFrame and `other`\n",
      " |          both contain non-NA data in the same place.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          When `raise_conflict` is True and there's overlapping non-NA data.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      dict.update : Similar method for dictionaries.\n",
      " |      DataFrame.merge : For column(s)-on-columns(s) operations.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3],\n",
      " |      ...                    'B': [400, 500, 600]})\n",
      " |      >>> new_df = pd.DataFrame({'B': [4, 5, 6],\n",
      " |      ...                        'C': [7, 8, 9]})\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |      \n",
      " |      The DataFrame's length does not increase as a result of the update,\n",
      " |      only values at matching index/column labels are updated.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      " |      ...                    'B': ['x', 'y', 'z']})\n",
      " |      >>> new_df = pd.DataFrame({'B': ['d', 'e', 'f', 'g', 'h', 'i']})\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  d\n",
      " |      1  b  e\n",
      " |      2  c  f\n",
      " |      \n",
      " |      For Series, it's name attribute must be set.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      " |      ...                    'B': ['x', 'y', 'z']})\n",
      " |      >>> new_column = pd.Series(['d', 'e'], name='B', index=[0, 2])\n",
      " |      >>> df.update(new_column)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  d\n",
      " |      1  b  y\n",
      " |      2  c  e\n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      " |      ...                    'B': ['x', 'y', 'z']})\n",
      " |      >>> new_df = pd.DataFrame({'B': ['d', 'e']}, index=[1, 2])\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  x\n",
      " |      1  b  d\n",
      " |      2  c  e\n",
      " |      \n",
      " |      If `other` contains NaNs the corresponding values are not updated\n",
      " |      in the original dataframe.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3],\n",
      " |      ...                    'B': [400, 500, 600]})\n",
      " |      >>> new_df = pd.DataFrame({'B': [4, np.nan, 6]})\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A      B\n",
      " |      0  1    4.0\n",
      " |      1  2  500.0\n",
      " |      2  3    6.0\n",
      " |  \n",
      " |  var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased variance over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      var : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_csv(path, header=0, sep=',', index_col=0, parse_dates=True, encoding=None, tupleize_cols=None, infer_datetime_format=False) from builtins.type\n",
      " |      Read CSV file.\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |          Use :func:`pandas.read_csv` instead.\n",
      " |      \n",
      " |      It is preferable to use the more powerful :func:`pandas.read_csv`\n",
      " |      for most general purposes, but ``from_csv`` makes for an easy\n",
      " |      roundtrip to and from a file (the exact counterpart of\n",
      " |      ``to_csv``), especially with a DataFrame of time series data.\n",
      " |      \n",
      " |      This method only differs from the preferred :func:`pandas.read_csv`\n",
      " |      in some defaults:\n",
      " |      \n",
      " |      - `index_col` is ``0`` instead of ``None`` (take first column as index\n",
      " |        by default)\n",
      " |      - `parse_dates` is ``True`` instead of ``False`` (try parsing the index\n",
      " |        as datetime by default)\n",
      " |      \n",
      " |      So a ``pd.DataFrame.from_csv(path)`` can be replaced by\n",
      " |      ``pd.read_csv(path, index_col=0, parse_dates=True)``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string file path or file handle / StringIO\n",
      " |      header : int, default 0\n",
      " |          Row to use as header (skip prior rows)\n",
      " |      sep : string, default ','\n",
      " |          Field delimiter\n",
      " |      index_col : int or sequence, default 0\n",
      " |          Column to use for index. If a sequence is given, a MultiIndex\n",
      " |          is used. Different default from read_table\n",
      " |      parse_dates : boolean, default True\n",
      " |          Parse dates. Different default from read_table\n",
      " |      tupleize_cols : boolean, default False\n",
      " |          write multi_index columns as a list of tuples (if True)\n",
      " |          or new (expanded format) if False)\n",
      " |      infer_datetime_format: boolean, default False\n",
      " |          If True and `parse_dates` is True for a column, try to infer the\n",
      " |          datetime format based on the first datetime string. If the format\n",
      " |          can be inferred, there often will be a large parsing speed-up.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.read_csv\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : DataFrame\n",
      " |  \n",
      " |  from_dict(data, orient='columns', dtype=None, columns=None) from builtins.type\n",
      " |      Construct DataFrame from dict of array-like or dicts.\n",
      " |      \n",
      " |      Creates DataFrame object from dictionary by columns or by index\n",
      " |      allowing dtype specification.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : dict\n",
      " |          Of the form {field : array-like} or {field : dict}.\n",
      " |      orient : {'columns', 'index'}, default 'columns'\n",
      " |          The \"orientation\" of the data. If the keys of the passed dict\n",
      " |          should be the columns of the resulting DataFrame, pass 'columns'\n",
      " |          (default). Otherwise if the keys should be rows, pass 'index'.\n",
      " |      dtype : dtype, default None\n",
      " |          Data type to force, otherwise infer.\n",
      " |      columns : list, default None\n",
      " |          Column labels to use when ``orient='index'``. Raises a ValueError\n",
      " |          if used with ``orient='columns'``.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_records : DataFrame from ndarray (structured\n",
      " |          dtype), list of tuples, dict, or DataFrame\n",
      " |      DataFrame : DataFrame object creation using constructor\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default the keys of the dict become the DataFrame columns:\n",
      " |      \n",
      " |      >>> data = {'col_1': [3, 2, 1, 0], 'col_2': ['a', 'b', 'c', 'd']}\n",
      " |      >>> pd.DataFrame.from_dict(data)\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |      \n",
      " |      Specify ``orient='index'`` to create the DataFrame using dictionary\n",
      " |      keys as rows:\n",
      " |      \n",
      " |      >>> data = {'row_1': [3, 2, 1, 0], 'row_2': ['a', 'b', 'c', 'd']}\n",
      " |      >>> pd.DataFrame.from_dict(data, orient='index')\n",
      " |             0  1  2  3\n",
      " |      row_1  3  2  1  0\n",
      " |      row_2  a  b  c  d\n",
      " |      \n",
      " |      When using the 'index' orientation, the column names can be\n",
      " |      specified manually:\n",
      " |      \n",
      " |      >>> pd.DataFrame.from_dict(data, orient='index',\n",
      " |      ...                        columns=['A', 'B', 'C', 'D'])\n",
      " |             A  B  C  D\n",
      " |      row_1  3  2  1  0\n",
      " |      row_2  a  b  c  d\n",
      " |  \n",
      " |  from_items(items, columns=None, orient='columns') from builtins.type\n",
      " |      Construct a dataframe from a list of tuples\n",
      " |      \n",
      " |      .. deprecated:: 0.23.0\n",
      " |        `from_items` is deprecated and will be removed in a future version.\n",
      " |        Use :meth:`DataFrame.from_dict(dict(items)) <DataFrame.from_dict>`\n",
      " |        instead.\n",
      " |        :meth:`DataFrame.from_dict(OrderedDict(items)) <DataFrame.from_dict>`\n",
      " |        may be used to preserve the key order.\n",
      " |      \n",
      " |      Convert (key, value) pairs to DataFrame. The keys will be the axis\n",
      " |      index (usually the columns, but depends on the specified\n",
      " |      orientation). The values should be arrays or Series.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      items : sequence of (key, value) pairs\n",
      " |          Values should be arrays or Series.\n",
      " |      columns : sequence of column labels, optional\n",
      " |          Must be passed if orient='index'.\n",
      " |      orient : {'columns', 'index'}, default 'columns'\n",
      " |          The \"orientation\" of the data. If the keys of the\n",
      " |          input correspond to column labels, pass 'columns'\n",
      " |          (default). Otherwise if the keys correspond to the index,\n",
      " |          pass 'index'.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      frame : DataFrame\n",
      " |  \n",
      " |  from_records(data, index=None, exclude=None, columns=None, coerce_float=False, nrows=None) from builtins.type\n",
      " |      Convert structured or record ndarray to DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : ndarray (structured dtype), list of tuples, dict, or DataFrame\n",
      " |      index : string, list of fields, array-like\n",
      " |          Field of array to use as the index, alternately a specific set of\n",
      " |          input labels to use\n",
      " |      exclude : sequence, default None\n",
      " |          Columns or fields to exclude\n",
      " |      columns : sequence, default None\n",
      " |          Column names to use. If the passed data do not have names\n",
      " |          associated with them, this argument provides names for the\n",
      " |          columns. Otherwise this argument indicates the order of the columns\n",
      " |          in the result (any names not found in the data will become all-NA\n",
      " |          columns)\n",
      " |      coerce_float : boolean, default False\n",
      " |          Attempt to convert values of non-string, non-numeric objects (like\n",
      " |          decimal.Decimal) to floating point, useful for SQL result sets\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      df : DataFrame\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  T\n",
      " |      Transpose index and columns.\n",
      " |      \n",
      " |      Reflect the DataFrame over its main diagonal by writing rows as columns\n",
      " |      and vice-versa. The property :attr:`.T` is an accessor to the method\n",
      " |      :meth:`transpose`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : bool, default False\n",
      " |          If True, the underlying data is copied. Otherwise (default), no\n",
      " |          copy is made if possible.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with numpy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The transposed DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.transpose : Permute the dimensions of a given array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Transposing a DataFrame with mixed dtypes will result in a homogeneous\n",
      " |      DataFrame with the `object` dtype. In such a case, a copy of the data\n",
      " |      is always made.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Square DataFrame with homogeneous dtype**\n",
      " |      \n",
      " |      >>> d1 = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |      >>> df1 = pd.DataFrame(data=d1)\n",
      " |      >>> df1\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |      \n",
      " |      >>> df1_transposed = df1.T # or df1.transpose()\n",
      " |      >>> df1_transposed\n",
      " |            0  1\n",
      " |      col1  1  2\n",
      " |      col2  3  4\n",
      " |      \n",
      " |      When the dtype is homogeneous in the original DataFrame, we get a\n",
      " |      transposed DataFrame with the same dtype:\n",
      " |      \n",
      " |      >>> df1.dtypes\n",
      " |      col1    int64\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |      >>> df1_transposed.dtypes\n",
      " |      0    int64\n",
      " |      1    int64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      **Non-square DataFrame with mixed dtypes**\n",
      " |      \n",
      " |      >>> d2 = {'name': ['Alice', 'Bob'],\n",
      " |      ...       'score': [9.5, 8],\n",
      " |      ...       'employed': [False, True],\n",
      " |      ...       'kids': [0, 0]}\n",
      " |      >>> df2 = pd.DataFrame(data=d2)\n",
      " |      >>> df2\n",
      " |          name  score  employed  kids\n",
      " |      0  Alice    9.5     False     0\n",
      " |      1    Bob    8.0      True     0\n",
      " |      \n",
      " |      >>> df2_transposed = df2.T # or df2.transpose()\n",
      " |      >>> df2_transposed\n",
      " |                    0     1\n",
      " |      name      Alice   Bob\n",
      " |      score       9.5     8\n",
      " |      employed  False  True\n",
      " |      kids          0     0\n",
      " |      \n",
      " |      When the DataFrame has mixed dtypes, we get a transposed DataFrame with\n",
      " |      the `object` dtype:\n",
      " |      \n",
      " |      >>> df2.dtypes\n",
      " |      name         object\n",
      " |      score       float64\n",
      " |      employed       bool\n",
      " |      kids          int64\n",
      " |      dtype: object\n",
      " |      >>> df2_transposed.dtypes\n",
      " |      0    object\n",
      " |      1    object\n",
      " |      dtype: object\n",
      " |  \n",
      " |  axes\n",
      " |      Return a list representing the axes of the DataFrame.\n",
      " |      \n",
      " |      It has the row axis labels and column axis labels as the only members.\n",
      " |      They are returned in that order.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.axes\n",
      " |      [RangeIndex(start=0, stop=2, step=1), Index(['coll', 'col2'],\n",
      " |      dtype='object')]\n",
      " |  \n",
      " |  columns\n",
      " |      The column labels of the DataFrame.\n",
      " |  \n",
      " |  index\n",
      " |      The index (row labels) of the DataFrame.\n",
      " |  \n",
      " |  shape\n",
      " |      Return a tuple representing the dimensionality of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndarray.shape\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.shape\n",
      " |      (2, 2)\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4],\n",
      " |      ...                    'col3': [5, 6]})\n",
      " |      >>> df.shape\n",
      " |      (2, 3)\n",
      " |  \n",
      " |  style\n",
      " |      Property returning a Styler object containing methods for\n",
      " |      building a styled HTML representation fo the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.io.formats.style.Styler\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  plot = <class 'pandas.plotting._core.FramePlotMethods'>\n",
      " |      DataFrame plotting accessor and method\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df.plot.line()\n",
      " |      >>> df.plot.scatter('x', 'y')\n",
      " |      >>> df.plot.hexbin()\n",
      " |      \n",
      " |      These plotting methods can also be accessed by calling the accessor as a\n",
      " |      method with the ``kind`` argument:\n",
      " |      ``df.plot(kind='line')`` is equivalent to ``df.plot.line()``\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  __abs__(self)\n",
      " |  \n",
      " |  __array__(self, dtype=None)\n",
      " |  \n",
      " |  __array_wrap__(self, result, context=None)\n",
      " |  \n",
      " |  __bool__ = __nonzero__(self)\n",
      " |  \n",
      " |  __contains__(self, key)\n",
      " |      True if the key is in the info axis\n",
      " |  \n",
      " |  __copy__(self, deep=True)\n",
      " |  \n",
      " |  __deepcopy__(self, memo=None)\n",
      " |  \n",
      " |  __delitem__(self, key)\n",
      " |      Delete item\n",
      " |  \n",
      " |  __finalize__(self, other, method=None, **kwargs)\n",
      " |      Propagate metadata from other to self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : the object from which to get the attributes that we are going\n",
      " |          to propagate\n",
      " |      method : optional, a passed method name ; possibly to take different\n",
      " |          types of propagation actions based on this\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |      After regular attribute access, try looking up the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __invert__(self)\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Iterate over infor axis\n",
      " |  \n",
      " |  __neg__(self)\n",
      " |  \n",
      " |  __nonzero__(self)\n",
      " |  \n",
      " |  __pos__(self)\n",
      " |  \n",
      " |  __round__(self, decimals=0)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      After regular attribute access, try setting the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  abs(self)\n",
      " |      Return a Series/DataFrame with absolute numeric value of each element.\n",
      " |      \n",
      " |      This function only applies to elements that are all numeric.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      abs\n",
      " |          Series/DataFrame containing the absolute value of each element.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For ``complex`` inputs, ``1.2 + 1j``, the absolute value is\n",
      " |      :math:`\\sqrt{ a^2 + b^2 }`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Absolute numeric values in a Series.\n",
      " |      \n",
      " |      >>> s = pd.Series([-1.10, 2, -3.33, 4])\n",
      " |      >>> s.abs()\n",
      " |      0    1.10\n",
      " |      1    2.00\n",
      " |      2    3.33\n",
      " |      3    4.00\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Absolute numeric values in a Series with complex numbers.\n",
      " |      \n",
      " |      >>> s = pd.Series([1.2 + 1j])\n",
      " |      >>> s.abs()\n",
      " |      0    1.56205\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Absolute numeric values in a Series with a Timedelta element.\n",
      " |      \n",
      " |      >>> s = pd.Series([pd.Timedelta('1 days')])\n",
      " |      >>> s.abs()\n",
      " |      0   1 days\n",
      " |      dtype: timedelta64[ns]\n",
      " |      \n",
      " |      Select rows with data closest to certain value using argsort (from\n",
      " |      `StackOverflow <https://stackoverflow.com/a/17758115>`__).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'a': [4, 5, 6, 7],\n",
      " |      ...     'b': [10, 20, 30, 40],\n",
      " |      ...     'c': [100, 50, -30, -50]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |           a    b    c\n",
      " |      0    4   10  100\n",
      " |      1    5   20   50\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |      >>> df.loc[(df.c - 43).abs().argsort()]\n",
      " |           a    b    c\n",
      " |      1    5   20   50\n",
      " |      0    4   10  100\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.absolute : calculate the absolute value element-wise.\n",
      " |  \n",
      " |  add_prefix(self, prefix)\n",
      " |      Prefix labels with string `prefix`.\n",
      " |      \n",
      " |      For Series, the row labels are prefixed.\n",
      " |      For DataFrame, the column labels are prefixed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      prefix : str\n",
      " |          The string to add before each label.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_suffix: Suffix row labels with string `suffix`.\n",
      " |      DataFrame.add_suffix: Suffix column labels with string `suffix`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.add_prefix('item_')\n",
      " |      item_0    1\n",
      " |      item_1    2\n",
      " |      item_2    3\n",
      " |      item_3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4],  'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |      \n",
      " |      >>> df.add_prefix('col_')\n",
      " |           col_A  col_B\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |  \n",
      " |  add_suffix(self, suffix)\n",
      " |      Suffix labels with string `suffix`.\n",
      " |      \n",
      " |      For Series, the row labels are suffixed.\n",
      " |      For DataFrame, the column labels are suffixed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      suffix : str\n",
      " |          The string to add after each label.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_prefix: Prefix row labels with string `prefix`.\n",
      " |      DataFrame.add_prefix: Prefix column labels with string `prefix`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.add_suffix('_item')\n",
      " |      0_item    1\n",
      " |      1_item    2\n",
      " |      2_item    3\n",
      " |      3_item    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4],  'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |      \n",
      " |      >>> df.add_suffix('_col')\n",
      " |           A_col  B_col\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |  \n",
      " |  as_blocks(self, copy=True)\n",
      " |      Convert the frame to a dict of dtype -> Constructor Types that each has\n",
      " |      a homogeneous dtype.\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |      \n",
      " |      NOTE: the dtypes of the blocks WILL BE PRESERVED HERE (unlike in\n",
      " |            as_matrix)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : boolean, default True\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values : a dict of dtype -> Constructor Types\n",
      " |  \n",
      " |  as_matrix(self, columns=None)\n",
      " |      Convert the frame to its Numpy-array representation.\n",
      " |      \n",
      " |      .. deprecated:: 0.23.0\n",
      " |          Use :meth:`DataFrame.values` instead.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      columns: list, optional, default:None\n",
      " |          If None, return all columns, otherwise, returns specified columns.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values : ndarray\n",
      " |          If the caller is heterogeneous and contains booleans or objects,\n",
      " |          the result will be of dtype=object. See Notes.\n",
      " |      \n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Return is NOT a Numpy-matrix, rather, a Numpy-array.\n",
      " |      \n",
      " |      The dtype will be a lower-common-denominator dtype (implicit\n",
      " |      upcasting); that is to say if the dtypes (even of numeric types)\n",
      " |      are mixed, the one that accommodates all will be chosen. Use this\n",
      " |      with care if you are not dealing with the blocks.\n",
      " |      \n",
      " |      e.g. If the dtypes are float16 and float32, dtype will be upcast to\n",
      " |      float32.  If dtypes are int32 and uint8, dtype will be upcase to\n",
      " |      int32. By numpy.find_common_type convention, mixing int64 and uint64\n",
      " |      will result in a flot64 dtype.\n",
      " |      \n",
      " |      This method is provided for backwards compatibility. Generally,\n",
      " |      it is recommended to use '.values'.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.values\n",
      " |  \n",
      " |  asfreq(self, freq, method=None, how=None, normalize=False, fill_value=None)\n",
      " |      Convert TimeSeries to specified frequency.\n",
      " |      \n",
      " |      Optionally provide filling method to pad/backfill missing values.\n",
      " |      \n",
      " |      Returns the original data conformed to a new index with the specified\n",
      " |      frequency. ``resample`` is more appropriate if an operation, such as\n",
      " |      summarization, is necessary to represent the data at the new frequency.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : DateOffset object, or string\n",
      " |      method : {'backfill'/'bfill', 'pad'/'ffill'}, default None\n",
      " |          Method to use for filling holes in reindexed Series (note this\n",
      " |          does not fill NaNs that already were present):\n",
      " |      \n",
      " |          * 'pad' / 'ffill': propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * 'backfill' / 'bfill': use NEXT valid observation to fill\n",
      " |      how : {'start', 'end'}, default end\n",
      " |          For PeriodIndex only, see PeriodIndex.asfreq\n",
      " |      normalize : bool, default False\n",
      " |          Whether to reset output index to midnight\n",
      " |      fill_value: scalar, optional\n",
      " |          Value to use for missing values, applied during upsampling (note\n",
      " |          this does not fill NaNs that already were present).\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : type of caller\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Start by creating a series with 4 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      " |      >>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)\n",
      " |      >>> df = pd.DataFrame({'s':series})\n",
      " |      >>> df\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    NaN\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``fill value``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', fill_value=9.0)\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    9.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    9.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    9.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``method``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', method='bfill')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    2.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    3.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To learn more about the frequency strings, please see `this link\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      " |  \n",
      " |  asof(self, where, subset=None)\n",
      " |      The last row without any NaN is taken (or the last row without\n",
      " |      NaN considering only the subset of columns in the case of a DataFrame)\n",
      " |      \n",
      " |      .. versionadded:: 0.19.0 For DataFrame\n",
      " |      \n",
      " |      If there is no good value, NaN is returned for a Series\n",
      " |      a Series of NaN values for a DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      where : date or array of dates\n",
      " |      subset : string or list of strings, default None\n",
      " |         if not None use these columns for NaN propagation\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Dates are assumed to be sorted\n",
      " |      Raises if this is not the case\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      where is scalar\n",
      " |      \n",
      " |        - value or NaN if input is Series\n",
      " |        - Series if input is DataFrame\n",
      " |      \n",
      " |      where is Index: same shape object as input\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      merge_asof\n",
      " |  \n",
      " |  astype(self, dtype, copy=True, errors='raise', **kwargs)\n",
      " |      Cast a pandas object to a specified dtype ``dtype``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : data type, or dict of column name -> data type\n",
      " |          Use a numpy.dtype or Python type to cast entire pandas object to\n",
      " |          the same type. Alternatively, use {col: dtype, ...}, where col is a\n",
      " |          column label and dtype is a numpy.dtype or Python type to cast one\n",
      " |          or more of the DataFrame's columns to column-specific types.\n",
      " |      copy : bool, default True.\n",
      " |          Return a copy when ``copy=True`` (be very careful setting\n",
      " |          ``copy=False`` as changes to values then may propagate to other\n",
      " |          pandas objects).\n",
      " |      errors : {'raise', 'ignore'}, default 'raise'.\n",
      " |          Control raising of exceptions on invalid data for provided dtype.\n",
      " |      \n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      raise_on_error : raise on invalid input\n",
      " |          .. deprecated:: 0.20.0\n",
      " |             Use ``errors`` instead\n",
      " |      kwargs : keyword arguments to pass on to the constructor\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      casted : type of caller\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series([1, 2], dtype='int32')\n",
      " |      >>> ser\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int32\n",
      " |      >>> ser.astype('int64')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Convert to categorical type:\n",
      " |      \n",
      " |      >>> ser.astype('category')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int64): [1, 2]\n",
      " |      \n",
      " |      Convert to ordered categorical type with custom ordering:\n",
      " |      \n",
      " |      >>> ser.astype('category', ordered=True, categories=[2, 1])\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int64): [2 < 1]\n",
      " |      \n",
      " |      Note that using ``copy=False`` and changing data on a new\n",
      " |      pandas object may propagate changes:\n",
      " |      \n",
      " |      >>> s1 = pd.Series([1,2])\n",
      " |      >>> s2 = s1.astype('int64', copy=False)\n",
      " |      >>> s2[0] = 10\n",
      " |      >>> s1  # note that s1[0] has changed too\n",
      " |      0    10\n",
      " |      1     2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.to_datetime : Convert argument to datetime.\n",
      " |      pandas.to_timedelta : Convert argument to timedelta.\n",
      " |      pandas.to_numeric : Convert argument to a numeric type.\n",
      " |      numpy.ndarray.astype : Cast a numpy array to a specified type.\n",
      " |  \n",
      " |  at_time(self, time, asof=False)\n",
      " |      Select values at particular time of day (e.g. 9:30AM).\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      time : datetime.time or string\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values_at_time : type of caller\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='12H')\n",
      " |      >>> ts = pd.DataFrame({'A': [1,2,3,4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 00:00:00  3\n",
      " |      2018-04-10 12:00:00  4\n",
      " |      \n",
      " |      >>> ts.at_time('12:00')\n",
      " |                           A\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 12:00:00  4\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      between_time : Select values between particular times of the day\n",
      " |      first : Select initial periods of time series based on a date offset\n",
      " |      last : Select final periods of time series based on a date offset\n",
      " |      DatetimeIndex.indexer_at_time : Get just the index locations for\n",
      " |          values at particular time of the day\n",
      " |  \n",
      " |  between_time(self, start_time, end_time, include_start=True, include_end=True)\n",
      " |      Select values between particular times of the day (e.g., 9:00-9:30 AM).\n",
      " |      \n",
      " |      By setting ``start_time`` to be later than ``end_time``,\n",
      " |      you can get the times that are *not* between the two times.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start_time : datetime.time or string\n",
      " |      end_time : datetime.time or string\n",
      " |      include_start : boolean, default True\n",
      " |      include_end : boolean, default True\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values_between_time : type of caller\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='1D20min')\n",
      " |      >>> ts = pd.DataFrame({'A': [1,2,3,4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      2018-04-12 01:00:00  4\n",
      " |      \n",
      " |      >>> ts.between_time('0:15', '0:45')\n",
      " |                           A\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      \n",
      " |      You get the times that are *not* between two times by setting\n",
      " |      ``start_time`` later than ``end_time``:\n",
      " |      \n",
      " |      >>> ts.between_time('0:45', '0:15')\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-12 01:00:00  4\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      at_time : Select values at a particular time of the day\n",
      " |      first : Select initial periods of time series based on a date offset\n",
      " |      last : Select final periods of time series based on a date offset\n",
      " |      DatetimeIndex.indexer_between_time : Get just the index locations for\n",
      " |          values between particular times of the day\n",
      " |  \n",
      " |  bfill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      " |      Synonym for :meth:`DataFrame.fillna(method='bfill') <DataFrame.fillna>`\n",
      " |  \n",
      " |  bool(self)\n",
      " |      Return the bool of a single element PandasObject.\n",
      " |      \n",
      " |      This must be a boolean scalar value, either True or False.  Raise a\n",
      " |      ValueError if the PandasObject does not have exactly 1 element, or that\n",
      " |      element is not boolean\n",
      " |  \n",
      " |  clip(self, lower=None, upper=None, axis=None, inplace=False, *args, **kwargs)\n",
      " |      Trim values at input threshold(s).\n",
      " |      \n",
      " |      Assigns values outside boundary to boundary values. Thresholds\n",
      " |      can be singular values or array like, and in the latter case\n",
      " |      the clipping is performed element-wise in the specified axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lower : float or array_like, default None\n",
      " |          Minimum threshold value. All values below this\n",
      " |          threshold will be set to it.\n",
      " |      upper : float or array_like, default None\n",
      " |          Maximum threshold value. All values above this\n",
      " |          threshold will be set to it.\n",
      " |      axis : int or string axis name, optional\n",
      " |          Align object with lower and upper along the given axis.\n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted\n",
      " |          for compatibility with numpy.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      clip_lower : Clip values below specified threshold(s).\n",
      " |      clip_upper : Clip values above specified threshold(s).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Same type as calling object with the values outside the\n",
      " |          clip boundaries replaced\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = {'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]}\n",
      " |      >>> df = pd.DataFrame(data)\n",
      " |      >>> df\n",
      " |         col_0  col_1\n",
      " |      0      9     -2\n",
      " |      1     -3     -7\n",
      " |      2      0      6\n",
      " |      3     -1      8\n",
      " |      4      5     -5\n",
      " |      \n",
      " |      Clips per column using lower and upper thresholds:\n",
      " |      \n",
      " |      >>> df.clip(-4, 6)\n",
      " |         col_0  col_1\n",
      " |      0      6     -2\n",
      " |      1     -3     -4\n",
      " |      2      0      6\n",
      " |      3     -1      6\n",
      " |      4      5     -4\n",
      " |      \n",
      " |      Clips using specific lower and upper thresholds per column element:\n",
      " |      \n",
      " |      >>> t = pd.Series([2, -4, -1, 6, 3])\n",
      " |      >>> t\n",
      " |      0    2\n",
      " |      1   -4\n",
      " |      2   -1\n",
      " |      3    6\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.clip(t, t + 4, axis=0)\n",
      " |         col_0  col_1\n",
      " |      0      6      2\n",
      " |      1     -3     -4\n",
      " |      2      0      3\n",
      " |      3      6      8\n",
      " |      4      5      3\n",
      " |  \n",
      " |  clip_lower(self, threshold, axis=None, inplace=False)\n",
      " |      Return copy of the input with values below a threshold truncated.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      threshold : numeric or array-like\n",
      " |          Minimum value allowed. All values below threshold will be set to\n",
      " |          this value.\n",
      " |      \n",
      " |          * float : every value is compared to `threshold`.\n",
      " |          * array-like : The shape of `threshold` should match the object\n",
      " |            it's compared to. When `self` is a Series, `threshold` should be\n",
      " |            the length. When `self` is a DataFrame, `threshold` should 2-D\n",
      " |            and the same shape as `self` for ``axis=None``, or 1-D and the\n",
      " |            same length as the axis being compared.\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Align `self` with `threshold` along the given axis.\n",
      " |      \n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.clip : Return copy of input with values below and above\n",
      " |          thresholds truncated.\n",
      " |      Series.clip_upper : Return copy of input with values above\n",
      " |          threshold truncated.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      clipped : same type as input\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Series single threshold clipping:\n",
      " |      \n",
      " |      >>> s = pd.Series([5, 6, 7, 8, 9])\n",
      " |      >>> s.clip_lower(8)\n",
      " |      0    8\n",
      " |      1    8\n",
      " |      2    8\n",
      " |      3    8\n",
      " |      4    9\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Series clipping element-wise using an array of thresholds. `threshold`\n",
      " |      should be the same length as the Series.\n",
      " |      \n",
      " |      >>> elemwise_thresholds = [4, 8, 7, 2, 5]\n",
      " |      >>> s.clip_lower(elemwise_thresholds)\n",
      " |      0    5\n",
      " |      1    8\n",
      " |      2    7\n",
      " |      3    8\n",
      " |      4    9\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      DataFrames can be compared to a scalar.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 3, 5], \"B\": [2, 4, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      2  5  6\n",
      " |      \n",
      " |      >>> df.clip_lower(3)\n",
      " |         A  B\n",
      " |      0  3  3\n",
      " |      1  3  4\n",
      " |      2  5  6\n",
      " |      \n",
      " |      Or to an array of values. By default, `threshold` should be the same\n",
      " |      shape as the DataFrame.\n",
      " |      \n",
      " |      >>> df.clip_lower(np.array([[3, 4], [2, 2], [6, 2]]))\n",
      " |         A  B\n",
      " |      0  3  4\n",
      " |      1  3  4\n",
      " |      2  6  6\n",
      " |      \n",
      " |      Control how `threshold` is broadcast with `axis`. In this case\n",
      " |      `threshold` should be the same length as the axis specified by\n",
      " |      `axis`.\n",
      " |      \n",
      " |      >>> df.clip_lower(np.array([3, 3, 5]), axis='index')\n",
      " |         A  B\n",
      " |      0  3  3\n",
      " |      1  3  4\n",
      " |      2  5  6\n",
      " |      \n",
      " |      >>> df.clip_lower(np.array([4, 5]), axis='columns')\n",
      " |         A  B\n",
      " |      0  4  5\n",
      " |      1  4  5\n",
      " |      2  5  6\n",
      " |  \n",
      " |  clip_upper(self, threshold, axis=None, inplace=False)\n",
      " |      Return copy of input with values above given value(s) truncated.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      threshold : float or array_like\n",
      " |      axis : int or string axis name, optional\n",
      " |          Align object with threshold along the given axis.\n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      clip\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      clipped : same type as input\n",
      " |  \n",
      " |  consolidate(self, inplace=False)\n",
      " |      Compute NDFrame with \"consolidated\" internals (data of each dtype\n",
      " |      grouped together in a single ndarray).\n",
      " |      \n",
      " |      .. deprecated:: 0.20.0\n",
      " |          Consolidate will be an internal implementation only.\n",
      " |  \n",
      " |  convert_objects(self, convert_dates=True, convert_numeric=False, convert_timedeltas=True, copy=True)\n",
      " |      Attempt to infer better dtype for object columns.\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      convert_dates : boolean, default True\n",
      " |          If True, convert to date where possible. If 'coerce', force\n",
      " |          conversion, with unconvertible values becoming NaT.\n",
      " |      convert_numeric : boolean, default False\n",
      " |          If True, attempt to coerce to numbers (including strings), with\n",
      " |          unconvertible values becoming NaN.\n",
      " |      convert_timedeltas : boolean, default True\n",
      " |          If True, convert to timedelta where possible. If 'coerce', force\n",
      " |          conversion, with unconvertible values becoming NaT.\n",
      " |      copy : boolean, default True\n",
      " |          If True, return a copy even if no copy is necessary (e.g. no\n",
      " |          conversion was done). Note: This is meant for internal use, and\n",
      " |          should not be confused with inplace.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.to_datetime : Convert argument to datetime.\n",
      " |      pandas.to_timedelta : Convert argument to timedelta.\n",
      " |      pandas.to_numeric : Return a fixed frequency timedelta index,\n",
      " |          with day as the default.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : same as input object\n",
      " |  \n",
      " |  copy(self, deep=True)\n",
      " |      Make a copy of this object's indices and data.\n",
      " |      \n",
      " |      When ``deep=True`` (default), a new object will be created with a\n",
      " |      copy of the calling object's data and indices. Modifications to\n",
      " |      the data or indices of the copy will not be reflected in the\n",
      " |      original object (see notes below).\n",
      " |      \n",
      " |      When ``deep=False``, a new object will be created without copying\n",
      " |      the calling object's data or index (only references to the data\n",
      " |      and index are copied). Any changes to the data of the original\n",
      " |      will be reflected in the shallow copy (and vice versa).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default True\n",
      " |          Make a deep copy, including a copy of the data and the indices.\n",
      " |          With ``deep=False`` neither the indices nor the data are copied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      copy : Series, DataFrame or Panel\n",
      " |          Object type matches caller.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      When ``deep=True``, data is copied but actual Python objects\n",
      " |      will not be copied recursively, only the reference to the object.\n",
      " |      This is in contrast to `copy.deepcopy` in the Standard Library,\n",
      " |      which recursively copies object data (see examples below).\n",
      " |      \n",
      " |      While ``Index`` objects are copied when ``deep=True``, the underlying\n",
      " |      numpy array is not copied for performance reasons. Since ``Index`` is\n",
      " |      immutable, the underlying data can be safely shared and a copy\n",
      " |      is not needed.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      >>> s\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s_copy = s.copy()\n",
      " |      >>> s_copy\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **Shallow copy versus default (deep) copy:**\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      >>> deep = s.copy()\n",
      " |      >>> shallow = s.copy(deep=False)\n",
      " |      \n",
      " |      Shallow copy shares data and index with original.\n",
      " |      \n",
      " |      >>> s is shallow\n",
      " |      False\n",
      " |      >>> s.values is shallow.values and s.index is shallow.index\n",
      " |      True\n",
      " |      \n",
      " |      Deep copy has own copy of data and index.\n",
      " |      \n",
      " |      >>> s is deep\n",
      " |      False\n",
      " |      >>> s.values is deep.values or s.index is deep.index\n",
      " |      False\n",
      " |      \n",
      " |      Updates to the data shared by shallow copy and original is reflected\n",
      " |      in both; deep copy remains unchanged.\n",
      " |      \n",
      " |      >>> s[0] = 3\n",
      " |      >>> shallow[1] = 4\n",
      " |      >>> s\n",
      " |      a    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> shallow\n",
      " |      a    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> deep\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Note that when copying an object containing Python objects, a deep copy\n",
      " |      will copy the data, but will not do so recursively. Updating a nested\n",
      " |      data object will be reflected in the deep copy.\n",
      " |      \n",
      " |      >>> s = pd.Series([[1, 2], [3, 4]])\n",
      " |      >>> deep = s.copy()\n",
      " |      >>> s[0][0] = 10\n",
      " |      >>> s\n",
      " |      0    [10, 2]\n",
      " |      1     [3, 4]\n",
      " |      dtype: object\n",
      " |      >>> deep\n",
      " |      0    [10, 2]\n",
      " |      1     [3, 4]\n",
      " |      dtype: object\n",
      " |  \n",
      " |  describe(self, percentiles=None, include=None, exclude=None)\n",
      " |      Generates descriptive statistics that summarize the central tendency,\n",
      " |      dispersion and shape of a dataset's distribution, excluding\n",
      " |      ``NaN`` values.\n",
      " |      \n",
      " |      Analyzes both numeric and object series, as well\n",
      " |      as ``DataFrame`` column sets of mixed data types. The output\n",
      " |      will vary depending on what is provided. Refer to the notes\n",
      " |      below for more detail.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles : list-like of numbers, optional\n",
      " |          The percentiles to include in the output. All should\n",
      " |          fall between 0 and 1. The default is\n",
      " |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      " |          75th percentiles.\n",
      " |      include : 'all', list-like of dtypes or None (default), optional\n",
      " |          A white list of data types to include in the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - 'all' : All columns of the input will be included in the output.\n",
      " |          - A list-like of dtypes : Limits the results to the\n",
      " |            provided data types.\n",
      " |            To limit the result to numeric types submit\n",
      " |            ``numpy.number``. To limit it instead to object columns submit\n",
      " |            the ``numpy.object`` data type. Strings\n",
      " |            can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            select pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will include all numeric columns.\n",
      " |      exclude : list-like of dtypes or None (default), optional,\n",
      " |          A black list of data types to omit from the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - A list-like of dtypes : Excludes the provided data types\n",
      " |            from the result. To exclude numeric types submit\n",
      " |            ``numpy.number``. To exclude object columns submit the data\n",
      " |            type ``numpy.object``. Strings can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            exclude pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will exclude nothing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      summary:  Series/DataFrame of summary statistics\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For numeric data, the result's index will include ``count``,\n",
      " |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      " |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      " |      upper percentile is ``75``. The ``50`` percentile is the\n",
      " |      same as the median.\n",
      " |      \n",
      " |      For object data (e.g. strings or timestamps), the result's index\n",
      " |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      " |      is the most common value. The ``freq`` is the most common value's\n",
      " |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      " |      \n",
      " |      If multiple object values have the highest count, then the\n",
      " |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |      \n",
      " |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      " |      return only an analysis of numeric columns. If the dataframe consists\n",
      " |      only of object and categorical data without any numeric columns, the\n",
      " |      default is to return an analysis of both the object and categorical\n",
      " |      columns. If ``include='all'`` is provided as an option, the result\n",
      " |      will include a union of attributes of each type.\n",
      " |      \n",
      " |      The `include` and `exclude` parameters can be used to limit\n",
      " |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      " |      The parameters are ignored when analyzing a ``Series``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Describing a numeric ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      \n",
      " |      Describing a categorical ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      " |      >>> s.describe()\n",
      " |      count     4\n",
      " |      unique    3\n",
      " |      top       a\n",
      " |      freq      2\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a timestamp ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\n",
      " |      ...   np.datetime64(\"2000-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\")\n",
      " |      ... ])\n",
      " |      >>> s.describe()\n",
      " |      count                       3\n",
      " |      unique                      2\n",
      " |      top       2010-01-01 00:00:00\n",
      " |      freq                        2\n",
      " |      first     2000-01-01 00:00:00\n",
      " |      last      2010-01-01 00:00:00\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a ``DataFrame``. By default only numeric fields\n",
      " |      are returned.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({ 'object': ['a', 'b', 'c'],\n",
      " |      ...                     'numeric': [1, 2, 3],\n",
      " |      ...                     'categorical': pd.Categorical(['d','e','f'])\n",
      " |      ...                   })\n",
      " |      >>> df.describe()\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      " |      \n",
      " |      >>> df.describe(include='all')\n",
      " |              categorical  numeric object\n",
      " |      count            3      3.0      3\n",
      " |      unique           3      NaN      3\n",
      " |      top              f      NaN      c\n",
      " |      freq             1      NaN      1\n",
      " |      mean           NaN      2.0    NaN\n",
      " |      std            NaN      1.0    NaN\n",
      " |      min            NaN      1.0    NaN\n",
      " |      25%            NaN      1.5    NaN\n",
      " |      50%            NaN      2.0    NaN\n",
      " |      75%            NaN      2.5    NaN\n",
      " |      max            NaN      3.0    NaN\n",
      " |      \n",
      " |      Describing a column from a ``DataFrame`` by accessing it as\n",
      " |      an attribute.\n",
      " |      \n",
      " |      >>> df.numeric.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      Name: numeric, dtype: float64\n",
      " |      \n",
      " |      Including only numeric columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.number])\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Including only string columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.object])\n",
      " |             object\n",
      " |      count       3\n",
      " |      unique      3\n",
      " |      top         c\n",
      " |      freq        1\n",
      " |      \n",
      " |      Including only categorical columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=['category'])\n",
      " |             categorical\n",
      " |      count            3\n",
      " |      unique           3\n",
      " |      top              f\n",
      " |      freq             1\n",
      " |      \n",
      " |      Excluding numeric columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.number])\n",
      " |             categorical object\n",
      " |      count            3      3\n",
      " |      unique           3      3\n",
      " |      top              f      c\n",
      " |      freq             1      1\n",
      " |      \n",
      " |      Excluding object columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.object])\n",
      " |              categorical  numeric\n",
      " |      count            3      3.0\n",
      " |      unique           3      NaN\n",
      " |      top              f      NaN\n",
      " |      freq             1      NaN\n",
      " |      mean           NaN      2.0\n",
      " |      std            NaN      1.0\n",
      " |      min            NaN      1.0\n",
      " |      25%            NaN      1.5\n",
      " |      50%            NaN      2.0\n",
      " |      75%            NaN      2.5\n",
      " |      max            NaN      3.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.count\n",
      " |      DataFrame.max\n",
      " |      DataFrame.min\n",
      " |      DataFrame.mean\n",
      " |      DataFrame.std\n",
      " |      DataFrame.select_dtypes\n",
      " |  \n",
      " |  equals(self, other)\n",
      " |      Determines if two NDFrame objects contain the same elements. NaNs in\n",
      " |      the same location are considered equal.\n",
      " |  \n",
      " |  ffill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      " |      Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`\n",
      " |  \n",
      " |  filter(self, items=None, like=None, regex=None, axis=None)\n",
      " |      Subset rows or columns of dataframe according to labels in\n",
      " |      the specified index.\n",
      " |      \n",
      " |      Note that this routine does not filter a dataframe on its\n",
      " |      contents. The filter is applied to the labels of the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      items : list-like\n",
      " |          List of info axis to restrict to (must not all be present)\n",
      " |      like : string\n",
      " |          Keep info axis where \"arg in col == True\"\n",
      " |      regex : string (regular expression)\n",
      " |          Keep info axis with re.search(regex, col) == True\n",
      " |      axis : int or string axis name\n",
      " |          The axis to filter on.  By default this is the info axis,\n",
      " |          'index' for Series, 'columns' for DataFrame\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as input object\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df\n",
      " |      one  two  three\n",
      " |      mouse     1    2      3\n",
      " |      rabbit    4    5      6\n",
      " |      \n",
      " |      >>> # select columns by name\n",
      " |      >>> df.filter(items=['one', 'three'])\n",
      " |      one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select columns by regular expression\n",
      " |      >>> df.filter(regex='e$', axis=1)\n",
      " |      one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select rows containing 'bbi'\n",
      " |      >>> df.filter(like='bbi', axis=0)\n",
      " |      one  two  three\n",
      " |      rabbit    4    5      6\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.loc\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The ``items``, ``like``, and ``regex`` parameters are\n",
      " |      enforced to be mutually exclusive.\n",
      " |      \n",
      " |      ``axis`` defaults to the info axis that is used when indexing\n",
      " |      with ``[]``.\n",
      " |  \n",
      " |  first(self, offset)\n",
      " |      Convenience method for subsetting initial periods of time series data\n",
      " |      based on a date offset.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : string, DateOffset, dateutil.relativedelta\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1,2,3,4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Get the rows for the first 3 days:\n",
      " |      \n",
      " |      >>> ts.first('3D')\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      \n",
      " |      Notice the data for 3 first calender days were returned, not the first\n",
      " |      3 days observed in the dataset, and therefore data for 2018-04-13 was\n",
      " |      not returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      subset : type of caller\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      last : Select final periods of time series based on a date offset\n",
      " |      at_time : Select values at a particular time of the day\n",
      " |      between_time : Select values between particular times of the day\n",
      " |  \n",
      " |  first_valid_index(self)\n",
      " |      Return index for first non-NA/null value.\n",
      " |      \n",
      " |      Notes\n",
      " |      --------\n",
      " |      If all elements are non-NA/null, returns None.\n",
      " |      Also returns None for empty NDFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      --------\n",
      " |      scalar : type of index\n",
      " |  \n",
      " |  get(self, key, default=None)\n",
      " |      Get item from object for given key (DataFrame column, Panel slice,\n",
      " |      etc.). Returns default value if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value : type of items contained in object\n",
      " |  \n",
      " |  get_dtype_counts(self)\n",
      " |      Return counts of unique dtypes in this object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dtype : Series\n",
      " |          Series with the count of columns with each dtype.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      dtypes : Return the dtypes in this object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = [['a', 1, 1.0], ['b', 2, 2.0], ['c', 3, 3.0]]\n",
      " |      >>> df = pd.DataFrame(a, columns=['str', 'int', 'float'])\n",
      " |      >>> df\n",
      " |        str  int  float\n",
      " |      0   a    1    1.0\n",
      " |      1   b    2    2.0\n",
      " |      2   c    3    3.0\n",
      " |      \n",
      " |      >>> df.get_dtype_counts()\n",
      " |      float64    1\n",
      " |      int64      1\n",
      " |      object     1\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  get_ftype_counts(self)\n",
      " |      Return counts of unique ftypes in this object.\n",
      " |      \n",
      " |      .. deprecated:: 0.23.0\n",
      " |      \n",
      " |      This is useful for SparseDataFrame or for DataFrames containing\n",
      " |      sparse arrays.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dtype : Series\n",
      " |          Series with the count of columns with each type and\n",
      " |          sparsity (dense/sparse)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ftypes : Return ftypes (indication of sparse/dense and dtype) in\n",
      " |          this object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = [['a', 1, 1.0], ['b', 2, 2.0], ['c', 3, 3.0]]\n",
      " |      >>> df = pd.DataFrame(a, columns=['str', 'int', 'float'])\n",
      " |      >>> df\n",
      " |        str  int  float\n",
      " |      0   a    1    1.0\n",
      " |      1   b    2    2.0\n",
      " |      2   c    3    3.0\n",
      " |      \n",
      " |      >>> df.get_ftype_counts()\n",
      " |      float64:dense    1\n",
      " |      int64:dense      1\n",
      " |      object:dense     1\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  get_values(self)\n",
      " |      Return an ndarray after converting sparse values to dense.\n",
      " |      \n",
      " |      This is the same as ``.values`` for non-sparse data. For sparse\n",
      " |      data contained in a `pandas.SparseArray`, the data are first\n",
      " |      converted to a dense representation.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          Numpy representation of DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      values : Numpy representation of DataFrame.\n",
      " |      pandas.SparseArray : Container for sparse data.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'a': [1, 2], 'b': [True, False],\n",
      " |      ...                    'c': [1.0, 2.0]})\n",
      " |      >>> df\n",
      " |         a      b    c\n",
      " |      0  1   True  1.0\n",
      " |      1  2  False  2.0\n",
      " |      \n",
      " |      >>> df.get_values()\n",
      " |      array([[1, True, 1.0], [2, False, 2.0]], dtype=object)\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"a\": pd.SparseArray([1, None, None]),\n",
      " |      ...                    \"c\": [1.0, 2.0, 3.0]})\n",
      " |      >>> df\n",
      " |           a    c\n",
      " |      0  1.0  1.0\n",
      " |      1  NaN  2.0\n",
      " |      2  NaN  3.0\n",
      " |      \n",
      " |      >>> df.get_values()\n",
      " |      array([[ 1.,  1.],\n",
      " |             [nan,  2.],\n",
      " |             [nan,  3.]])\n",
      " |  \n",
      " |  groupby(self, by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, observed=False, **kwargs)\n",
      " |      Group series using mapper (dict or key function, apply given function\n",
      " |      to group, return result as series) or by a series of columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : mapping, function, label, or list of labels\n",
      " |          Used to determine the groups for the groupby.\n",
      " |          If ``by`` is a function, it's called on each value of the object's\n",
      " |          index. If a dict or Series is passed, the Series or dict VALUES\n",
      " |          will be used to determine the groups (the Series' values are first\n",
      " |          aligned; see ``.align()`` method). If an ndarray is passed, the\n",
      " |          values are used as-is determine the groups. A label or list of\n",
      " |          labels may be passed to group by the columns in ``self``. Notice\n",
      " |          that a tuple is interpreted a (single) key.\n",
      " |      axis : int, default 0\n",
      " |      level : int, level name, or sequence of such, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), group by a particular\n",
      " |          level or levels\n",
      " |      as_index : boolean, default True\n",
      " |          For aggregated output, return object with group labels as the\n",
      " |          index. Only relevant for DataFrame input. as_index=False is\n",
      " |          effectively \"SQL-style\" grouped output\n",
      " |      sort : boolean, default True\n",
      " |          Sort group keys. Get better performance by turning this off.\n",
      " |          Note this does not influence the order of observations within each\n",
      " |          group.  groupby preserves the order of rows within each group.\n",
      " |      group_keys : boolean, default True\n",
      " |          When calling apply, add group keys to index to identify pieces\n",
      " |      squeeze : boolean, default False\n",
      " |          reduce the dimensionality of the return type if possible,\n",
      " |          otherwise return a consistent type\n",
      " |      observed : boolean, default False\n",
      " |          This only applies if any of the groupers are Categoricals\n",
      " |          If True: only show observed values for categorical groupers.\n",
      " |          If False: show all values for categorical groupers.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      GroupBy object\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      DataFrame results\n",
      " |      \n",
      " |      >>> data.groupby(func, axis=0).mean()\n",
      " |      >>> data.groupby(['col1', 'col2'])['col3'].mean()\n",
      " |      \n",
      " |      DataFrame with hierarchical index\n",
      " |      \n",
      " |      >>> data.groupby(['col1', 'col2']).mean()\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/groupby.html>`_ for more.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      resample : Convenience method for frequency conversion and resampling\n",
      " |          of time series.\n",
      " |  \n",
      " |  head(self, n=5)\n",
      " |      Return the first `n` rows.\n",
      " |      \n",
      " |      This function returns the first `n` rows for the object based\n",
      " |      on position. It is useful for quickly testing if your object\n",
      " |      has the right type of data in it.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      obj_head : type of caller\n",
      " |          The first `n` rows of the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.tail: Returns the last `n` rows.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal':['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |      \n",
      " |      Viewing the first 5 lines\n",
      " |      \n",
      " |      >>> df.head()\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      \n",
      " |      Viewing the first `n` lines (three in this case)\n",
      " |      \n",
      " |      >>> df.head(3)\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |  \n",
      " |  infer_objects(self)\n",
      " |      Attempt to infer better dtypes for object columns.\n",
      " |      \n",
      " |      Attempts soft conversion of object-dtyped\n",
      " |      columns, leaving non-object and unconvertible\n",
      " |      columns unchanged. The inference rules are the\n",
      " |      same as during normal Series/DataFrame construction.\n",
      " |      \n",
      " |      .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.to_datetime : Convert argument to datetime.\n",
      " |      pandas.to_timedelta : Convert argument to timedelta.\n",
      " |      pandas.to_numeric : Convert argument to numeric typeR\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : same type as input object\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [\"a\", 1, 2, 3]})\n",
      " |      >>> df = df.iloc[1:]\n",
      " |      >>> df\n",
      " |         A\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |      \n",
      " |      >>> df.dtypes\n",
      " |      A    object\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> df.infer_objects().dtypes\n",
      " |      A    int64\n",
      " |      dtype: object\n",
      " |  \n",
      " |  interpolate(self, method='linear', axis=0, limit=None, inplace=False, limit_direction='forward', limit_area=None, downcast=None, **kwargs)\n",
      " |      Interpolate values according to different methods.\n",
      " |      \n",
      " |      Please note that only ``method='linear'`` is supported for\n",
      " |      DataFrames/Series with a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'linear', 'time', 'index', 'values', 'nearest', 'zero',\n",
      " |                'slinear', 'quadratic', 'cubic', 'barycentric', 'krogh',\n",
      " |                'polynomial', 'spline', 'piecewise_polynomial',\n",
      " |                'from_derivatives', 'pchip', 'akima'}\n",
      " |      \n",
      " |          * 'linear': ignore the index and treat the values as equally\n",
      " |            spaced. This is the only method supported on MultiIndexes.\n",
      " |            default\n",
      " |          * 'time': interpolation works on daily and higher resolution\n",
      " |            data to interpolate given length of interval\n",
      " |          * 'index', 'values': use the actual numerical values of the index\n",
      " |          * 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n",
      " |            'barycentric', 'polynomial' is passed to\n",
      " |            ``scipy.interpolate.interp1d``. Both 'polynomial' and 'spline'\n",
      " |            require that you also specify an `order` (int),\n",
      " |            e.g. df.interpolate(method='polynomial', order=4).\n",
      " |            These use the actual numerical values of the index.\n",
      " |          * 'krogh', 'piecewise_polynomial', 'spline', 'pchip' and 'akima'\n",
      " |            are all wrappers around the scipy interpolation methods of\n",
      " |            similar names. These use the actual numerical values of the\n",
      " |            index. For more information on their behavior, see the\n",
      " |            `scipy documentation\n",
      " |            <http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation>`__\n",
      " |            and `tutorial documentation\n",
      " |            <http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html>`__\n",
      " |          * 'from_derivatives' refers to BPoly.from_derivatives which\n",
      " |            replaces 'piecewise_polynomial' interpolation method in\n",
      " |            scipy 0.18\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |      \n",
      " |             Added support for the 'akima' method\n",
      " |             Added interpolate method 'from_derivatives' which replaces\n",
      " |             'piecewise_polynomial' in scipy 0.18; backwards-compatible with\n",
      " |             scipy < 0.18\n",
      " |      \n",
      " |      axis : {0, 1}, default 0\n",
      " |          * 0: fill column-by-column\n",
      " |          * 1: fill row-by-row\n",
      " |      limit : int, default None.\n",
      " |          Maximum number of consecutive NaNs to fill. Must be greater than 0.\n",
      " |      limit_direction : {'forward', 'backward', 'both'}, default 'forward'\n",
      " |      limit_area : {'inside', 'outside'}, default None\n",
      " |          * None: (default) no fill restriction\n",
      " |          * 'inside' Only fill NaNs surrounded by valid values (interpolate).\n",
      " |          * 'outside' Only fill NaNs outside valid values (extrapolate).\n",
      " |      \n",
      " |          If limit is specified, consecutive NaNs will be filled in this\n",
      " |          direction.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      inplace : bool, default False\n",
      " |          Update the NDFrame in place if possible.\n",
      " |      downcast : optional, 'infer' or None, defaults to None\n",
      " |          Downcast dtypes if possible.\n",
      " |      kwargs : keyword arguments to pass on to the interpolating function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame of same shape interpolated at the NaNs\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex, replace, fillna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Filling in NaNs\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 1, np.nan, 3])\n",
      " |      >>> s.interpolate()\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  keys(self)\n",
      " |      Get the 'info axis' (see Indexing for more)\n",
      " |      \n",
      " |      This is index for Series, columns for DataFrame and major_axis for\n",
      " |      Panel.\n",
      " |  \n",
      " |  last(self, offset)\n",
      " |      Convenience method for subsetting final periods of time series data\n",
      " |      based on a date offset.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : string, DateOffset, dateutil.relativedelta\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1,2,3,4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Get the rows for the last 3 days:\n",
      " |      \n",
      " |      >>> ts.last('3D')\n",
      " |                  A\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Notice the data for 3 last calender days were returned, not the last\n",
      " |      3 observed days in the dataset, and therefore data for 2018-04-11 was\n",
      " |      not returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      subset : type of caller\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      first : Select initial periods of time series based on a date offset\n",
      " |      at_time : Select values at a particular time of the day\n",
      " |      between_time : Select values between particular times of the day\n",
      " |  \n",
      " |  last_valid_index(self)\n",
      " |      Return index for last non-NA/null value.\n",
      " |      \n",
      " |      Notes\n",
      " |      --------\n",
      " |      If all elements are non-NA/null, returns None.\n",
      " |      Also returns None for empty NDFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      --------\n",
      " |      scalar : type of index\n",
      " |  \n",
      " |  mask(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=False, raise_on_error=None)\n",
      " |      Return an object of same shape as self and whose corresponding\n",
      " |      entries are from self where `cond` is False and otherwise are from\n",
      " |      `other`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : boolean NDFrame, array-like, or callable\n",
      " |          Where `cond` is False, keep the original value. Where\n",
      " |          True, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the NDFrame and\n",
      " |          should return boolean NDFrame or array. The callable must\n",
      " |          not change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as cond.\n",
      " |      \n",
      " |      other : scalar, NDFrame, or callable\n",
      " |          Entries where `cond` is True are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the NDFrame and\n",
      " |          should return scalar or NDFrame. The callable must not\n",
      " |          change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as other.\n",
      " |      \n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data\n",
      " |      axis : alignment axis if needed, default None\n",
      " |      level : alignment level if needed, default None\n",
      " |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object\n",
      " |      \n",
      " |          Note that currently this parameter won't affect\n",
      " |          the results and will always coerce to a suitable dtype.\n",
      " |      \n",
      " |      try_cast : boolean, default False\n",
      " |          try to cast the result back to the input type (if possible),\n",
      " |      raise_on_error : boolean, default True\n",
      " |          Whether to raise on invalid data types (e.g. trying to where on\n",
      " |          strings)\n",
      " |      \n",
      " |          .. deprecated:: 0.21.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      wh : same type as caller\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The mask method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``False`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``mask`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      \n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      \n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10.0\n",
      " |      1    10.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.where`\n",
      " |  \n",
      " |  pct_change(self, periods=1, fill_method='pad', limit=None, freq=None, **kwargs)\n",
      " |      Percentage change between the current and a prior element.\n",
      " |      \n",
      " |      Computes the percentage change from the immediately previous row by\n",
      " |      default. This is useful in comparing the percentage of change in a time\n",
      " |      series of elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming percent change.\n",
      " |      fill_method : str, default 'pad'\n",
      " |          How to handle NAs before computing percent changes.\n",
      " |      limit : int, default None\n",
      " |          The number of consecutive NAs to fill before stopping.\n",
      " |      freq : DateOffset, timedelta, or offset alias string, optional\n",
      " |          Increment to use from time series API (e.g. 'M' or BDay()).\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments are passed into\n",
      " |          `DataFrame.shift` or `Series.shift`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      chg : Series or DataFrame\n",
      " |          The same type as the calling object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.diff : Compute the difference of two elements in a Series.\n",
      " |      DataFrame.diff : Compute the difference of two elements in a DataFrame.\n",
      " |      Series.shift : Shift the index by some number of periods.\n",
      " |      DataFrame.shift : Shift the index by some number of periods.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([90, 91, 85])\n",
      " |      >>> s\n",
      " |      0    90\n",
      " |      1    91\n",
      " |      2    85\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.pct_change()\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2   -0.065934\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.pct_change(periods=2)\n",
      " |      0         NaN\n",
      " |      1         NaN\n",
      " |      2   -0.055556\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See the percentage change in a Series where filling NAs with last\n",
      " |      valid observation forward to next valid.\n",
      " |      \n",
      " |      >>> s = pd.Series([90, 91, None, 85])\n",
      " |      >>> s\n",
      " |      0    90.0\n",
      " |      1    91.0\n",
      " |      2     NaN\n",
      " |      3    85.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.pct_change(fill_method='ffill')\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2    0.000000\n",
      " |      3   -0.065934\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      Percentage change in French franc, Deutsche Mark, and Italian lira from\n",
      " |      1980-01-01 to 1980-03-01.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'FR': [4.0405, 4.0963, 4.3149],\n",
      " |      ...     'GR': [1.7246, 1.7482, 1.8519],\n",
      " |      ...     'IT': [804.74, 810.01, 860.13]},\n",
      " |      ...     index=['1980-01-01', '1980-02-01', '1980-03-01'])\n",
      " |      >>> df\n",
      " |                      FR      GR      IT\n",
      " |      1980-01-01  4.0405  1.7246  804.74\n",
      " |      1980-02-01  4.0963  1.7482  810.01\n",
      " |      1980-03-01  4.3149  1.8519  860.13\n",
      " |      \n",
      " |      >>> df.pct_change()\n",
      " |                        FR        GR        IT\n",
      " |      1980-01-01       NaN       NaN       NaN\n",
      " |      1980-02-01  0.013810  0.013684  0.006549\n",
      " |      1980-03-01  0.053365  0.059318  0.061876\n",
      " |      \n",
      " |      Percentage of change in GOOG and APPL stock volume. Shows computing\n",
      " |      the percentage change between columns.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     '2016': [1769950, 30586265],\n",
      " |      ...     '2015': [1500923, 40912316],\n",
      " |      ...     '2014': [1371819, 41403351]},\n",
      " |      ...     index=['GOOG', 'APPL'])\n",
      " |      >>> df\n",
      " |                2016      2015      2014\n",
      " |      GOOG   1769950   1500923   1371819\n",
      " |      APPL  30586265  40912316  41403351\n",
      " |      \n",
      " |      >>> df.pct_change(axis='columns')\n",
      " |            2016      2015      2014\n",
      " |      GOOG   NaN -0.151997 -0.086016\n",
      " |      APPL   NaN  0.337604  0.012002\n",
      " |  \n",
      " |  pipe(self, func, *args, **kwargs)\n",
      " |      Apply func(self, \\*args, \\*\\*kwargs)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          function to apply to the NDFrame.\n",
      " |          ``args``, and ``kwargs`` are passed into ``func``.\n",
      " |          Alternatively a ``(callable, data_keyword)`` tuple where\n",
      " |          ``data_keyword`` is a string indicating the keyword of\n",
      " |          ``callable`` that expects the NDFrame.\n",
      " |      args : iterable, optional\n",
      " |          positional arguments passed into ``func``.\n",
      " |      kwargs : mapping, optional\n",
      " |          a dictionary of keyword arguments passed into ``func``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object : the return type of ``func``.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      Use ``.pipe`` when chaining together functions that expect\n",
      " |      Series, DataFrames or GroupBy objects. Instead of writing\n",
      " |      \n",
      " |      >>> f(g(h(df), arg1=a), arg2=b, arg3=c)\n",
      " |      \n",
      " |      You can write\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe(f, arg2=b, arg3=c)\n",
      " |      ... )\n",
      " |      \n",
      " |      If you have a function that takes the data as (say) the second\n",
      " |      argument, pass a tuple indicating which keyword expects the\n",
      " |      data. For example, suppose ``f`` takes its data as ``arg2``:\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe((f, 'arg2'), arg1=a, arg3=c)\n",
      " |      ...  )\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.apply\n",
      " |      pandas.DataFrame.applymap\n",
      " |      pandas.Series.map\n",
      " |  \n",
      " |  pop(self, item)\n",
      " |      Return item and drop from frame. Raise KeyError if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      item : str\n",
      " |          Column label to be popped\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      popped : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird',    389.0),\n",
      " |      ...                    ('parrot', 'bird',     24.0),\n",
      " |      ...                    ('lion',   'mammal',   80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                   columns=('name', 'class', 'max_speed'))\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  parrot    bird       24.0\n",
      " |      2    lion  mammal       80.5\n",
      " |      3  monkey  mammal        NaN\n",
      " |      \n",
      " |      >>> df.pop('class')\n",
      " |      0      bird\n",
      " |      1      bird\n",
      " |      2    mammal\n",
      " |      3    mammal\n",
      " |      Name: class, dtype: object\n",
      " |      \n",
      " |      >>> df\n",
      " |           name  max_speed\n",
      " |      0  falcon      389.0\n",
      " |      1  parrot       24.0\n",
      " |      2    lion       80.5\n",
      " |      3  monkey        NaN\n",
      " |  \n",
      " |  rank(self, axis=0, method='average', numeric_only=None, na_option='keep', ascending=True, pct=False)\n",
      " |      Compute numerical data ranks (1 through n) along axis. Equal values are\n",
      " |      assigned a rank that is the average of the ranks of those values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          index to direct ranking\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}\n",
      " |          * average: average rank of group\n",
      " |          * min: lowest rank in group\n",
      " |          * max: highest rank in group\n",
      " |          * first: ranks assigned in order they appear in the array\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. Valid only for DataFrame or\n",
      " |          Panel objects\n",
      " |      na_option : {'keep', 'top', 'bottom'}\n",
      " |          * keep: leave NA values where they are\n",
      " |          * top: smallest rank if ascending\n",
      " |          * bottom: smallest rank if descending\n",
      " |      ascending : boolean, default True\n",
      " |          False for ranks by high (1) to low (N)\n",
      " |      pct : boolean, default False\n",
      " |          Computes percentage rank of data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ranks : same type as caller\n",
      " |  \n",
      " |  reindex_like(self, other, method=None, copy=True, limit=None, tolerance=None)\n",
      " |      Return an object with matching indices to myself.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Object\n",
      " |      method : string or None\n",
      " |      copy : boolean, default True\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive labels to fill for inexact matches.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between labels of the other object and this\n",
      " |          object for inexact matches. Can be list-like.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0 (list-like tolerance)\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Like calling s.reindex(index=other.index, columns=other.columns,\n",
      " |                             method=...)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reindexed : same as input\n",
      " |  \n",
      " |  rename_axis(self, mapper, axis=0, copy=True, inplace=False)\n",
      " |      Alter the name of the index or columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : scalar, list-like, optional\n",
      " |          Value to set as the axis name attribute.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis.\n",
      " |      copy : boolean, default True\n",
      " |          Also copy underlying data.\n",
      " |      inplace : boolean, default False\n",
      " |          Modifies the object directly, instead of creating a new Series\n",
      " |          or DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : Series, DataFrame, or None\n",
      " |          The same type as the caller or None if `inplace` is True.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Prior to version 0.21.0, ``rename_axis`` could also be used to change\n",
      " |      the axis *labels* by passing a mapping or scalar. This behavior is\n",
      " |      deprecated and will be removed in a future version. Use ``rename``\n",
      " |      instead.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.rename : Alter Series index labels or name\n",
      " |      pandas.DataFrame.rename : Alter DataFrame index labels or name\n",
      " |      pandas.Index.rename : Set new names on index\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.rename_axis(\"foo\")\n",
      " |      foo\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      >>> df.rename_axis(\"foo\")\n",
      " |           A  B\n",
      " |      foo\n",
      " |      0    1  4\n",
      " |      1    2  5\n",
      " |      2    3  6\n",
      " |      \n",
      " |      >>> df.rename_axis(\"bar\", axis=\"columns\")\n",
      " |      bar  A  B\n",
      " |      0    1  4\n",
      " |      1    2  5\n",
      " |      2    3  6\n",
      " |  \n",
      " |  resample(self, rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention='start', kind=None, loffset=None, limit=None, base=0, on=None, level=None)\n",
      " |      Convenience method for frequency conversion and resampling of time\n",
      " |      series.  Object must have a datetime-like index (DatetimeIndex,\n",
      " |      PeriodIndex, or TimedeltaIndex), or pass datetime-like values\n",
      " |      to the on or level keyword.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rule : string\n",
      " |          the offset string or object representing target conversion\n",
      " |      axis : int, optional, default 0\n",
      " |      closed : {'right', 'left'}\n",
      " |          Which side of bin interval is closed. The default is 'left'\n",
      " |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      " |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      " |      label : {'right', 'left'}\n",
      " |          Which bin edge label to label bucket with. The default is 'left'\n",
      " |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      " |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      " |      convention : {'start', 'end', 's', 'e'}\n",
      " |          For PeriodIndex only, controls whether to use the start or end of\n",
      " |          `rule`\n",
      " |      kind: {'timestamp', 'period'}, optional\n",
      " |          Pass 'timestamp' to convert the resulting index to a\n",
      " |          ``DateTimeIndex`` or 'period' to convert it to a ``PeriodIndex``.\n",
      " |          By default the input representation is retained.\n",
      " |      loffset : timedelta\n",
      " |          Adjust the resampled time labels\n",
      " |      base : int, default 0\n",
      " |          For frequencies that evenly subdivide 1 day, the \"origin\" of the\n",
      " |          aggregated intervals. For example, for '5min' frequency, base could\n",
      " |          range from 0 through 4. Defaults to 0\n",
      " |      on : string, optional\n",
      " |          For a DataFrame, column to use instead of index for resampling.\n",
      " |          Column must be datetime-like.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      level : string or int, optional\n",
      " |          For a MultiIndex, level (name or number) to use for\n",
      " |          resampling.  Level must be datetime-like.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Resampler object\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#resampling>`_\n",
      " |      for more.\n",
      " |      \n",
      " |      To learn more about the offset strings, please see `this link\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Start by creating a series with 9 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      " |      >>> series = pd.Series(range(9), index=index)\n",
      " |      >>> series\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      2000-01-01 00:03:00    3\n",
      " |      2000-01-01 00:04:00    4\n",
      " |      2000-01-01 00:05:00    5\n",
      " |      2000-01-01 00:06:00    6\n",
      " |      2000-01-01 00:07:00    7\n",
      " |      2000-01-01 00:08:00    8\n",
      " |      Freq: T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins and sum the values\n",
      " |      of the timestamps falling into a bin.\n",
      " |      \n",
      " |      >>> series.resample('3T').sum()\n",
      " |      2000-01-01 00:00:00     3\n",
      " |      2000-01-01 00:03:00    12\n",
      " |      2000-01-01 00:06:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but label each\n",
      " |      bin using the right edge instead of the left. Please note that the\n",
      " |      value in the bucket used as the label is not included in the bucket,\n",
      " |      which it labels. For example, in the original series the\n",
      " |      bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed\n",
      " |      value in the resampled bucket with the label ``2000-01-01 00:03:00``\n",
      " |      does not include 3 (if it did, the summed value would be 6, not 3).\n",
      " |      To include this value close the right side of the bin interval as\n",
      " |      illustrated in the example below this one.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right').sum()\n",
      " |      2000-01-01 00:03:00     3\n",
      " |      2000-01-01 00:06:00    12\n",
      " |      2000-01-01 00:09:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but close the right\n",
      " |      side of the bin interval.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right', closed='right').sum()\n",
      " |      2000-01-01 00:00:00     0\n",
      " |      2000-01-01 00:03:00     6\n",
      " |      2000-01-01 00:06:00    15\n",
      " |      2000-01-01 00:09:00    15\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> series.resample('30S').asfreq()[0:5] #select first 5 rows\n",
      " |      2000-01-01 00:00:00   0.0\n",
      " |      2000-01-01 00:00:30   NaN\n",
      " |      2000-01-01 00:01:00   1.0\n",
      " |      2000-01-01 00:01:30   NaN\n",
      " |      2000-01-01 00:02:00   2.0\n",
      " |      Freq: 30S, dtype: float64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the ``NaN``\n",
      " |      values using the ``pad`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').pad()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the\n",
      " |      ``NaN`` values using the ``bfill`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').bfill()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    1\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    2\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Pass a custom function via ``apply``\n",
      " |      \n",
      " |      >>> def custom_resampler(array_like):\n",
      " |      ...     return np.sum(array_like)+5\n",
      " |      \n",
      " |      >>> series.resample('3T').apply(custom_resampler)\n",
      " |      2000-01-01 00:00:00     8\n",
      " |      2000-01-01 00:03:00    17\n",
      " |      2000-01-01 00:06:00    26\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      For a Series with a PeriodIndex, the keyword `convention` can be\n",
      " |      used to control whether to use the start or end of `rule`.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2], index=pd.period_range('2012-01-01',\n",
      " |                                                      freq='A',\n",
      " |                                                      periods=2))\n",
      " |      >>> s\n",
      " |      2012    1\n",
      " |      2013    2\n",
      " |      Freq: A-DEC, dtype: int64\n",
      " |      \n",
      " |      Resample by month using 'start' `convention`. Values are assigned to\n",
      " |      the first month of the period.\n",
      " |      \n",
      " |      >>> s.resample('M', convention='start').asfreq().head()\n",
      " |      2012-01    1.0\n",
      " |      2012-02    NaN\n",
      " |      2012-03    NaN\n",
      " |      2012-04    NaN\n",
      " |      2012-05    NaN\n",
      " |      Freq: M, dtype: float64\n",
      " |      \n",
      " |      Resample by month using 'end' `convention`. Values are assigned to\n",
      " |      the last month of the period.\n",
      " |      \n",
      " |      >>> s.resample('M', convention='end').asfreq()\n",
      " |      2012-12    1.0\n",
      " |      2013-01    NaN\n",
      " |      2013-02    NaN\n",
      " |      2013-03    NaN\n",
      " |      2013-04    NaN\n",
      " |      2013-05    NaN\n",
      " |      2013-06    NaN\n",
      " |      2013-07    NaN\n",
      " |      2013-08    NaN\n",
      " |      2013-09    NaN\n",
      " |      2013-10    NaN\n",
      " |      2013-11    NaN\n",
      " |      2013-12    2.0\n",
      " |      Freq: M, dtype: float64\n",
      " |      \n",
      " |      For DataFrame objects, the keyword ``on`` can be used to specify the\n",
      " |      column instead of the index for resampling.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(data=9*[range(4)], columns=['a', 'b', 'c', 'd'])\n",
      " |      >>> df['time'] = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      " |      >>> df.resample('3T', on='time').sum()\n",
      " |                           a  b  c  d\n",
      " |      time\n",
      " |      2000-01-01 00:00:00  0  3  6  9\n",
      " |      2000-01-01 00:03:00  0  3  6  9\n",
      " |      2000-01-01 00:06:00  0  3  6  9\n",
      " |      \n",
      " |      For a DataFrame with MultiIndex, the keyword ``level`` can be used to\n",
      " |      specify on level the resampling needs to take place.\n",
      " |      \n",
      " |      >>> time = pd.date_range('1/1/2000', periods=5, freq='T')\n",
      " |      >>> df2 = pd.DataFrame(data=10*[range(4)],\n",
      " |                             columns=['a', 'b', 'c', 'd'],\n",
      " |                             index=pd.MultiIndex.from_product([time, [1, 2]])\n",
      " |                             )\n",
      " |      >>> df2.resample('3T', level=0).sum()\n",
      " |                           a  b   c   d\n",
      " |      2000-01-01 00:00:00  0  6  12  18\n",
      " |      2000-01-01 00:03:00  0  4   8  12\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      groupby : Group by mapping, function, label, or list of labels.\n",
      " |  \n",
      " |  sample(self, n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)\n",
      " |      Return a random sample of items from an axis of object.\n",
      " |      \n",
      " |      You can use `random_state` for reproducibility.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, optional\n",
      " |          Number of items from axis to return. Cannot be used with `frac`.\n",
      " |          Default = 1 if `frac` = None.\n",
      " |      frac : float, optional\n",
      " |          Fraction of axis items to return. Cannot be used with `n`.\n",
      " |      replace : boolean, optional\n",
      " |          Sample with or without replacement. Default = False.\n",
      " |      weights : str or ndarray-like, optional\n",
      " |          Default 'None' results in equal probability weighting.\n",
      " |          If passed a Series, will align with target object on index. Index\n",
      " |          values in weights not found in sampled object will be ignored and\n",
      " |          index values in sampled object not in weights will be assigned\n",
      " |          weights of zero.\n",
      " |          If called on a DataFrame, will accept the name of a column\n",
      " |          when axis = 0.\n",
      " |          Unless weights are a Series, weights must be same length as axis\n",
      " |          being sampled.\n",
      " |          If weights do not sum to 1, they will be normalized to sum to 1.\n",
      " |          Missing values in the weights column will be treated as zero.\n",
      " |          inf and -inf values not allowed.\n",
      " |      random_state : int or numpy.random.RandomState, optional\n",
      " |          Seed for the random number generator (if int), or numpy RandomState\n",
      " |          object.\n",
      " |      axis : int or string, optional\n",
      " |          Axis to sample. Accepts axis number or name. Default is stat axis\n",
      " |          for given data type (0 for Series and DataFrames, 1 for Panels).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A new object of same type as caller.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Generate an example ``Series`` and ``DataFrame``:\n",
      " |      \n",
      " |      >>> s = pd.Series(np.random.randn(50))\n",
      " |      >>> s.head()\n",
      " |      0   -0.038497\n",
      " |      1    1.820773\n",
      " |      2   -0.972766\n",
      " |      3   -1.598270\n",
      " |      4   -1.095526\n",
      " |      dtype: float64\n",
      " |      >>> df = pd.DataFrame(np.random.randn(50, 4), columns=list('ABCD'))\n",
      " |      >>> df.head()\n",
      " |                A         B         C         D\n",
      " |      0  0.016443 -2.318952 -0.566372 -1.028078\n",
      " |      1 -1.051921  0.438836  0.658280 -0.175797\n",
      " |      2 -1.243569 -0.364626 -0.215065  0.057736\n",
      " |      3  1.768216  0.404512 -0.385604 -1.457834\n",
      " |      4  1.072446 -1.137172  0.314194 -0.046661\n",
      " |      \n",
      " |      Next extract a random sample from both of these objects...\n",
      " |      \n",
      " |      3 random elements from the ``Series``:\n",
      " |      \n",
      " |      >>> s.sample(n=3)\n",
      " |      27   -0.994689\n",
      " |      55   -1.049016\n",
      " |      67   -0.224565\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      And a random 10% of the ``DataFrame`` with replacement:\n",
      " |      \n",
      " |      >>> df.sample(frac=0.1, replace=True)\n",
      " |                 A         B         C         D\n",
      " |      35  1.981780  0.142106  1.817165 -0.290805\n",
      " |      49 -1.336199 -0.448634 -0.789640  0.217116\n",
      " |      40  0.823173 -0.078816  1.009536  1.015108\n",
      " |      15  1.421154 -0.055301 -1.922594 -0.019696\n",
      " |      6  -0.148339  0.832938  1.787600 -1.383767\n",
      " |      \n",
      " |      You can use `random state` for reproducibility:\n",
      " |      \n",
      " |      >>> df.sample(random_state=1)\n",
      " |      A         B         C         D\n",
      " |      37 -2.027662  0.103611  0.237496 -0.165867\n",
      " |      43 -0.259323 -0.583426  1.516140 -0.479118\n",
      " |      12 -1.686325 -0.579510  0.985195 -0.460286\n",
      " |      8   1.167946  0.429082  1.215742 -1.636041\n",
      " |      9   1.197475 -0.864188  1.554031 -1.505264\n",
      " |  \n",
      " |  select(self, crit, axis=0)\n",
      " |      Return data corresponding to axis labels matching criteria\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |          Use df.loc[df.index.map(crit)] to select via labels\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      crit : function\n",
      " |          To be called on each index (label). Should return True or False\n",
      " |      axis : int\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      selection : type of caller\n",
      " |  \n",
      " |  set_axis(self, labels, axis=0, inplace=None)\n",
      " |      Assign desired index to given axis.\n",
      " |      \n",
      " |      Indexes for column or row labels can be changed by assigning\n",
      " |      a list-like or Index.\n",
      " |      \n",
      " |      .. versionchanged:: 0.21.0\n",
      " |      \n",
      " |         The signature is now `labels` and `axis`, consistent with\n",
      " |         the rest of pandas API. Previously, the `axis` and `labels`\n",
      " |         arguments were respectively the first and second positional\n",
      " |         arguments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : list-like, Index\n",
      " |          The values for the new index.\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to update. The value 0 identifies the rows, and 1\n",
      " |          identifies the columns.\n",
      " |      \n",
      " |      inplace : boolean, default None\n",
      " |          Whether to return a new %(klass)s instance.\n",
      " |      \n",
      " |          .. warning::\n",
      " |      \n",
      " |             ``inplace=None`` currently falls back to to True, but in a\n",
      " |             future version, will default to False. Use inplace=True\n",
      " |             explicitly rather than relying on the default.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : %(klass)s or None\n",
      " |          An object of same type as caller if inplace=False, None otherwise.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.rename_axis : Alter the name of the index or columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.set_axis(['a', 'b', 'c'], axis=0, inplace=False)\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      c    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The original object is not modified.\n",
      " |      \n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      \n",
      " |      Change the row labels.\n",
      " |      \n",
      " |      >>> df.set_axis(['a', 'b', 'c'], axis='index', inplace=False)\n",
      " |         A  B\n",
      " |      a  1  4\n",
      " |      b  2  5\n",
      " |      c  3  6\n",
      " |      \n",
      " |      Change the column labels.\n",
      " |      \n",
      " |      >>> df.set_axis(['I', 'II'], axis='columns', inplace=False)\n",
      " |         I  II\n",
      " |      0  1   4\n",
      " |      1  2   5\n",
      " |      2  3   6\n",
      " |      \n",
      " |      Now, update the labels inplace.\n",
      " |      \n",
      " |      >>> df.set_axis(['i', 'ii'], axis='columns', inplace=True)\n",
      " |      >>> df\n",
      " |         i  ii\n",
      " |      0  1   4\n",
      " |      1  2   5\n",
      " |      2  3   6\n",
      " |  \n",
      " |  slice_shift(self, periods=1, axis=0)\n",
      " |      Equivalent to `shift` without copying data. The shifted data will\n",
      " |      not include the dropped periods and the shifted axis will be smaller\n",
      " |      than the original.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      While the `slice_shift` is faster than `shift`, you may pay for it\n",
      " |      later during alignment.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : same type as caller\n",
      " |  \n",
      " |  squeeze(self, axis=None)\n",
      " |      Squeeze length 1 dimensions.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : None, integer or string axis name, optional\n",
      " |          The axis to squeeze if 1-sized.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar if 1-sized, else original object\n",
      " |  \n",
      " |  swapaxes(self, axis1, axis2, copy=True)\n",
      " |      Interchange axes and swap values axes appropriately\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : same as input\n",
      " |  \n",
      " |  tail(self, n=5)\n",
      " |      Return the last `n` rows.\n",
      " |      \n",
      " |      This function returns last `n` rows from the object based on\n",
      " |      position. It is useful for quickly verifying data, for example,\n",
      " |      after sorting or appending rows.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The last `n` rows of the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.head : The first `n` rows of the caller object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal':['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |      \n",
      " |      Viewing the last 5 lines\n",
      " |      \n",
      " |      >>> df.tail()\n",
      " |         animal\n",
      " |      4  monkey\n",
      " |      5  parrot\n",
      " |      6   shark\n",
      " |      7   whale\n",
      " |      8   zebra\n",
      " |      \n",
      " |      Viewing the last `n` lines (three in this case)\n",
      " |      \n",
      " |      >>> df.tail(3)\n",
      " |        animal\n",
      " |      6  shark\n",
      " |      7  whale\n",
      " |      8  zebra\n",
      " |  \n",
      " |  take(self, indices, axis=0, convert=None, is_copy=True, **kwargs)\n",
      " |      Return the elements in the given *positional* indices along an axis.\n",
      " |      \n",
      " |      This means that we are not indexing according to actual values in\n",
      " |      the index attribute of the object. We are indexing according to the\n",
      " |      actual position of the element in the object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : array-like\n",
      " |          An array of ints indicating which positions to take.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          The axis on which to select elements. ``0`` means that we are\n",
      " |          selecting rows, ``1`` means that we are selecting columns.\n",
      " |      convert : bool, default True\n",
      " |          Whether to convert negative indices into positive ones.\n",
      " |          For example, ``-1`` would map to the ``len(axis) - 1``.\n",
      " |          The conversions are similar to the behavior of indexing a\n",
      " |          regular Python list.\n",
      " |      \n",
      " |          .. deprecated:: 0.21.0\n",
      " |             In the future, negative indices will always be converted.\n",
      " |      \n",
      " |      is_copy : bool, default True\n",
      " |          Whether to return a copy of the original object or not.\n",
      " |      **kwargs\n",
      " |          For compatibility with :meth:`numpy.take`. Has no effect on the\n",
      " |          output.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      taken : type of caller\n",
      " |          An array-like containing the elements taken from the object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by labels.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by positions.\n",
      " |      numpy.take : Take elements from an array along an axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird',    389.0),\n",
      " |      ...                    ('parrot', 'bird',     24.0),\n",
      " |      ...                    ('lion',   'mammal',   80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                    columns=['name', 'class', 'max_speed'],\n",
      " |      ...                    index=[0, 2, 3, 1])\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      2  parrot    bird       24.0\n",
      " |      3    lion  mammal       80.5\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at positions 0 and 3 along the axis 0 (default).\n",
      " |      \n",
      " |      Note how the actual indices selected (0 and 1) do not correspond to\n",
      " |      our selected indices 0 and 3. That's because we are selecting the 0th\n",
      " |      and 3rd rows, not rows whose indices equal 0 and 3.\n",
      " |      \n",
      " |      >>> df.take([0, 3])\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      " |      \n",
      " |      >>> df.take([1, 2], axis=1)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      2    bird       24.0\n",
      " |      3  mammal       80.5\n",
      " |      1  mammal        NaN\n",
      " |      \n",
      " |      We may take elements using negative integers for positive indices,\n",
      " |      starting from the end of the object, just like with Python lists.\n",
      " |      \n",
      " |      >>> df.take([-1, -2])\n",
      " |           name   class  max_speed\n",
      " |      1  monkey  mammal        NaN\n",
      " |      3    lion  mammal       80.5\n",
      " |  \n",
      " |  to_clipboard(self, excel=True, sep=None, **kwargs)\n",
      " |      Copy object to the system clipboard.\n",
      " |      \n",
      " |      Write a text representation of object to the system clipboard.\n",
      " |      This can be pasted into Excel, for example.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel : bool, default True\n",
      " |          - True, use the provided separator, writing in a csv format for\n",
      " |            allowing easy pasting into excel.\n",
      " |          - False, write a string representation of the object to the\n",
      " |            clipboard.\n",
      " |      \n",
      " |      sep : str, default ``'\\t'``\n",
      " |          Field delimiter.\n",
      " |      **kwargs\n",
      " |          These parameters will be passed to DataFrame.to_csv.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_csv : Write a DataFrame to a comma-separated values\n",
      " |          (csv) file.\n",
      " |      read_clipboard : Read text from clipboard and pass to read_table.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Requirements for your platform.\n",
      " |      \n",
      " |        - Linux : `xclip`, or `xsel` (with `gtk` or `PyQt4` modules)\n",
      " |        - Windows : none\n",
      " |        - OS X : none\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Copy the contents of a DataFrame to the clipboard.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['A', 'B', 'C'])\n",
      " |      >>> df.to_clipboard(sep=',')\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # ,A,B,C\n",
      " |      ... # 0,1,2,3\n",
      " |      ... # 1,4,5,6\n",
      " |      \n",
      " |      We can omit the the index by passing the keyword `index` and setting\n",
      " |      it to false.\n",
      " |      \n",
      " |      >>> df.to_clipboard(sep=',', index=False)\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # A,B,C\n",
      " |      ... # 1,2,3\n",
      " |      ... # 4,5,6\n",
      " |  \n",
      " |  to_dense(self)\n",
      " |      Return dense representation of NDFrame (as opposed to sparse)\n",
      " |  \n",
      " |  to_hdf(self, path_or_buf, key, **kwargs)\n",
      " |      Write the contained data to an HDF5 file using HDFStore.\n",
      " |      \n",
      " |      Hierarchical Data Format (HDF) is self-describing, allowing an\n",
      " |      application to interpret the structure and contents of a file with\n",
      " |      no outside information. One HDF file can hold a mix of related objects\n",
      " |      which can be accessed as a group or as individual objects.\n",
      " |      \n",
      " |      In order to add another DataFrame or Series to an existing HDF file\n",
      " |      please use append mode and a different a key.\n",
      " |      \n",
      " |      For more information see the :ref:`user guide <io.hdf5>`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str or pandas.HDFStore\n",
      " |          File path or HDFStore object.\n",
      " |      key : str\n",
      " |          Identifier for the group in the store.\n",
      " |      mode : {'a', 'w', 'r+'}, default 'a'\n",
      " |          Mode to open file:\n",
      " |      \n",
      " |          - 'w': write, a new file is created (an existing file with\n",
      " |            the same name would be deleted).\n",
      " |          - 'a': append, an existing file is opened for reading and\n",
      " |            writing, and if the file does not exist it is created.\n",
      " |          - 'r+': similar to 'a', but the file must already exist.\n",
      " |      format : {'fixed', 'table'}, default 'fixed'\n",
      " |          Possible values:\n",
      " |      \n",
      " |          - 'fixed': Fixed format. Fast writing/reading. Not-appendable,\n",
      " |            nor searchable.\n",
      " |          - 'table': Table format. Write as a PyTables Table structure\n",
      " |            which may perform worse but allow more flexible operations\n",
      " |            like searching / selecting subsets of the data.\n",
      " |      append : bool, default False\n",
      " |          For Table formats, append the input data to the existing.\n",
      " |      data_columns :  list of columns or True, optional\n",
      " |          List of columns to create as indexed data columns for on-disk\n",
      " |          queries, or True to use all columns. By default only the axes\n",
      " |          of the object are indexed. See :ref:`io.hdf5-query-data-columns`.\n",
      " |          Applicable only to format='table'.\n",
      " |      complevel : {0-9}, optional\n",
      " |          Specifies a compression level for data.\n",
      " |          A value of 0 disables compression.\n",
      " |      complib : {'zlib', 'lzo', 'bzip2', 'blosc'}, default 'zlib'\n",
      " |          Specifies the compression library to be used.\n",
      " |          As of v0.20.2 these additional compressors for Blosc are supported\n",
      " |          (default if no compressor specified: 'blosc:blosclz'):\n",
      " |          {'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy',\n",
      " |          'blosc:zlib', 'blosc:zstd'}.\n",
      " |          Specifying a compression library which is not available issues\n",
      " |          a ValueError.\n",
      " |      fletcher32 : bool, default False\n",
      " |          If applying compression use the fletcher32 checksum.\n",
      " |      dropna : bool, default False\n",
      " |          If true, ALL nan rows will not be written to store.\n",
      " |      errors : str, default 'strict'\n",
      " |          Specifies how encoding and decoding errors are to be handled.\n",
      " |          See the errors argument for :func:`open` for a full list\n",
      " |          of options.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.read_hdf : Read from HDF file.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      DataFrame.to_sql : Write to a sql table.\n",
      " |      DataFrame.to_feather : Write out feather-format for DataFrames.\n",
      " |      DataFrame.to_csv : Write out to a csv file.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},\n",
      " |      ...                   index=['a', 'b', 'c'])\n",
      " |      >>> df.to_hdf('data.h5', key='df', mode='w')\n",
      " |      \n",
      " |      We can add another object to the same file:\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s.to_hdf('data.h5', key='s')\n",
      " |      \n",
      " |      Reading from HDF file:\n",
      " |      \n",
      " |      >>> pd.read_hdf('data.h5', 'df')\n",
      " |      A  B\n",
      " |      a  1  4\n",
      " |      b  2  5\n",
      " |      c  3  6\n",
      " |      >>> pd.read_hdf('data.h5', 's')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Deleting file with data:\n",
      " |      \n",
      " |      >>> import os\n",
      " |      >>> os.remove('data.h5')\n",
      " |  \n",
      " |  to_json(self, path_or_buf=None, orient=None, date_format=None, double_precision=10, force_ascii=True, date_unit='ms', default_handler=None, lines=False, compression=None, index=True)\n",
      " |      Convert the object to a JSON string.\n",
      " |      \n",
      " |      Note NaN's and None will be converted to null and datetime objects\n",
      " |      will be converted to UNIX timestamps.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : string or file handle, optional\n",
      " |          File path or object. If not specified, the result is returned as\n",
      " |          a string.\n",
      " |      orient : string\n",
      " |          Indication of expected JSON string format.\n",
      " |      \n",
      " |          * Series\n",
      " |      \n",
      " |            - default is 'index'\n",
      " |            - allowed values are: {'split','records','index'}\n",
      " |      \n",
      " |          * DataFrame\n",
      " |      \n",
      " |            - default is 'columns'\n",
      " |            - allowed values are:\n",
      " |              {'split','records','index','columns','values'}\n",
      " |      \n",
      " |          * The format of the JSON string\n",
      " |      \n",
      " |            - 'split' : dict like {'index' -> [index],\n",
      " |              'columns' -> [columns], 'data' -> [values]}\n",
      " |            - 'records' : list like\n",
      " |              [{column -> value}, ... , {column -> value}]\n",
      " |            - 'index' : dict like {index -> {column -> value}}\n",
      " |            - 'columns' : dict like {column -> {index -> value}}\n",
      " |            - 'values' : just the values array\n",
      " |            - 'table' : dict like {'schema': {schema}, 'data': {data}}\n",
      " |              describing the data, and the data component is\n",
      " |              like ``orient='records'``.\n",
      " |      \n",
      " |              .. versionchanged:: 0.20.0\n",
      " |      \n",
      " |      date_format : {None, 'epoch', 'iso'}\n",
      " |          Type of date conversion. 'epoch' = epoch milliseconds,\n",
      " |          'iso' = ISO8601. The default depends on the `orient`. For\n",
      " |          ``orient='table'``, the default is 'iso'. For all other orients,\n",
      " |          the default is 'epoch'.\n",
      " |      double_precision : int, default 10\n",
      " |          The number of decimal places to use when encoding\n",
      " |          floating point values.\n",
      " |      force_ascii : boolean, default True\n",
      " |          Force encoded string to be ASCII.\n",
      " |      date_unit : string, default 'ms' (milliseconds)\n",
      " |          The time unit to encode to, governs timestamp and ISO8601\n",
      " |          precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      " |          microsecond, and nanosecond respectively.\n",
      " |      default_handler : callable, default None\n",
      " |          Handler to call if object cannot otherwise be converted to a\n",
      " |          suitable format for JSON. Should receive a single argument which is\n",
      " |          the object to convert and return a serialisable object.\n",
      " |      lines : boolean, default False\n",
      " |          If 'orient' is 'records' write out line delimited json format. Will\n",
      " |          throw ValueError if incorrect 'orient' since others are not list\n",
      " |          like.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      compression : {None, 'gzip', 'bz2', 'zip', 'xz'}\n",
      " |          A string representing the compression to use in the output file,\n",
      " |          only used when the first argument is a filename.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      index : boolean, default True\n",
      " |          Whether to include the index values in the JSON string. Not\n",
      " |          including the index (``index=False``) is only supported when\n",
      " |          orient is 'split' or 'table'.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.read_json\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      " |      ...                   index=['row 1', 'row 2'],\n",
      " |      ...                   columns=['col 1', 'col 2'])\n",
      " |      >>> df.to_json(orient='split')\n",
      " |      '{\"columns\":[\"col 1\",\"col 2\"],\n",
      " |        \"index\":[\"row 1\",\"row 2\"],\n",
      " |        \"data\":[[\"a\",\"b\"],[\"c\",\"d\"]]}'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      " |      Note that index labels are not preserved with this encoding.\n",
      " |      \n",
      " |      >>> df.to_json(orient='records')\n",
      " |      '[{\"col 1\":\"a\",\"col 2\":\"b\"},{\"col 1\":\"c\",\"col 2\":\"d\"}]'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      " |      \n",
      " |      >>> df.to_json(orient='index')\n",
      " |      '{\"row 1\":{\"col 1\":\"a\",\"col 2\":\"b\"},\"row 2\":{\"col 1\":\"c\",\"col 2\":\"d\"}}'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'columns'`` formatted JSON:\n",
      " |      \n",
      " |      >>> df.to_json(orient='columns')\n",
      " |      '{\"col 1\":{\"row 1\":\"a\",\"row 2\":\"c\"},\"col 2\":{\"row 1\":\"b\",\"row 2\":\"d\"}}'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'values'`` formatted JSON:\n",
      " |      \n",
      " |      >>> df.to_json(orient='values')\n",
      " |      '[[\"a\",\"b\"],[\"c\",\"d\"]]'\n",
      " |      \n",
      " |      Encoding with Table Schema\n",
      " |      \n",
      " |      >>> df.to_json(orient='table')\n",
      " |      '{\"schema\": {\"fields\": [{\"name\": \"index\", \"type\": \"string\"},\n",
      " |                              {\"name\": \"col 1\", \"type\": \"string\"},\n",
      " |                              {\"name\": \"col 2\", \"type\": \"string\"}],\n",
      " |                   \"primaryKey\": \"index\",\n",
      " |                   \"pandas_version\": \"0.20.0\"},\n",
      " |        \"data\": [{\"index\": \"row 1\", \"col 1\": \"a\", \"col 2\": \"b\"},\n",
      " |                 {\"index\": \"row 2\", \"col 1\": \"c\", \"col 2\": \"d\"}]}'\n",
      " |  \n",
      " |  to_latex(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=False, column_format=None, longtable=None, escape=None, encoding=None, decimal='.', multicolumn=None, multicolumn_format=None, multirow=None)\n",
      " |      Render an object to a tabular environment table. You can splice\n",
      " |      this into a LaTeX document. Requires \\\\usepackage{booktabs}.\n",
      " |      \n",
      " |      .. versionchanged:: 0.20.2\n",
      " |         Added to Series\n",
      " |      \n",
      " |      `to_latex`-specific options:\n",
      " |      \n",
      " |      bold_rows : boolean, default False\n",
      " |          Make the row labels bold in the output\n",
      " |      column_format : str, default None\n",
      " |          The columns format as specified in `LaTeX table format\n",
      " |          <https://en.wikibooks.org/wiki/LaTeX/Tables>`__ e.g 'rcl' for 3\n",
      " |          columns\n",
      " |      longtable : boolean, default will be read from the pandas config module\n",
      " |          Default: False.\n",
      " |          Use a longtable environment instead of tabular. Requires adding\n",
      " |          a \\\\usepackage{longtable} to your LaTeX preamble.\n",
      " |      escape : boolean, default will be read from the pandas config module\n",
      " |          Default: True.\n",
      " |          When set to False prevents from escaping latex special\n",
      " |          characters in column names.\n",
      " |      encoding : str, default None\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'ascii' on Python 2 and 'utf-8' on Python 3.\n",
      " |      decimal : string, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      multicolumn : boolean, default True\n",
      " |          Use \\multicolumn to enhance MultiIndex columns.\n",
      " |          The default will be read from the config module.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      multicolumn_format : str, default 'l'\n",
      " |          The alignment for multicolumns, similar to `column_format`\n",
      " |          The default will be read from the config module.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      multirow : boolean, default False\n",
      " |          Use \\multirow to enhance MultiIndex rows.\n",
      " |          Requires adding a \\\\usepackage{multirow} to your LaTeX preamble.\n",
      " |          Will print centered labels (instead of top-aligned)\n",
      " |          across the contained rows, separating groups via clines.\n",
      " |          The default will be read from the pandas config module.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |  \n",
      " |  to_msgpack(self, path_or_buf=None, encoding='utf-8', **kwargs)\n",
      " |      msgpack (serialize) object to input file path\n",
      " |      \n",
      " |      THIS IS AN EXPERIMENTAL LIBRARY and the storage format\n",
      " |      may not be stable until a future release.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string File path, buffer-like, or None\n",
      " |          if None, return generated string\n",
      " |      append : boolean whether to append to an existing msgpack\n",
      " |          (default is False)\n",
      " |      compress : type of compressor (zlib or blosc), default to None (no\n",
      " |          compression)\n",
      " |  \n",
      " |  to_pickle(self, path, compression='infer', protocol=4)\n",
      " |      Pickle (serialize) object to file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str\n",
      " |          File path where the pickled object will be stored.\n",
      " |      compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None},         default 'infer'\n",
      " |          A string representing the compression to use in the output file. By\n",
      " |          default, infers from the file extension in specified path.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      protocol : int\n",
      " |          Int which indicates which protocol should be used by the pickler,\n",
      " |          default HIGHEST_PROTOCOL (see [1]_ paragraph 12.1.2). The possible\n",
      " |          values for this parameter depend on the version of Python. For\n",
      " |          Python 2.x, possible values are 0, 1, 2. For Python>=3.0, 3 is a\n",
      " |          valid value. For Python >= 3.4, 4 is a valid value. A negative\n",
      " |          value for the protocol parameter is equivalent to setting its value\n",
      " |          to HIGHEST_PROTOCOL.\n",
      " |      \n",
      " |          .. [1] https://docs.python.org/3/library/pickle.html\n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_pickle : Load pickled pandas object (or any object) from file.\n",
      " |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.\n",
      " |      DataFrame.to_sql : Write DataFrame to a SQL database.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> original_df = pd.DataFrame({\"foo\": range(5), \"bar\": range(5, 10)})\n",
      " |      >>> original_df\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |      >>> original_df.to_pickle(\"./dummy.pkl\")\n",
      " |      \n",
      " |      >>> unpickled_df = pd.read_pickle(\"./dummy.pkl\")\n",
      " |      >>> unpickled_df\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |      \n",
      " |      >>> import os\n",
      " |      >>> os.remove(\"./dummy.pkl\")\n",
      " |  \n",
      " |  to_sql(self, name, con, schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None)\n",
      " |      Write records stored in a DataFrame to a SQL database.\n",
      " |      \n",
      " |      Databases supported by SQLAlchemy [1]_ are supported. Tables can be\n",
      " |      newly created, appended to, or overwritten.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : string\n",
      " |          Name of SQL table.\n",
      " |      con : sqlalchemy.engine.Engine or sqlite3.Connection\n",
      " |          Using SQLAlchemy makes it possible to use any DB supported by that\n",
      " |          library. Legacy support is provided for sqlite3.Connection objects.\n",
      " |      schema : string, optional\n",
      " |          Specify the schema (if database flavor supports this). If None, use\n",
      " |          default schema.\n",
      " |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      " |          How to behave if the table already exists.\n",
      " |      \n",
      " |          * fail: Raise a ValueError.\n",
      " |          * replace: Drop the table before inserting new values.\n",
      " |          * append: Insert new values to the existing table.\n",
      " |      \n",
      " |      index : boolean, default True\n",
      " |          Write DataFrame index as a column. Uses `index_label` as the column\n",
      " |          name in the table.\n",
      " |      index_label : string or sequence, default None\n",
      " |          Column label for index column(s). If None is given (default) and\n",
      " |          `index` is True, then the index names are used.\n",
      " |          A sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      chunksize : int, optional\n",
      " |          Rows will be written in batches of this size at a time. By default,\n",
      " |          all rows will be written at once.\n",
      " |      dtype : dict, optional\n",
      " |          Specifying the datatype for columns. The keys should be the column\n",
      " |          names and the values should be the SQLAlchemy types or strings for\n",
      " |          the sqlite3 legacy mode.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          When the table already exists and `if_exists` is 'fail' (the\n",
      " |          default).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.read_sql : read a DataFrame from a table\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] http://docs.sqlalchemy.org\n",
      " |      .. [2] https://www.python.org/dev/peps/pep-0249/\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Create an in-memory SQLite database.\n",
      " |      \n",
      " |      >>> from sqlalchemy import create_engine\n",
      " |      >>> engine = create_engine('sqlite://', echo=False)\n",
      " |      \n",
      " |      Create a table from scratch with 3 rows.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})\n",
      " |      >>> df\n",
      " |           name\n",
      " |      0  User 1\n",
      " |      1  User 2\n",
      " |      2  User 3\n",
      " |      \n",
      " |      >>> df.to_sql('users', con=engine)\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3')]\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'name' : ['User 4', 'User 5']})\n",
      " |      >>> df1.to_sql('users', con=engine, if_exists='append')\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3'),\n",
      " |       (0, 'User 4'), (1, 'User 5')]\n",
      " |      \n",
      " |      Overwrite the table with just ``df1``.\n",
      " |      \n",
      " |      >>> df1.to_sql('users', con=engine, if_exists='replace',\n",
      " |      ...            index_label='id')\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 4'), (1, 'User 5')]\n",
      " |      \n",
      " |      Specify the dtype (especially useful for integers with missing values).\n",
      " |      Notice that while pandas is forced to store the data as floating point,\n",
      " |      the database supports nullable integers. When fetching the data with\n",
      " |      Python, we get back integer scalars.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, None, 2]})\n",
      " |      >>> df\n",
      " |           A\n",
      " |      0  1.0\n",
      " |      1  NaN\n",
      " |      2  2.0\n",
      " |      \n",
      " |      >>> from sqlalchemy.types import Integer\n",
      " |      >>> df.to_sql('integers', con=engine, index=False,\n",
      " |      ...           dtype={\"A\": Integer()})\n",
      " |      \n",
      " |      >>> engine.execute(\"SELECT * FROM integers\").fetchall()\n",
      " |      [(1,), (None,), (2,)]\n",
      " |  \n",
      " |  to_xarray(self)\n",
      " |      Return an xarray object from the pandas object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a DataArray for a Series\n",
      " |      a Dataset for a DataFrame\n",
      " |      a DataArray for higher dims\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A' : [1, 1, 2],\n",
      " |                             'B' : ['foo', 'bar', 'foo'],\n",
      " |                             'C' : np.arange(4.,7)})\n",
      " |      >>> df\n",
      " |         A    B    C\n",
      " |      0  1  foo  4.0\n",
      " |      1  1  bar  5.0\n",
      " |      2  2  foo  6.0\n",
      " |      \n",
      " |      >>> df.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (index: 3)\n",
      " |      Coordinates:\n",
      " |        * index    (index) int64 0 1 2\n",
      " |      Data variables:\n",
      " |          A        (index) int64 1 1 2\n",
      " |          B        (index) object 'foo' 'bar' 'foo'\n",
      " |          C        (index) float64 4.0 5.0 6.0\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A' : [1, 1, 2],\n",
      " |                             'B' : ['foo', 'bar', 'foo'],\n",
      " |                             'C' : np.arange(4.,7)}\n",
      " |                           ).set_index(['B','A'])\n",
      " |      >>> df\n",
      " |               C\n",
      " |      B   A\n",
      " |      foo 1  4.0\n",
      " |      bar 1  5.0\n",
      " |      foo 2  6.0\n",
      " |      \n",
      " |      >>> df.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (A: 2, B: 2)\n",
      " |      Coordinates:\n",
      " |        * B        (B) object 'bar' 'foo'\n",
      " |        * A        (A) int64 1 2\n",
      " |      Data variables:\n",
      " |          C        (B, A) float64 5.0 nan 4.0 6.0\n",
      " |      \n",
      " |      >>> p = pd.Panel(np.arange(24).reshape(4,3,2),\n",
      " |                       items=list('ABCD'),\n",
      " |                       major_axis=pd.date_range('20130101', periods=3),\n",
      " |                       minor_axis=['first', 'second'])\n",
      " |      >>> p\n",
      " |      <class 'pandas.core.panel.Panel'>\n",
      " |      Dimensions: 4 (items) x 3 (major_axis) x 2 (minor_axis)\n",
      " |      Items axis: A to D\n",
      " |      Major_axis axis: 2013-01-01 00:00:00 to 2013-01-03 00:00:00\n",
      " |      Minor_axis axis: first to second\n",
      " |      \n",
      " |      >>> p.to_xarray()\n",
      " |      <xarray.DataArray (items: 4, major_axis: 3, minor_axis: 2)>\n",
      " |      array([[[ 0,  1],\n",
      " |              [ 2,  3],\n",
      " |              [ 4,  5]],\n",
      " |             [[ 6,  7],\n",
      " |              [ 8,  9],\n",
      " |              [10, 11]],\n",
      " |             [[12, 13],\n",
      " |              [14, 15],\n",
      " |              [16, 17]],\n",
      " |             [[18, 19],\n",
      " |              [20, 21],\n",
      " |              [22, 23]]])\n",
      " |      Coordinates:\n",
      " |        * items       (items) object 'A' 'B' 'C' 'D'\n",
      " |        * major_axis  (major_axis) datetime64[ns] 2013-01-01 2013-01-02 2013-01-03  # noqa\n",
      " |        * minor_axis  (minor_axis) object 'first' 'second'\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `xarray docs <http://xarray.pydata.org/en/stable/>`__\n",
      " |  \n",
      " |  truncate(self, before=None, after=None, axis=None, copy=True)\n",
      " |      Truncate a Series or DataFrame before and after some index value.\n",
      " |      \n",
      " |      This is a useful shorthand for boolean indexing based on index\n",
      " |      values above or below certain thresholds.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      before : date, string, int\n",
      " |          Truncate all rows before this index value.\n",
      " |      after : date, string, int\n",
      " |          Truncate all rows after this index value.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, optional\n",
      " |          Axis to truncate. Truncates the index (rows) by default.\n",
      " |      copy : boolean, default is True,\n",
      " |          Return a copy of the truncated section.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The truncated Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by label.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by position.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the index being truncated contains only datetime values,\n",
      " |      `before` and `after` may be specified as strings instead of\n",
      " |      Timestamps.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c', 'd', 'e'],\n",
      " |      ...                    'B': ['f', 'g', 'h', 'i', 'j'],\n",
      " |      ...                    'C': ['k', 'l', 'm', 'n', 'o']},\n",
      " |      ...                    index=[1, 2, 3, 4, 5])\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      1  a  f  k\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      5  e  j  o\n",
      " |      \n",
      " |      >>> df.truncate(before=2, after=4)\n",
      " |         A  B  C\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      \n",
      " |      The columns of a DataFrame can be truncated.\n",
      " |      \n",
      " |      >>> df.truncate(before=\"A\", after=\"B\", axis=\"columns\")\n",
      " |         A  B\n",
      " |      1  a  f\n",
      " |      2  b  g\n",
      " |      3  c  h\n",
      " |      4  d  i\n",
      " |      5  e  j\n",
      " |      \n",
      " |      For Series, only rows can be truncated.\n",
      " |      \n",
      " |      >>> df['A'].truncate(before=2, after=4)\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    d\n",
      " |      Name: A, dtype: object\n",
      " |      \n",
      " |      The index values in ``truncate`` can be datetimes or string\n",
      " |      dates.\n",
      " |      \n",
      " |      >>> dates = pd.date_range('2016-01-01', '2016-02-01', freq='s')\n",
      " |      >>> df = pd.DataFrame(index=dates, data={'A': 1})\n",
      " |      >>> df.tail()\n",
      " |                           A\n",
      " |      2016-01-31 23:59:56  1\n",
      " |      2016-01-31 23:59:57  1\n",
      " |      2016-01-31 23:59:58  1\n",
      " |      2016-01-31 23:59:59  1\n",
      " |      2016-02-01 00:00:00  1\n",
      " |      \n",
      " |      >>> df.truncate(before=pd.Timestamp('2016-01-05'),\n",
      " |      ...             after=pd.Timestamp('2016-01-10')).tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |      \n",
      " |      Because the index is a DatetimeIndex containing only dates, we can\n",
      " |      specify `before` and `after` as strings. They will be coerced to\n",
      " |      Timestamps before truncation.\n",
      " |      \n",
      " |      >>> df.truncate('2016-01-05', '2016-01-10').tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |      \n",
      " |      Note that ``truncate`` assumes a 0 value for any unspecified time\n",
      " |      component (midnight). This differs from partial string slicing, which\n",
      " |      returns any partially matching dates.\n",
      " |      \n",
      " |      >>> df.loc['2016-01-05':'2016-01-10', :].tail()\n",
      " |                           A\n",
      " |      2016-01-10 23:59:55  1\n",
      " |      2016-01-10 23:59:56  1\n",
      " |      2016-01-10 23:59:57  1\n",
      " |      2016-01-10 23:59:58  1\n",
      " |      2016-01-10 23:59:59  1\n",
      " |  \n",
      " |  tshift(self, periods=1, freq=None, axis=0)\n",
      " |      Shift the time index, using the index's frequency if available.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      freq : DateOffset, timedelta, or time rule string, default None\n",
      " |          Increment to use from the tseries module or time rule (e.g. 'EOM')\n",
      " |      axis : int or basestring\n",
      " |          Corresponds to the axis that contains the Index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is not specified then tries to use the freq or inferred_freq\n",
      " |      attributes of the index. If neither of those attributes exist, a\n",
      " |      ValueError is thrown\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : NDFrame\n",
      " |  \n",
      " |  tz_convert(self, tz, axis=0, level=None, copy=True)\n",
      " |      Convert tz-aware axis to target time zone.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : string or pytz.timezone object\n",
      " |      axis : the axis to convert\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, convert a specific level. Otherwise\n",
      " |          must be None\n",
      " |      copy : boolean, default True\n",
      " |          Also make a copy of the underlying data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the axis is tz-naive.\n",
      " |  \n",
      " |  tz_localize(self, tz, axis=0, level=None, copy=True, ambiguous='raise')\n",
      " |      Localize tz-naive TimeSeries to target time zone.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : string or pytz.timezone object\n",
      " |      axis : the axis to localize\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, localize a specific level. Otherwise\n",
      " |          must be None\n",
      " |      copy : boolean, default True\n",
      " |          Also make a copy of the underlying data\n",
      " |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      " |            order\n",
      " |          - bool-ndarray where True signifies a DST time, False designates\n",
      " |            a non-DST time (note that this flag is only applicable for\n",
      " |            ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      " |            times\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the TimeSeries is tz-aware and tz is not None.\n",
      " |  \n",
      " |  where(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=False, raise_on_error=None)\n",
      " |      Return an object of same shape as self and whose corresponding\n",
      " |      entries are from self where `cond` is True and otherwise are from\n",
      " |      `other`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : boolean NDFrame, array-like, or callable\n",
      " |          Where `cond` is True, keep the original value. Where\n",
      " |          False, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the NDFrame and\n",
      " |          should return boolean NDFrame or array. The callable must\n",
      " |          not change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as cond.\n",
      " |      \n",
      " |      other : scalar, NDFrame, or callable\n",
      " |          Entries where `cond` is False are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the NDFrame and\n",
      " |          should return scalar or NDFrame. The callable must not\n",
      " |          change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as other.\n",
      " |      \n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data\n",
      " |      axis : alignment axis if needed, default None\n",
      " |      level : alignment level if needed, default None\n",
      " |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object\n",
      " |      \n",
      " |          Note that currently this parameter won't affect\n",
      " |          the results and will always coerce to a suitable dtype.\n",
      " |      \n",
      " |      try_cast : boolean, default False\n",
      " |          try to cast the result back to the input type (if possible),\n",
      " |      raise_on_error : boolean, default True\n",
      " |          Whether to raise on invalid data types (e.g. trying to where on\n",
      " |          strings)\n",
      " |      \n",
      " |          .. deprecated:: 0.21.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      wh : same type as caller\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The where method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``True`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``where`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      \n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      \n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10.0\n",
      " |      1    10.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.mask`\n",
      " |  \n",
      " |  xs(self, key, axis=0, level=None, drop_level=True)\n",
      " |      Returns a cross-section (row(s) or column(s)) from the\n",
      " |      Series/DataFrame. Defaults to cross-section on the rows (axis=0).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |          Some label contained in the index, or partially in a MultiIndex\n",
      " |      axis : int, default 0\n",
      " |          Axis to retrieve cross-section on\n",
      " |      level : object, defaults to first n levels (n=1 or len(key))\n",
      " |          In case of a key partially contained in a MultiIndex, indicate\n",
      " |          which levels are used. Levels can be referred by label or position.\n",
      " |      drop_level : boolean, default True\n",
      " |          If False, returns object with same levels as self.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      a  4  5  2\n",
      " |      b  4  0  9\n",
      " |      c  9  7  3\n",
      " |      >>> df.xs('a')\n",
      " |      A    4\n",
      " |      B    5\n",
      " |      C    2\n",
      " |      Name: a\n",
      " |      >>> df.xs('C', axis=1)\n",
      " |      a    2\n",
      " |      b    9\n",
      " |      c    3\n",
      " |      Name: C\n",
      " |      \n",
      " |      >>> df\n",
      " |                          A  B  C  D\n",
      " |      first second third\n",
      " |      bar   one    1      4  1  8  9\n",
      " |            two    1      7  5  5  0\n",
      " |      baz   one    1      6  6  8  0\n",
      " |            three  2      5  3  5  3\n",
      " |      >>> df.xs(('baz', 'three'))\n",
      " |             A  B  C  D\n",
      " |      third\n",
      " |      2      5  3  5  3\n",
      " |      >>> df.xs('one', level=1)\n",
      " |                   A  B  C  D\n",
      " |      first third\n",
      " |      bar   1      4  1  8  9\n",
      " |      baz   1      6  6  8  0\n",
      " |      >>> df.xs(('baz', 2), level=[0, 'third'])\n",
      " |              A  B  C  D\n",
      " |      second\n",
      " |      three   5  3  5  3\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      xs : Series or DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      xs is only for getting, not setting values.\n",
      " |      \n",
      " |      MultiIndex Slicers is a generic way to get/set values on any level or\n",
      " |      levels.  It is a superset of xs functionality, see\n",
      " |      :ref:`MultiIndex Slicers <advanced.mi_slicers>`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  at\n",
      " |      Access a single value for a row/column label pair.\n",
      " |      \n",
      " |      Similar to ``loc``, in that both provide label-based lookups. Use\n",
      " |      ``at`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iat : Access a single value for a row/column pair by integer\n",
      " |          position\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s)\n",
      " |      Series.at : Access a single value using a label\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   index=[4, 5, 6], columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      4   0   2   3\n",
      " |      5   0   4   1\n",
      " |      6  10  20  30\n",
      " |      \n",
      " |      Get value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.at[4, 'B']\n",
      " |      2\n",
      " |      \n",
      " |      Set value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.at[4, 'B'] = 10\n",
      " |      >>> df.at[4, 'B']\n",
      " |      10\n",
      " |      \n",
      " |      Get value within a Series\n",
      " |      \n",
      " |      >>> df.loc[5].at['B']\n",
      " |      4\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          When label does not exist in DataFrame\n",
      " |  \n",
      " |  blocks\n",
      " |      Internal property, property synonym for as_blocks()\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |  \n",
      " |  dtypes\n",
      " |      Return the dtypes in the DataFrame.\n",
      " |      \n",
      " |      This returns a Series with the data type of each column.\n",
      " |      The result's index is the original DataFrame's columns. Columns\n",
      " |      with mixed types are stored with the ``object`` dtype. See\n",
      " |      :ref:`the User Guide <basics.dtypes>` for more.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Series\n",
      " |          The data type of each column.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.ftypes : dtype and sparsity information.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'float': [1.0],\n",
      " |      ...                    'int': [1],\n",
      " |      ...                    'datetime': [pd.Timestamp('20180310')],\n",
      " |      ...                    'string': ['foo']})\n",
      " |      >>> df.dtypes\n",
      " |      float              float64\n",
      " |      int                  int64\n",
      " |      datetime    datetime64[ns]\n",
      " |      string              object\n",
      " |      dtype: object\n",
      " |  \n",
      " |  empty\n",
      " |      Indicator whether DataFrame is empty.\n",
      " |      \n",
      " |      True if DataFrame is entirely empty (no items), meaning any of the\n",
      " |      axes are of length 0.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          If DataFrame is empty, return True, if not return False.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If DataFrame contains only NaNs, it is still not considered empty. See\n",
      " |      the example below.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      An example of an actual empty DataFrame. Notice the index is empty:\n",
      " |      \n",
      " |      >>> df_empty = pd.DataFrame({'A' : []})\n",
      " |      >>> df_empty\n",
      " |      Empty DataFrame\n",
      " |      Columns: [A]\n",
      " |      Index: []\n",
      " |      >>> df_empty.empty\n",
      " |      True\n",
      " |      \n",
      " |      If we only have NaNs in our DataFrame, it is not considered empty! We\n",
      " |      will need to drop the NaNs to make the DataFrame empty:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A' : [np.nan]})\n",
      " |      >>> df\n",
      " |          A\n",
      " |      0 NaN\n",
      " |      >>> df.empty\n",
      " |      False\n",
      " |      >>> df.dropna().empty\n",
      " |      True\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.dropna\n",
      " |      pandas.DataFrame.dropna\n",
      " |  \n",
      " |  ftypes\n",
      " |      Return the ftypes (indication of sparse/dense and dtype) in DataFrame.\n",
      " |      \n",
      " |      This returns a Series with the data type of each column.\n",
      " |      The result's index is the original DataFrame's columns. Columns\n",
      " |      with mixed types are stored with the ``object`` dtype.  See\n",
      " |      :ref:`the User Guide <basics.dtypes>` for more.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Series\n",
      " |          The data type and indication of sparse/dense of each column.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.dtypes: Series with just dtype information.\n",
      " |      pandas.SparseDataFrame : Container for sparse tabular data.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Sparse data should have the same dtypes as its dense representation.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import numpy as np\n",
      " |      >>> arr = np.random.RandomState(0).randn(100, 4)\n",
      " |      >>> arr[arr < .8] = np.nan\n",
      " |      >>> pd.DataFrame(arr).ftypes\n",
      " |      0    float64:dense\n",
      " |      1    float64:dense\n",
      " |      2    float64:dense\n",
      " |      3    float64:dense\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> pd.SparseDataFrame(arr).ftypes\n",
      " |      0    float64:sparse\n",
      " |      1    float64:sparse\n",
      " |      2    float64:sparse\n",
      " |      3    float64:sparse\n",
      " |      dtype: object\n",
      " |  \n",
      " |  iat\n",
      " |      Access a single value for a row/column pair by integer position.\n",
      " |      \n",
      " |      Similar to ``iloc``, in that both provide integer-based lookups. Use\n",
      " |      ``iat`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s)\n",
      " |      DataFrame.iloc : Access a group of rows and columns by integer position(s)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      0   0   2   3\n",
      " |      1   0   4   1\n",
      " |      2  10  20  30\n",
      " |      \n",
      " |      Get value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.iat[1, 2]\n",
      " |      1\n",
      " |      \n",
      " |      Set value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.iat[1, 2] = 10\n",
      " |      >>> df.iat[1, 2]\n",
      " |      10\n",
      " |      \n",
      " |      Get value within a series\n",
      " |      \n",
      " |      >>> df.loc[0].iat[1]\n",
      " |      2\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      IndexError\n",
      " |          When integer position is out of bounds\n",
      " |  \n",
      " |  iloc\n",
      " |      Purely integer-location based indexing for selection by position.\n",
      " |      \n",
      " |      ``.iloc[]`` is primarily integer position based (from ``0`` to\n",
      " |      ``length-1`` of the axis), but may also be used with a boolean\n",
      " |      array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - An integer, e.g. ``5``.\n",
      " |      - A list or array of integers, e.g. ``[4, 3, 0]``.\n",
      " |      - A slice object with ints, e.g. ``1:7``.\n",
      " |      - A boolean array.\n",
      " |      - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      " |        or Panel) and that returns valid output for indexing (one of the above)\n",
      " |      \n",
      " |      ``.iloc`` will raise ``IndexError`` if a requested indexer is\n",
      " |      out-of-bounds, except *slice* indexers which allow out-of-bounds\n",
      " |      indexing (this conforms with python/numpy *slice* semantics).\n",
      " |      \n",
      " |      See more at :ref:`Selection by Position <indexing.integer>`\n",
      " |  \n",
      " |  is_copy\n",
      " |  \n",
      " |  ix\n",
      " |      A primarily label-location based indexer, with integer position\n",
      " |      fallback.\n",
      " |      \n",
      " |      Warning: Starting in 0.20.0, the .ix indexer is deprecated, in\n",
      " |      favor of the more strict .iloc and .loc indexers.\n",
      " |      \n",
      " |      ``.ix[]`` supports mixed integer and label based access. It is\n",
      " |      primarily label based, but will fall back to integer positional\n",
      " |      access unless the corresponding axis is of integer type.\n",
      " |      \n",
      " |      ``.ix`` is the most general indexer and will support any of the\n",
      " |      inputs in ``.loc`` and ``.iloc``. ``.ix`` also supports floating\n",
      " |      point label schemes. ``.ix`` is exceptionally useful when dealing\n",
      " |      with mixed positional and label based hierarchical indexes.\n",
      " |      \n",
      " |      However, when an axis is integer based, ONLY label based access\n",
      " |      and not positional access is supported. Thus, in such cases, it's\n",
      " |      usually better to be explicit and use ``.iloc`` or ``.loc``.\n",
      " |      \n",
      " |      See more at :ref:`Advanced Indexing <advanced>`.\n",
      " |  \n",
      " |  loc\n",
      " |      Access a group of rows and columns by label(s) or a boolean array.\n",
      " |      \n",
      " |      ``.loc[]`` is primarily label based, but may also be used with a\n",
      " |      boolean array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      " |        interpreted as a *label* of the index, and **never** as an\n",
      " |        integer position along the index).\n",
      " |      - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      " |      - A slice object with labels, e.g. ``'a':'f'``.\n",
      " |      \n",
      " |        .. warning:: Note that contrary to usual python slices, **both** the\n",
      " |            start and the stop are included\n",
      " |      \n",
      " |      - A boolean array of the same length as the axis being sliced,\n",
      " |        e.g. ``[True, False, True]``.\n",
      " |      - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      " |        or Panel) and that returns valid output for indexing (one of the above)\n",
      " |      \n",
      " |      See more at :ref:`Selection by Label <indexing.label>`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair\n",
      " |      DataFrame.iloc : Access group of rows and columns by integer position(s)\n",
      " |      DataFrame.xs : Returns a cross-section (row(s) or column(s)) from the\n",
      " |          Series/DataFrame.\n",
      " |      Series.loc : Access group of values using labels\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Getting values**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...      index=['cobra', 'viper', 'sidewinder'],\n",
      " |      ...      columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Single label. Note this returns the row as a Series.\n",
      " |      \n",
      " |      >>> df.loc['viper']\n",
      " |      max_speed    4\n",
      " |      shield       5\n",
      " |      Name: viper, dtype: int64\n",
      " |      \n",
      " |      List of labels. Note using ``[[]]`` returns a DataFrame.\n",
      " |      \n",
      " |      >>> df.loc[['viper', 'sidewinder']]\n",
      " |                  max_speed  shield\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Single label for row and column\n",
      " |      \n",
      " |      >>> df.loc['cobra', 'shield']\n",
      " |      2\n",
      " |      \n",
      " |      Slice with labels for row and single label for column. As mentioned\n",
      " |      above, note that both the start and stop of the slice are included.\n",
      " |      \n",
      " |      >>> df.loc['cobra':'viper', 'max_speed']\n",
      " |      cobra    1\n",
      " |      viper    4\n",
      " |      Name: max_speed, dtype: int64\n",
      " |      \n",
      " |      Boolean list with the same length as the row axis\n",
      " |      \n",
      " |      >>> df.loc[[False, False, True]]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Conditional that returns a boolean Series\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 6]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Conditional that returns a boolean Series with column labels specified\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 6, ['max_speed']]\n",
      " |                  max_speed\n",
      " |      sidewinder          7\n",
      " |      \n",
      " |      Callable that returns a boolean Series\n",
      " |      \n",
      " |      >>> df.loc[lambda df: df['shield'] == 8]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      **Setting values**\n",
      " |      \n",
      " |      Set value for all items matching the list of labels\n",
      " |      \n",
      " |      >>> df.loc[['viper', 'sidewinder'], ['shield']] = 50\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |      \n",
      " |      Set value for an entire row\n",
      " |      \n",
      " |      >>> df.loc['cobra'] = 10\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              10      10\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |      \n",
      " |      Set value for an entire column\n",
      " |      \n",
      " |      >>> df.loc[:, 'max_speed'] = 30\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper              30      50\n",
      " |      sidewinder         30      50\n",
      " |      \n",
      " |      Set value for rows matching callable condition\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 35] = 0\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper               0       0\n",
      " |      sidewinder          0       0\n",
      " |      \n",
      " |      **Getting values on a DataFrame with an index that has integer labels**\n",
      " |      \n",
      " |      Another example using integers for the index\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...      index=[7, 8, 9], columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |      \n",
      " |      Slice with integer labels for rows. As mentioned above, note that both\n",
      " |      the start and stop of the slice are included.\n",
      " |      \n",
      " |      >>> df.loc[7:9]\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |      \n",
      " |      **Getting values with a MultiIndex**\n",
      " |      \n",
      " |      A number of examples using a DataFrame with a MultiIndex\n",
      " |      \n",
      " |      >>> tuples = [\n",
      " |      ...    ('cobra', 'mark i'), ('cobra', 'mark ii'),\n",
      " |      ...    ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),\n",
      " |      ...    ('viper', 'mark ii'), ('viper', 'mark iii')\n",
      " |      ... ]\n",
      " |      >>> index = pd.MultiIndex.from_tuples(tuples)\n",
      " |      >>> values = [[12, 2], [0, 4], [10, 20],\n",
      " |      ...         [1, 4], [7, 1], [16, 36]]\n",
      " |      >>> df = pd.DataFrame(values, columns=['max_speed', 'shield'], index=index)\n",
      " |      >>> df\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |      \n",
      " |      Single label. Note this returns a DataFrame with a single index.\n",
      " |      \n",
      " |      >>> df.loc['cobra']\n",
      " |               max_speed  shield\n",
      " |      mark i          12       2\n",
      " |      mark ii          0       4\n",
      " |      \n",
      " |      Single index tuple. Note this returns a Series.\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark ii')]\n",
      " |      max_speed    0\n",
      " |      shield       4\n",
      " |      Name: (cobra, mark ii), dtype: int64\n",
      " |      \n",
      " |      Single label for row and column. Similar to passing in a tuple, this\n",
      " |      returns a Series.\n",
      " |      \n",
      " |      >>> df.loc['cobra', 'mark i']\n",
      " |      max_speed    12\n",
      " |      shield        2\n",
      " |      Name: (cobra, mark i), dtype: int64\n",
      " |      \n",
      " |      Single tuple. Note using ``[[]]`` returns a DataFrame.\n",
      " |      \n",
      " |      >>> df.loc[[('cobra', 'mark ii')]]\n",
      " |                     max_speed  shield\n",
      " |      cobra mark ii          0       4\n",
      " |      \n",
      " |      Single tuple for the index with a single label for the column\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'), 'shield']\n",
      " |      2\n",
      " |      \n",
      " |      Slice from index tuple to single label\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'):'viper']\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |      \n",
      " |      Slice from index tuple to index tuple\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'):('viper', 'mark ii')]\n",
      " |                          max_speed  shield\n",
      " |      cobra      mark i          12       2\n",
      " |                 mark ii          0       4\n",
      " |      sidewinder mark i          10      20\n",
      " |                 mark ii          1       4\n",
      " |      viper      mark ii          7       1\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError:\n",
      " |          when any items are not found\n",
      " |  \n",
      " |  ndim\n",
      " |      Return an int representing the number of axes / array dimensions.\n",
      " |      \n",
      " |      Return 1 if Series. Otherwise return 2 if DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndarray.ndim\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series({'a': 1, 'b': 2, 'c': 3})\n",
      " |      >>> s.ndim\n",
      " |      1\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.ndim\n",
      " |      2\n",
      " |  \n",
      " |  size\n",
      " |      Return an int representing the number of elements in this object.\n",
      " |      \n",
      " |      Return the number of rows if Series. Otherwise return the number of\n",
      " |      rows times number of columns if DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndarray.size\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series({'a': 1, 'b': 2, 'c': 3})\n",
      " |      >>> s.size\n",
      " |      3\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.size\n",
      " |      4\n",
      " |  \n",
      " |  values\n",
      " |      Return a Numpy representation of the DataFrame.\n",
      " |      \n",
      " |      Only the values in the DataFrame will be returned, the axes labels\n",
      " |      will be removed.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          The values of the DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      A DataFrame where all columns are the same type (e.g., int64) results\n",
      " |      in an array of the same type.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age':    [ 3,  29],\n",
      " |      ...                    'height': [94, 170],\n",
      " |      ...                    'weight': [31, 115]})\n",
      " |      >>> df\n",
      " |         age  height  weight\n",
      " |      0    3      94      31\n",
      " |      1   29     170     115\n",
      " |      >>> df.dtypes\n",
      " |      age       int64\n",
      " |      height    int64\n",
      " |      weight    int64\n",
      " |      dtype: object\n",
      " |      >>> df.values\n",
      " |      array([[  3,  94,  31],\n",
      " |             [ 29, 170, 115]], dtype=int64)\n",
      " |      \n",
      " |      A DataFrame with mixed type columns(e.g., str/object, int64, float32)\n",
      " |      results in an ndarray of the broadest type that accommodates these\n",
      " |      mixed types (e.g., object).\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame([('parrot',   24.0, 'second'),\n",
      " |      ...                     ('lion',     80.5, 1),\n",
      " |      ...                     ('monkey', np.nan, None)],\n",
      " |      ...                   columns=('name', 'max_speed', 'rank'))\n",
      " |      >>> df2.dtypes\n",
      " |      name          object\n",
      " |      max_speed    float64\n",
      " |      rank          object\n",
      " |      dtype: object\n",
      " |      >>> df2.values\n",
      " |      array([['parrot', 24.0, 'second'],\n",
      " |             ['lion', 80.5, 1],\n",
      " |             ['monkey', nan, None]], dtype=object)\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The dtype will be a lower-common-denominator dtype (implicit\n",
      " |      upcasting); that is to say if the dtypes (even of numeric types)\n",
      " |      are mixed, the one that accommodates all will be chosen. Use this\n",
      " |      with care if you are not dealing with the blocks.\n",
      " |      \n",
      " |      e.g. If the dtypes are float16 and float32, dtype will be upcast to\n",
      " |      float32.  If dtypes are int32 and uint8, dtype will be upcast to\n",
      " |      int32. By :func:`numpy.find_common_type` convention, mixing int64\n",
      " |      and uint64 will result in a float64 dtype.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.index : Retrievie the index labels\n",
      " |      pandas.DataFrame.columns : Retrieving the column names\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __sizeof__(self)\n",
      " |      Generates the total memory usage for an object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.StringMixin:\n",
      " |  \n",
      " |  __bytes__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Invoked by bytes(obj) in py3 only.\n",
      " |      Yields a bytestring in both py2/py3.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return a string representation for a particular Object\n",
      " |      \n",
      " |      Invoked by str(df) in both py2/py3.\n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.StringMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Provide method name lookup and completion\n",
      " |      Only provide 'public' methods\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(KD.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.from_dict of <class 'pandas.core.frame.DataFrame'>>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kd.dtypes\n",
    "kd.from_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.from_dict of <class 'pandas.core.frame.DataFrame'>>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "kd.from_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAD0CAYAAAB97VinAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAGZdJREFUeJzt3XmUXGWZx/FvdaeTICQhECIycQgIPGE5JBwyEvboISI7cpghAsMAQgiCIuAo64hzYBBZFHBQm+WAiCJCGAMj4LjEgQAHw4CymAeDAi4ISWgIQRLS3Xf+uLeaSlNJv/fWvV3b78Opc7qq3n7vS6f7qXe7z1uKoggREYCOejdARBqHAoKIDFBAEJEBCggiMkABQUQGKCCIyAAFBJEmYWa7mdmCKq8fYma/MrNHzOzkWq6hgCDSBMzsC8ANwOhBr3cBXwM+BuwLzDGzzbNeRwFBpDk8DxxR5fXtgSXu3uPu7wAPAXtnvciIrN8oIut34nFHRz2vrwgq+6z/7hlgVcVL3e7eXX7i7neZ2eQq3zoWeKPi+ZvAuPStjSkgiBSk5/U3uOOGrweV3Wnvg1e5+/QMl1kBjKl4PgZ4PUM9gAKCSLGi/qKv8FtgWzPbBFgJ7ANckbUyBQSRokQR9BcTEMzsaGAjd+82s7OAB4jnBG9y9z9nrVcBQaRAUY49BHd/AZiRfP29itfvAe7J4xoKCCKFKa6HUBQFBJEiFT+HkKthDwhm1gFcB0wFVgMnufuSGuvsAm4CJgOjgIvdfX6NTS3XPRF4HJjl7otzqO9c4FBgJHCdu99YY31dwC3E/+99wMm1tNPMdgMuc/eZZrYNcDMQAU8Dp7l76t/wQXVOA65N2roaOM7dX6mlzorXjgY+4+67p62vSjsnAtcD44HOpJ3Pp6owiqC/L0tT6qYeG5MOB0Yn/2jnAFfmUOexwHJ33xs4APhGDnWW/9i+DbydU30zgT2APYl3lX0wh2oPBEa4+x7AvwOX1NC+wbvhrgIuSH6uJeCwHOq8mviPdiYwD/hiDnWSBJpPJe1MrUqdXwVuc/d9gAuAKVnqpa837NEg6hEQ9gLuB3D3R4Esa6+D/RC4sOJ5Xj/hK4BvAX/Jqb79gaeAu4knge7Noc7ngBFJz2sssKaGugbvhtsV+GXy9X3AfjnUOdvdn0y+HsHam3Ey1WlmmwJfAT6Xoa6qdRIH7Ulm9lPgGGBB6hqjiCjqD3o0inoEhME7q/rMrKahi7uvdPc3zWwMcCdxRK+JmR0PLHX3B2qtq8IE4gD4j8Bc4DYzy/SJVmEl8XBhMXEX95qsFbn7XawdUEruXk66mWkH3OA63f1lADPbAzideB9+5jrNrBO4ETgzaWMmVf7fJwM97r4f8BIZejJAPKkY8mgQ9QgIg3dWdbh7zZ/oZvZB4BfArZVLMjU4EZiV3F02DfhOLTeNJJYDD7j7O+7uxJ+Om9VY55lJndsRz8vcYmajh/ieUJW/qTXtgKtkZkcR97wOcvelNVa3K7At8E3gdmAHMwvbHrh+y4HyPNQ9ZOrJRvGkYsijQdRjlWEhcAhwh5nNIO5C18TM3g/8BDjd3X9Wa30AydixXP8CYK67/7XGah8CzjCzq4APABsS/+LVood3P9leA7qIJ8Hy8ISZzXT3BcRzM7+otUIzOxY4BZjp7q/VWp+7PwbsmNQ9Gbjd3WsZOpQ9RDw/cyvx7r9nUtcQ0XSTivUICHcTf/I+TDwBdEIOdZ5HPBt8oZmV5xIOcPdcJgPz4u73mtk+wGPEvbPT3L3W35ivATeZ2YPEKxfnuftbNdZZdjZwvZmNJN4ie2ctlSXd+2uIu+DzzAzgl+7+pVobWoCzgRvM7FTiIe7R6auIGurTP0RJ5zKIFOMTB86Kbr/8nKCyOx/x6ccz3tyUK21MEilKFDXUkmIIBQSRwkREkeYQRKSsyeYQFBBEihLRUHsMQtQ1p6KZzVGdqrN162y+fQj1TrKa+z+i6lSdDVVnf1/Yo0FoyCBSGO1DqGq3D/9DtMXmE9/zes/rKxi/8di1Xlv+bNh9RC/2Vt+23tlRoq9/7f+nHUe+L6jOl6PqtxX00seIQZv/VgfOHk/Zebuqr/f09DB+/PigOkJVq/PXT4ZtsJs6bcfgOkP9/qnqdwv30suIQZ9FW20/KajO3z37UtXX+0t9dERr/xv1E/rHWP3fPSr1U4rW7kT3da5Z5u5B280/sf/M6PsXnRLUgqnHX9Q++xC22Hwid9wYds/NzdPCNq3NffXnwdf/8d9bULlLekcG1/mHNT1B5ebNmxdcZxEmjgu7a7eIds7e8vDgsrfeGHYX/P67nBpc58q+sBspO0vhI+fXxrz8YnDhJpxU1JBBpEjtEBCKyHok0nqab2NS1lWGIrIeibSW8pChDfIhFJH1SKTFNN8+hKxzCFWzHlUmOkk2dcwB+MD737vCINL62ufmpiGzHiUHVXYDfOLQg3SPtbSfJlxlyDpkWEicTYa8sh6JtKQ2GTIUkfVIpMXkd3LTUCt7ZvZ54JPEeTD/w93vznKdTAEhOaxjbpbvFWkb+Q4ZBlb2kl75lSTnZJjZxsBngW2I83Q+SfyhndqwbExa/uxfgncgHv/kl4PKHXRY+AG3m/xn4O62w8MPUUqzu62edhyTx1kw2YyjK7jsq4ecFFRug9IGwXWuKoXlmu0o1ZoJf11yvZdhrZU9M6tc2XsLeJE4GGwIwXu230M7FUWKFN5DmGBmiyqedycT82VDrez9EXiWOOP2pVmbq4AgUpR0ORWXDXFz0/pW9g4gTuu/VfL8ATNbmKSoT6U5+r0izSq/VYb1rez1EJ8/utrdVxEfqLNxluaqhyBSlCi/VQaqrOyZ2VnAEnefb2b7AY+aWT/xITP/k+UiCggiRcopIKxjZW9xxftfAmo+8EYBQaRITXYQkgKCSFHyHTIMCwUEkSIpIIgIoKPc1uXF3jeDcyCG7kDc7Ec3BF+/e5ewuZbAjW0ATBoxduhCDWD/jvrder46xYa5E/88KqjcxI7RwXVu3BFWZx/h4/ylhO+QBTSHICJlmkMQkbImzIeQNclqF3ATMBkYBVzs7vNzbJdIa2igXAchsm5dPhZY7u57E++j/kZ+TRJpDRERUX/Yo1FkHTL8ELiz4nlzTaWKDId2GTK4+0oAMxtDHBguGFymMslqZ0dR95uLNLII+prrXIbMk4pm9kHiGy6uc/fvDX6/MsnqlpO3aZw+kchwaZcegpm9H/gJcLq7/yzfJom0kHYICMB5wHjgQjO7MHntAHd/O59mibSCqD02Jrn7GcAZObdFpLW0y5AhrR1Hvi/4SPbQhKih25EB5jwRlrj14emfD67zt6teCS5bT1eveCKo3DkFXLuT8Mnk7+7wt6ByRz0T/gf26po3hi4EdKZZfQ/fOR1roCXFENqpKFKYXLMuDwsFBJGiRBD1tsmyo4gE0JBBRIB4hUFDBhEZoB6CiAzQsqOIAEmSVfUQRKRMcwgiAkAUadmxmpejEpf0jgwrHHgke5qEqKE7EG9edEVwncen2NVYTweO26Fu115F+B/DOYvDksFO6gz/xJ3UuVFQuTSd+sd4LUVpNGQQkUREbgHBzDqA64CpwGrgJHdfUvH+Abx7lNv/Aae5e+qL6/RnkSLld/rz4cBod9+d+NaTK8tvJImKLgcOdvcZwAvAhCzNrSkgmNlEM/ujmU2ppR6R1pSsMoQ8hrYXcD+Auz8KTK94bw/i4+GvNLMHgVfcfWmWFteSMakL+DbxufQiMlhEmgSqE8xsUcXz7iTrWNlYoPL2zT4zG+HuvcS9gY8A04CVwINm9oi7P5e2ybXMIVwBfAs4t4Y6RFpXBISvMixz9+nreX8FMKbieUcSDACWA79y978CmNn/EgeH1AEh05DBzI4Hlrr7A+spM8fMFpnZot4Us80irSPXIcNC4EAAM5tBPEQoexzYycwmmNkIYAbwbJYWZ+0hnAhEZrYfcST6jpkdWo5QsHaS1V22ndpcay8ieclv2fFuYJaZPQyUgBPM7CxgibvPN7NzgfIH9B3u/nSWi2RNobZP+WszWwDMrQwGIkKSUjGfgODu/cDcQS8vrnj/duD2Wq+jfQgiRWq3jUnuPjOHdoi0pnYLCCFWR338YU1PUNnOUtg856QRY4OvH5oQNc125DTbnOtp9qoUe7xztkkpcLs6sHDVn4LKPXjaVsF1ljYdH1Su86NHBte582FzgstGUWOd2xhCQwaRokRArwKCiCTUQxCRdykgiAiQ3O1Y70ako4AgUiANGUQkph6CiLxLy44iUhZB1Dt0sUaigCBSJA0Z3mvKztsxb9684biUDDLrlR/U7drXvlC/azeCJjzJTT0EkUIpIIhIWdv0EJKEDIcCI4Hr3D3sQAWRdtGEQ4asKdRmEmd63RPYF/hgjm0SaRn5ZWEfHll7CPsT53S7mzgb7L/m1iKRVhGViPpK9W5FKlkDwgRgS+BgYCtgvplNqTwpxszmAHMAtthii1rbKdJ0IiDqb4+AsBxY7O7vAG5mq4DNgFfLBSqTrB5xxBHNtV1LJA/tMocAPAR83MxKZrYFsCFxkBCRClFUCno0ikwBwd3vBZ4AHgPuIT5YUocviAzSLpOKuPsX8myISMuJ2mcOQUSGEBFvX24mCggiRYlK9PfWdMD6sFNAECmQeggiMiCvOQQz6wCuA6YCq4GT3H1JlTL/DfzI3b+V5TrN1Z8RaSLxHEJuy46HA6PdfXfgHODKKmUuBjappc0KCCJFiXJddtwLuB/A3R8Fple+aWZHEt9sfV8tTdaQQaRA/eGbjiaY2aKK593Jbt+yscAbFc/7zGyEu/ea2U7A0cCRwL/V0l4FBJGCRFGJ/r7ATniJZe4+fT0lVgBjKp53uHs5Y+NxwN8BPwcmA++Y2Qvufn/aNisgiBQoeJVh6I7EQuAQ4A4zm0F8tzGw9iZBM7sI+GuWYAAKCCKFCl5lGLojcTcwy8weJg4fJ5jZWcASd59fQxPXooAgUpQo1RzCerl7PzB30MuLq5S7qJbrKCCIFKS87NhMFBBECtQWOxXNrAu4hXhGsw842d3f030RaXd5DRmGS9aNSQcCI9x9D+DfgUvya5JIa4iiEv39YY9GkXXI8BwwItk7PRZYk1+TRFpHs/UQsgaElcTDhcXECVcPHlxASVZFmm9SMeuQ4UzgAXffjvjuq1vMbHRlAXfvdvfp7j59/PjxtbZTpOlExD2EkEejyNpD6OHdYcJrQBfQmUuLRFpIky0yZA4IXwNuMrMHiY9yO8/d38qvWSKtoZE+/UNkCgjuvhL4p5zbItJSGi3Feohh2Zj06yefYeK4KUFldxwTdkzk/h0Tg69/9YongsodOG6H4DpnrwobIc165QfBdRZhzdLng8p1bfah3K997pafDC57y4rfBJU7f8Ndguvcbk3Y4leqLOgbpykMfQF3LTUS7VQUKUg8qVjvVqSjgCBSoH71EESkLFJAEBFIhgz1bkRKCggiBVIPQUQGqIcgIkDcO9Cyo4gMaKA7m4MoIIgUJJ5UbK6IMCwBYeq0HZk3b95wXKqqc+p25forYgdiqEtf/H542QLbkSuzVMWbbF+SeggiRdKkoogAEJWgv9SCQwYz2w24zN1nmtk2wM3EvaGngdOSnPEiMkizDRmGzJhkZl8AbgDKGZGuAi5w972JT5A5rLjmiTSvCOgthT0aRUgKteeBIyqe7wr8Mvn6PmC/vBsl0ir6KQU9GsWQQwZ3v8vMJle8VHL3ck/oTWBcte9TklWR/IYMSYbz64hzmK4GTnL3JRXvnwnMTp7+2N2/nOU6WZKsVs4XjAFer1ZISVal3UXEG5NCHgEOB0a7++7EK+lXlt8ws62BY4A9gN2Bj5nZzlnanCUgPGFmM5OvDwAezHJhkXbQH/gIsBdwP4C7PwpMr3jvj8DH3b0vmeDvAlZlaW+WZcezgevNbCTwW+DOLBcWaQcphgwTzGxRxfNud++ueD4WeKPieZ+ZjXD3XndfAywzsxJwOfCEuz+Xpb1BAcHdXwBmJF8/B+yb5WIi7aS8yhBombtPX8/7K4iH6GUd7t5bfpKci3IT8bzep9O19F3amCRSoBw36CwEDgHuMLMZwFPlN5KewY+An7v7ZbVcRAFBpCAR8W7FnNwNzDKzh4n3/5xgZmcBS4gPSdoXGGVmByTlz3X3R9JeRAFBpEB59RCSycK5g15eXPH1aHKggCBSoGbb06+AIFKQiOa7l0EBQaQo4ZuOGoYCgkhBIqB3yFKNRQFBpEAaMojIAA0ZRATQyU3r9Punnmf2locHlR1HV1C51Sl+1J2B95uvoi+4zk1KI4PKXftCfY+DDz2SPU1C1FChR9EDHLPrWUHl3lcK/5WdUAr7XSql2T2UcrVfQwYRGdDfZCFBAUGkIC07ZBiUZHUacC3QR5y55Th3f6XANoo0rfBBaGPIkmT1auAz7j4TmAd8sbDWiTSxnDMmDYssSVZnu/uTydcjyJiZRaQd9BMFPRpF6iSr7v4ygJntAZwO7FPt+yqTrHZpqkLaVOP8qYfJ9JdqZkcB5wMHufvSamWS9E/dANO2ndpsPxeRmrXspGIlMzsWOAWY6e6v5d8kkdbRSMOBEKmyLptZJ3ANcW63eWa2wMwy5X8XaXVRikejSJ1kFdiksNaItJSI3ob6cx/asMz2bbX9JG698cqhCwKvHnJSULkT/zwq+Prf3eFvQeXOWTwxuM6Fq/4UXLaeblnxm6BylxZw7dDtyAC3PX5VULn9pp0SXOcTvW8FlUvVrU+xdbnRPv1DaPpfpEAtP6koIuGiJusjKCCIFKQtlh1FJFyzLTsqIIgUqLnCgQKCSGHiJKvNFRIUEEQKpElFEQHynVQ0sw7gOmAqcR6Sk9x9ScX7JxPfUtALXOzu92a5TqqtyyKSRhT8X4DDgdHuvjtwDjCw08/MNgc+C+wJ7A9cambhO/cqDEsP4XfPvsT+u5waVHaD0gZB5SZ2hG8ZO+qZsDg9qTM8nj942lbBZevp/A13qdu10yREDd2B+NMnvx1c54qTTgwqN2rKpsF17vpfPcFlIddlx72A+wHc/VEzm17x3oeBhe6+GlhtZkuAnYFfpb2IhgwiBYmA/ih4DmGCmS2qeN6dpBAoGwu8UfG8z8xGuHtvlffeBMZlaLICgkiR+sInFZe5+/T1vL+C+C7jso4kGFR7bwzwenAjKysNKWRmu5nZgkGvHW1mj2S5qEi7yHEOYSFwIICZzQCeqnjvMWBvMxttZuOA7YGns7R3yB5CkmT1n4G3Kl6bBnwKAk9AEWlDOW9dvhuYZWYPE//dnWBmZwFL3H2+mV0DPEj8IX++u2fKdRoyZCgnWb0VwMw2Bb4CfA64PstFRdpFXluX3b0fmDvo5cUV719PDn+PqZKsJhmTbgTOBN5e3/dVJlntLHXW2k6RJhQ8HGgYafch7ApsC3wTuB3Ywcy+Xq2gu3e7+3R3n94RKSBI+ykPGUIejSLVKoO7PwbsCJD0Gm53988V0C6RlhCFLzs2BC07ihSkZW9uGpRkdZ2vicjamm0OYVh6CP30s7IvbBVkVeAE5MYd4Vu1X13zxtCFgEmdGwXXWdp0fHDZetpuzZq6XXtCqSu4bGhC1NDtyABjb7gpqNyaedcG1wnPpCirBCkikoiiSHMIIvKuRlpBCKGAIFIgzSGICFDeh6CAICKJvqi5Bg0KCCKFab6tywoIIgVJmSClISggiBSoucKBAoJIoTSpWFWJzlLYjZUdpbCcKylSU9EZeFNnmn+6zo8emaJ0/dRzSqsUhefPCf3DSZMQNXQHYtcRnwmuk6vuCy6qVQYRWYt2KooIEK8x9DXZXsWggGBmuwGXuftMM5tInKppPNAJHOfuzxfYRpGm1Ww9hCEH10mS1RuA8skoXwVuc/d9gAuAKcU1T6S59RMFPRpFyGxbOclq2Z7AJDP7KXAMsKCAdok0v+jdOx6HejSKIQOCu98FVN5UPxnocff9gJeAL1b7PjObY2aLzGxRVGqucZRIHqLA3kEj9RCyTCouB+YnX98DXFKtUHIMVTfADtvs1Dj/xyLDqNm2Lmc5/fkhkhNkgH1Im0JGpI30R1HQo1Fk6SGcDdxgZqcSHzB5dL5NEmkNES16t2NlQlV3fxGYVWCbRFpE893tWBqOGU4zWwq8WOWtCcCynC+nOlVnkXVu6e6bhXzzdh/aPmLFhkEXKm3y5uNDnP78Hma2AfBdYCLxEfD/4u5LB5W5HNiL+MO/OznybZ2GZafiun6AZrYo7Q9hKKpTdTZSnaE9hIynJp8KPOXuF5nZbOJ9QWeU3zSzjwDbuPvuZjYKeMbM7nT3nnVVmGVSUUQCFTypuBdwf/L1fcB+g95/BCjnrY+IdxavNy+/7mUQKUhEqmXHCWa2qOJ5d7J0D4CZfYr4kOVKrxBP7EM8ZBhX+WZyJPwqM+sCbknqXLm+RtQ7IHQPXUR1qs4mrTOK6Iv6gop2wbL1DU/c/Ubik9cHmNk8YEzydAzw+uDvM7PxwJ3AAne/dKh2DMukokg72nbrKdHq18NOr9pgs3eyTCqeDYypmEPY191PrXh/A2AhcKW73xZSZ717CCItaxgSpHwTuMXMHgLeIdkTZGZfJe4V7AlsDZxsZicn33OCu/9hXRWqhyBSkG22tujtnrDP3I0m9qbuIRRBPQSRAjXStuQQCggiBUm5ytAQFBBECtRsQ3IFBJGiRBF9wQEh417FnCkgiBQk3clNCggiLU9DBhEZ0Ejp0UIoIIgUJKKxEqiGUEAQKZD2IYjIAO1DEBEAogj6+lswp6KIZNF8ORUVEEQKpElFERmggCAiAIwa1fnA1lttNCGweN4ZozNRPgQRGaCsyyIyQAFBRAYoIIjIAAUEERmggCAiAxQQRGSAAoKIDFBAEJEBCggiMuD/AUnPX5qXf35DAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(KD.corr())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dfs = []\n",
    "for datasetId, category_row in KD.set_index(\"datasetId\")[\"categories\"].iteritems():\n",
    "    category_dict = eval(category_row)\n",
    "    categories = category_dict[\"categories\"]\n",
    "    _df = pd.DataFrame(categories)\n",
    "    _df[\"datasetId\"] = datasetId \n",
    "    if category_dict[\"type\"] != \"dataset\":\n",
    "        print(category_dict[\"type\"])\n",
    "    _dfs.append(_df)\n",
    "categories_df = pd.concat(_dfs, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Categories')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "categories_df.groupby(\"name\")[\"totalCount\"].sum().nlargest(10).plot(kind='bar', ax=ax)\n",
    "ax.set_ylabel(\"Total count\")\n",
    "ax.set_xlabel(\"Categories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(categories_df .corr())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
